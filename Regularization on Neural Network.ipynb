{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Activation\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = None, index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index() # key_word,value_index dic\n",
    "reverse_index = dict([(value, key) for (key, value) in word_index.items()]) # key_index,value_word dic\n",
    "decoded = \" \".join( [reverse_index.get(i-3, \"#\") for i in X_train[0]] )\n",
    "print(decoded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "num_classes = max(y_train) + 1\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num = 10000\n",
    "tokenizer = Tokenizer(num_words=max_num)\n",
    "tokenizer.fit_on_sequences(X_train)\n",
    "X_train = tokenizer.sequences_to_matrix(X_train, mode = 'tfidf')\n",
    "X_test = tokenizer.sequences_to_matrix(X_test, mode = 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5855967311039936\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 3,shuffle = True)\n",
    "kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find out the overfitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 348us/step - loss: 0.3507 - acc: 0.8497\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 313us/step - loss: 0.0815 - acc: 0.9764\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 311us/step - loss: 0.0231 - acc: 0.9962\n",
      "8334/8334 [==============================] - 2s 197us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 312us/step - loss: 0.1807 - acc: 0.9381\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 306us/step - loss: 0.0318 - acc: 0.9924\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 303us/step - loss: 0.0068 - acc: 0.9993\n",
      "8333/8333 [==============================] - 1s 167us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 305us/step - loss: 0.0291 - acc: 0.9914\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 310us/step - loss: 0.0068 - acc: 0.9994\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 311us/step - loss: 0.0018 - acc: 1.0000\n",
      "8333/8333 [==============================] - 2s 191us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 375us/step - loss: 0.3582 - acc: 0.8471\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 327us/step - loss: 0.0808 - acc: 0.9758\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 320us/step - loss: 0.0230 - acc: 0.9966 1s - loss: 0.0\n",
      "8334/8334 [==============================] - 2s 185us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 322us/step - loss: 0.1744 - acc: 0.9376\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 326us/step - loss: 0.0292 - acc: 0.9941\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 326us/step - loss: 0.0081 - acc: 0.9993 \n",
      "8333/8333 [==============================] - 2s 195us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 328us/step - loss: 0.0243 - acc: 0.9942\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 324us/step - loss: 0.0066 - acc: 0.9995\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 323us/step - loss: 0.0035 - acc: 0.9999\n",
      "8333/8333 [==============================] - 1s 171us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 376us/step - loss: 0.3464 - acc: 0.8511\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 6s 335us/step - loss: 0.0717 - acc: 0.9793\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 6s 337us/step - loss: 0.0189 - acc: 0.9968\n",
      "8334/8334 [==============================] - 2s 231us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 331us/step - loss: 0.1824 - acc: 0.9396\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 337us/step - loss: 0.0323 - acc: 0.9924\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 334us/step - loss: 0.0071 - acc: 0.9994\n",
      "8333/8333 [==============================] - 2s 215us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 337us/step - loss: 0.0240 - acc: 0.9935\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 337us/step - loss: 0.0043 - acc: 0.9999\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 330us/step - loss: 0.0015 - acc: 1.0000\n",
      "8333/8333 [==============================] - 1s 171us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 401us/step - loss: 0.3568 - acc: 0.8478\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 6s 346us/step - loss: 0.0784 - acc: 0.9767\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 6s 346us/step - loss: 0.0211 - acc: 0.9965\n",
      "8334/8334 [==============================] - 2s 207us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 350us/step - loss: 0.1641 - acc: 0.9431\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 346us/step - loss: 0.0249 - acc: 0.9950\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 346us/step - loss: 0.0066 - acc: 0.9997\n",
      "8333/8333 [==============================] - 2s 194us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 351us/step - loss: 0.0221 - acc: 0.9935\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 348us/step - loss: 0.0041 - acc: 0.9999\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 335us/step - loss: 0.0013 - acc: 1.0000\n",
      "8333/8333 [==============================] - 2s 180us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 410us/step - loss: 0.3449 - acc: 0.8558\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 6s 367us/step - loss: 0.0700 - acc: 0.9797\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 6s 361us/step - loss: 0.0191 - acc: 0.9971\n",
      "8334/8334 [==============================] - 2s 189us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 363us/step - loss: 0.1831 - acc: 0.9359\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 362us/step - loss: 0.0282 - acc: 0.9932\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 360us/step - loss: 0.0061 - acc: 0.9993\n",
      "8333/8333 [==============================] - 1s 172us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 365us/step - loss: 0.0232 - acc: 0.9926\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 365us/step - loss: 0.0044 - acc: 0.9999\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 365us/step - loss: 0.0013 - acc: 1.0000\n",
      "8333/8333 [==============================] - 1s 178us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 431us/step - loss: 0.3515 - acc: 0.8508\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 6s 374us/step - loss: 0.0702 - acc: 0.9798\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 6s 376us/step - loss: 0.0171 - acc: 0.9976\n",
      "8334/8334 [==============================] - 2s 249us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 378us/step - loss: 0.1710 - acc: 0.9398\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 372us/step - loss: 0.0269 - acc: 0.9941\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 376us/step - loss: 0.0053 - acc: 0.9996\n",
      "8333/8333 [==============================] - 2s 187us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 384us/step - loss: 0.0214 - acc: 0.9936\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 391us/step - loss: 0.0044 - acc: 0.9998\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 379us/step - loss: 0.0013 - acc: 1.0000\n",
      "8333/8333 [==============================] - 1s 179us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 8s 450us/step - loss: 0.3481 - acc: 0.8507\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 393us/step - loss: 0.0658 - acc: 0.9822\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 6s 389us/step - loss: 0.0162 - acc: 0.9979\n",
      "8334/8334 [==============================] - 2s 237us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 394us/step - loss: 0.1803 - acc: 0.9387\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 391us/step - loss: 0.0298 - acc: 0.9933\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 388us/step - loss: 0.0070 - acc: 0.9995\n",
      "8333/8333 [==============================] - 2s 180us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 412us/step - loss: 0.0217 - acc: 0.9947\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 386us/step - loss: 0.0049 - acc: 0.9999\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 380us/step - loss: 0.0023 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 230us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 8s 461us/step - loss: 0.3559 - acc: 0.8495\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 405us/step - loss: 0.0674 - acc: 0.9803\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 399us/step - loss: 0.0162 - acc: 0.9977\n",
      "8334/8334 [==============================] - 2s 239us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 400us/step - loss: 0.1739 - acc: 0.9401\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 405us/step - loss: 0.0252 - acc: 0.9944\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 401us/step - loss: 0.0054 - acc: 0.9998\n",
      "8333/8333 [==============================] - 1s 180us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 407us/step - loss: 0.0233 - acc: 0.9939\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 405us/step - loss: 0.0055 - acc: 0.9998\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 401us/step - loss: 0.0013 - acc: 1.0000\n",
      "8333/8333 [==============================] - 1s 177us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 8s 492us/step - loss: 0.3523 - acc: 0.8539 0s - loss: 0.3579 - acc: \n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 415us/step - loss: 0.0618 - acc: 0.9835\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 413us/step - loss: 0.0140 - acc: 0.9983\n",
      "8334/8334 [==============================] - 2s 244us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 420us/step - loss: 0.1693 - acc: 0.9417\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 421us/step - loss: 0.0241 - acc: 0.9951\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 419us/step - loss: 0.0050 - acc: 0.9995\n",
      "8333/8333 [==============================] - 2s 199us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 420us/step - loss: 0.0183 - acc: 0.9954\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 420us/step - loss: 0.0040 - acc: 0.9999\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 424us/step - loss: 0.0012 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 185us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 8s 500us/step - loss: 0.3536 - acc: 0.8477\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 436us/step - loss: 0.0664 - acc: 0.9811\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 434us/step - loss: 0.0167 - acc: 0.9975\n",
      "8334/8334 [==============================] - 2s 249us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 434us/step - loss: 0.1722 - acc: 0.9413\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 435us/step - loss: 0.0246 - acc: 0.9943\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 436us/step - loss: 0.0060 - acc: 0.9994\n",
      "8333/8333 [==============================] - 2s 188us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 435us/step - loss: 0.0163 - acc: 0.9962 2s - l\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 431us/step - loss: 0.0030 - acc: 0.9998\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 432us/step - loss: 0.0012 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 193us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 515us/step - loss: 0.3518 - acc: 0.8531\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 443us/step - loss: 0.0624 - acc: 0.9822\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 444us/step - loss: 0.0149 - acc: 0.9977\n",
      "8334/8334 [==============================] - 2s 266us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 438us/step - loss: 0.1750 - acc: 0.9394\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 443us/step - loss: 0.0226 - acc: 0.9957\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 443us/step - loss: 0.0046 - acc: 0.9996\n",
      "8333/8333 [==============================] - 2s 196us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 450us/step - loss: 0.0198 - acc: 0.9945\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 452us/step - loss: 0.0033 - acc: 0.9999 0s - loss: 0.0034 - \n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 443us/step - loss: 9.6005e-04 - acc: 1.0000\n",
      "8333/8333 [==============================] - 2s 202us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 546us/step - loss: 0.3499 - acc: 0.8516\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 8s 455us/step - loss: 0.0636 - acc: 0.9821\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 8s 457us/step - loss: 0.0140 - acc: 0.9984\n",
      "8334/8334 [==============================] - 2s 231us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 455us/step - loss: 0.1757 - acc: 0.9401 4s -  - ETA: 2s \n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 459us/step - loss: 0.0237 - acc: 0.9953 1s - loss: 0.0247 - a - ETA: 0s - loss: 0.0247 - acc\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 458us/step - loss: 0.0051 - acc: 0.9996\n",
      "8333/8333 [==============================] - 2s 193us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 461us/step - loss: 0.0194 - acc: 0.9944 0s - loss: 0.0197 - acc:\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 458us/step - loss: 0.0047 - acc: 0.9998\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 452us/step - loss: 0.0020 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 200us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 557us/step - loss: 0.3528 - acc: 0.8481\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 8s 472us/step - loss: 0.0625 - acc: 0.9827\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 8s 478us/step - loss: 0.0147 - acc: 0.9981\n",
      "8334/8334 [==============================] - 2s 239us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 471us/step - loss: 0.1722 - acc: 0.9393\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 471us/step - loss: 0.0225 - acc: 0.9951\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 472us/step - loss: 0.0043 - acc: 0.9997\n",
      "8333/8333 [==============================] - 2s 224us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 469us/step - loss: 0.0200 - acc: 0.9943\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 476us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 479us/step - loss: 9.7745e-04 - acc: 1.0000\n",
      "8333/8333 [==============================] - 2s 192us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 567us/step - loss: 0.3629 - acc: 0.8415\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 8s 490us/step - loss: 0.0611 - acc: 0.9840\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 8s 489us/step - loss: 0.0144 - acc: 0.9983\n",
      "8334/8334 [==============================] - 2s 239us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 489us/step - loss: 0.1723 - acc: 0.9405\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 497us/step - loss: 0.0212 - acc: 0.9954\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 486us/step - loss: 0.0044 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 202us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 487us/step - loss: 0.0198 - acc: 0.9952\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 492us/step - loss: 0.0038 - acc: 0.9998\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 485us/step - loss: 0.0012 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 200us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 10s 581us/step - loss: 0.3549 - acc: 0.8484\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 8s 502us/step - loss: 0.0604 - acc: 0.9838\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 8s 494us/step - loss: 0.0137 - acc: 0.9983\n",
      "8334/8334 [==============================] - 2s 260us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 502us/step - loss: 0.1755 - acc: 0.9399\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 499us/step - loss: 0.0243 - acc: 0.9953\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 501us/step - loss: 0.0053 - acc: 0.9995\n",
      "8333/8333 [==============================] - 2s 201us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 498us/step - loss: 0.0192 - acc: 0.9953\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 505us/step - loss: 0.0044 - acc: 0.9999\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 505us/step - loss: 0.0020 - acc: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8333/8333 [==============================] - 2s 210us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 10s 600us/step - loss: 0.3489 - acc: 0.8510\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 9s 513us/step - loss: 0.0567 - acc: 0.9848\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 9s 511us/step - loss: 0.0125 - acc: 0.9984\n",
      "8334/8334 [==============================] - 2s 257us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 512us/step - loss: 0.1816 - acc: 0.9365\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 511us/step - loss: 0.0247 - acc: 0.9956\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 530us/step - loss: 0.0054 - acc: 0.9998\n",
      "8333/8333 [==============================] - 2s 213us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 521us/step - loss: 0.0194 - acc: 0.9952\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 523us/step - loss: 0.0038 - acc: 0.9999\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 526us/step - loss: 0.0019 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 198us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - ETA: 0s - loss: 0.3548 - acc: 0.848 - 11s 636us/step - loss: 0.3543 - acc: 0.8486\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 9s 545us/step - loss: 0.0561 - acc: 0.9840\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 9s 561us/step - loss: 0.0121 - acc: 0.9987\n",
      "8334/8334 [==============================] - 2s 260us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 546us/step - loss: 0.1709 - acc: 0.9416\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 548us/step - loss: 0.0223 - acc: 0.9954\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 544us/step - loss: 0.0049 - acc: 0.9997\n",
      "8333/8333 [==============================] - 2s 246us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 564us/step - loss: 0.0199 - acc: 0.9946\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 546us/step - loss: 0.0046 - acc: 0.9998\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 561us/step - loss: 0.0019 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 212us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 11s 655us/step - loss: 0.3657 - acc: 0.8369\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 9s 558us/step - loss: 0.0616 - acc: 0.9836\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 9s 560us/step - loss: 0.0145 - acc: 0.9985\n",
      "8334/8334 [==============================] - 2s 286us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 555us/step - loss: 0.1766 - acc: 0.9380\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 556us/step - loss: 0.0222 - acc: 0.9956\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 551us/step - loss: 0.0044 - acc: 0.9998\n",
      "8333/8333 [==============================] - 2s 209us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 552us/step - loss: 0.0182 - acc: 0.9949\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 552us/step - loss: 0.0040 - acc: 0.9999\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 552us/step - loss: 0.0010 - acc: 1.0000\n",
      "8333/8333 [==============================] - 2s 224us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 11s 665us/step - loss: 0.3492 - acc: 0.8510\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 10s 570us/step - loss: 0.0551 - acc: 0.9851\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 10s 571us/step - loss: 0.0112 - acc: 0.9987\n",
      "8334/8334 [==============================] - 2s 266us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 561us/step - loss: 0.1771 - acc: 0.9399\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 10s 571us/step - loss: 0.0243 - acc: 0.9953\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 10s 575us/step - loss: 0.0049 - acc: 0.9996\n",
      "8333/8333 [==============================] - 2s 215us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 564us/step - loss: 0.0173 - acc: 0.9956\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 567us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 562us/step - loss: 8.4070e-04 - acc: 1.0000\n",
      "8333/8333 [==============================] - 2s 212us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 11s 686us/step - loss: 0.3447 - acc: 0.8502\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 10s 582us/step - loss: 0.0500 - acc: 0.9859\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 10s 583us/step - loss: 0.0109 - acc: 0.9989\n",
      "8334/8334 [==============================] - 2s 270us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 10s 577us/step - loss: 0.1847 - acc: 0.9339\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 10s 582us/step - loss: 0.0222 - acc: 0.9953\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 10s 578us/step - loss: 0.0040 - acc: 0.9998\n",
      "8333/8333 [==============================] - 2s 219us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 10s 574us/step - loss: 0.0183 - acc: 0.9957\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 569us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 10s 577us/step - loss: 8.6907e-04 - acc: 1.0000\n",
      "8333/8333 [==============================] - 2s 217us/step\n"
     ]
    }
   ],
   "source": [
    "units = range(100,300,10)\n",
    "loss_train = []\n",
    "acc_train = []\n",
    "loss_val = []\n",
    "acc_val = []\n",
    "for num in units:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num,input_shape = (max_num,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    loss_val_cv = 0\n",
    "    acc_val_cv = 0\n",
    "    loss_train_cv = 0\n",
    "    acc_train_cv = 0\n",
    "    for train_cv_index, val_index in kf.split(X_train):\n",
    "        X_train_cv = X_train[train_cv_index]\n",
    "        y_train_cv = y_train[train_cv_index]\n",
    "        X_val_cv = X_train[val_index]\n",
    "        y_val_cv = y_train[val_index]\n",
    "        hist = model.fit(X_train_cv,y_train_cv,batch_size=200, epochs = 3)\n",
    "        loss_train_cv = loss_train_cv + hist.history.get('loss')[-1]\n",
    "        acc_train_cv = acc_train_cv + hist.history.get('acc')[-1]\n",
    "        score_val_cv = model.evaluate(X_val_cv,y_val_cv, batch_size=200, verbose = 1)\n",
    "        loss_val_cv = loss_val_cv + score_val_cv[0]\n",
    "        acc_val_cv = acc_val_cv + score_val_cv[1]\n",
    "    loss_val.append(loss_val_cv/3)\n",
    "    acc_val.append(acc_val_cv/3)\n",
    "    loss_train.append(loss_train_cv/3)\n",
    "    acc_train.append(acc_train_cv/3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = units\n",
    "loss_train= pd.Series(loss_train, index = ix)\n",
    "loss_val = pd.Series(loss_val, index = ix)\n",
    "acc_train = pd.Series(acc_train, index = ix)\n",
    "acc_val = pd.Series(acc_val, index = ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(loss_val, label = 'loss_val')\n",
    "ax.plot(loss_train, label = 'loss_train')\n",
    "ax.legend()\n",
    "plt.xlabel('hidden_layer_units_#') \n",
    "plt.ylabel('cross_entropy_loss') \n",
    "plt.title('Model Loss vs. hidden layer size')\n",
    "fig.savefig(\"loss_cv.png\",dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(acc_val,label = 'acc_val')\n",
    "ax.plot(acc_train, label = 'acc_train')\n",
    "ax.legend()\n",
    "plt.xlabel('hidden_layer_units_#') \n",
    "plt.ylabel('accurate_rate') \n",
    "plt.title('Model accuracy vs. hidden layer size')\n",
    "fig.savefig(\"acc_cv.png\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfitting, while hidden layer contains 250 nodes in this case\n",
    "# first kind of regularization: dropout\n",
    "# second kind of regularization: l1_norm_kernel_regularizer\n",
    "# third kind of regularization: l2_norm_kernel_regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 13s 536us/step - loss: 0.3210 - acc: 0.8646\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 11s 435us/step - loss: 0.0665 - acc: 0.9803\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 10s 417us/step - loss: 0.0141 - acc: 0.9978\n",
      "25000/25000 [==============================] - 6s 229us/step\n"
     ]
    }
   ],
   "source": [
    "# the baseline to compare with\n",
    "model_overfitting = Sequential()\n",
    "model_overfitting.add(Dense(250,input_shape = (max_num,)))\n",
    "model_overfitting.add(Activation('relu'))\n",
    "model_overfitting.add(Dense(num_classes))\n",
    "model_overfitting.add(Activation('softmax'))\n",
    "model_overfitting.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_overfitting = model_overfitting.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_overfitting = model_overfitting.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "base_train_acc = hist_overfitting.history.get('acc')[-1]\n",
    "base_test_acc = score_overfitting[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the overfitting model on training dataset is\n",
      "0.9978400020599365\n",
      "The accurate rate of the overfitting model on test dataset is\n",
      "0.8704400014877319\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the overfitting model on training dataset is')\n",
    "print(base_train_acc)\n",
    "print('The accurate rate of the overfitting model on test dataset is')\n",
    "print(base_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model_overfitting.save_weights('model_base_weights.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('model_base_architecture.json', 'w') as f:\n",
    "    f.write(model_overfitting.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Model reconstruction from JSON file\n",
    "with open('model_base_architecture.json', 'r') as f:\n",
    "     model_overfitting = model_from_json(f.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "model_overfitting.load_weights('model_base_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 10s 575us/step - loss: 0.3509 - acc: 0.8487\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 439us/step - loss: 0.0665 - acc: 0.9796\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 417us/step - loss: 0.0151 - acc: 0.9976\n",
      "8334/8334 [==============================] - 2s 235us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 420us/step - loss: 0.1679 - acc: 0.9443\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 417us/step - loss: 0.0240 - acc: 0.9945\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 413us/step - loss: 0.0043 - acc: 0.9999\n",
      "8333/8333 [==============================] - 1s 124us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 412us/step - loss: 0.0190 - acc: 0.9951\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 422us/step - loss: 0.0036 - acc: 0.9998\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 418us/step - loss: 0.0016 - acc: 0.9999\n",
      "8333/8333 [==============================] - 1s 123us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 554us/step - loss: 0.3457 - acc: 0.8537\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 412us/step - loss: 0.0728 - acc: 0.9778\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 432us/step - loss: 0.0186 - acc: 0.9969 2\n",
      "8334/8334 [==============================] - 2s 256us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 434us/step - loss: 0.1829 - acc: 0.9414\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 444us/step - loss: 0.0335 - acc: 0.9917\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 439us/step - loss: 0.0084 - acc: 0.9990\n",
      "8333/8333 [==============================] - 1s 138us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 421us/step - loss: 0.0229 - acc: 0.9932\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 414us/step - loss: 0.0064 - acc: 0.9998\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 411us/step - loss: 0.0032 - acc: 0.9998\n",
      "8333/8333 [==============================] - 1s 132us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 554us/step - loss: 0.3603 - acc: 0.8462\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 411us/step - loss: 0.0846 - acc: 0.9735\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 413us/step - loss: 0.0265 - acc: 0.9945\n",
      "8334/8334 [==============================] - 2s 226us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 411us/step - loss: 0.1752 - acc: 0.9429\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 413us/step - loss: 0.0341 - acc: 0.9919\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 413us/step - loss: 0.0082 - acc: 0.9991\n",
      "8333/8333 [==============================] - 1s 127us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 417us/step - loss: 0.0210 - acc: 0.9939\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 418us/step - loss: 0.0067 - acc: 0.9995\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 420us/step - loss: 0.0031 - acc: 0.9996\n",
      "8333/8333 [==============================] - 1s 141us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 555us/step - loss: 0.3671 - acc: 0.8420\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 412us/step - loss: 0.0941 - acc: 0.9708\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 409us/step - loss: 0.0308 - acc: 0.9935\n",
      "8334/8334 [==============================] - 2s 226us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 413us/step - loss: 0.1784 - acc: 0.9383\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 411us/step - loss: 0.0409 - acc: 0.9898\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 412us/step - loss: 0.0141 - acc: 0.9978\n",
      "8333/8333 [==============================] - 1s 123us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 411us/step - loss: 0.0287 - acc: 0.9920\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 413us/step - loss: 0.0091 - acc: 0.9989\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 412us/step - loss: 0.0055 - acc: 0.9996\n",
      "8333/8333 [==============================] - 1s 133us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 558us/step - loss: 0.3780 - acc: 0.8363\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 432us/step - loss: 0.1128 - acc: 0.9608\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 432us/step - loss: 0.0445 - acc: 0.9884\n",
      "8334/8334 [==============================] - 2s 246us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 413us/step - loss: 0.1829 - acc: 0.9386\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 415us/step - loss: 0.0575 - acc: 0.9849\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 414us/step - loss: 0.0210 - acc: 0.9962\n",
      "8333/8333 [==============================] - 1s 129us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 421us/step - loss: 0.0391 - acc: 0.9882\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 431us/step - loss: 0.0153 - acc: 0.9977\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 427us/step - loss: 0.0076 - acc: 0.9986\n",
      "8333/8333 [==============================] - 1s 150us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 562us/step - loss: 0.3803 - acc: 0.8366\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 410us/step - loss: 0.1395 - acc: 0.9504\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 413us/step - loss: 0.0698 - acc: 0.9794\n",
      "8334/8334 [==============================] - 2s 233us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 409us/step - loss: 0.1915 - acc: 0.9342\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 413us/step - loss: 0.0792 - acc: 0.9764\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 417us/step - loss: 0.0386 - acc: 0.9897\n",
      "8333/8333 [==============================] - 1s 131us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 411us/step - loss: 0.0574 - acc: 0.9815\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 412us/step - loss: 0.0248 - acc: 0.9935\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 412us/step - loss: 0.0161 - acc: 0.9960\n",
      "8333/8333 [==============================] - 1s 140us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 562us/step - loss: 0.4089 - acc: 0.8185\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 409us/step - loss: 0.1725 - acc: 0.9378\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 408us/step - loss: 0.0985 - acc: 0.9662\n",
      "8334/8334 [==============================] - 2s 229us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 411us/step - loss: 0.2037 - acc: 0.9276 0s - loss: 0.2014 - ac\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 413us/step - loss: 0.1088 - acc: 0.9640\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 411us/step - loss: 0.0641 - acc: 0.9798\n",
      "8333/8333 [==============================] - 1s 122us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 412us/step - loss: 0.0792 - acc: 0.9730\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 411us/step - loss: 0.0532 - acc: 0.9847\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 413us/step - loss: 0.0350 - acc: 0.9908\n",
      "8333/8333 [==============================] - 1s 135us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 568us/step - loss: 0.4576 - acc: 0.7972\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 410us/step - loss: 0.2261 - acc: 0.9171\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 421us/step - loss: 0.1576 - acc: 0.9432\n",
      "8334/8334 [==============================] - 2s 251us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 423us/step - loss: 0.2300 - acc: 0.9158\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 423us/step - loss: 0.1624 - acc: 0.9420\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 420us/step - loss: 0.1271 - acc: 0.9572\n",
      "8333/8333 [==============================] - 1s 138us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 409us/step - loss: 0.1395 - acc: 0.9500\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 410us/step - loss: 0.1138 - acc: 0.9620\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 410us/step - loss: 0.0836 - acc: 0.9724\n",
      "8333/8333 [==============================] - 1s 123us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 10s 577us/step - loss: 0.6025 - acc: 0.7201\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 7s 420us/step - loss: 0.3487 - acc: 0.8590\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 7s 418us/step - loss: 0.2781 - acc: 0.8943\n",
      "8334/8334 [==============================] - 2s 255us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 417us/step - loss: 0.3046 - acc: 0.8816\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 464us/step - loss: 0.2533 - acc: 0.9060\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 430us/step - loss: 0.2226 - acc: 0.9167\n",
      "8333/8333 [==============================] - 1s 139us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 7s 407us/step - loss: 0.2397 - acc: 0.9089\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 7s 413us/step - loss: 0.2120 - acc: 0.9220\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 7s 441us/step - loss: 0.1995 - acc: 0.9277\n",
      "8333/8333 [==============================] - 1s 147us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "rate = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "loss_train_drop = []\n",
    "acc_train_drop = []\n",
    "loss_val_drop = []\n",
    "acc_val_drop = []\n",
    "for r in rate:\n",
    "    model_drop = Sequential()\n",
    "    model_drop.add(Dense(250,input_shape = (max_num,)))\n",
    "    model_drop.add(Activation('relu'))\n",
    "    model_drop.add(Dropout(r))\n",
    "    model_drop.add(Dense(num_classes))\n",
    "    model_drop.add(Activation('softmax'))\n",
    "    model_drop.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    loss_val_cv = 0\n",
    "    acc_val_cv = 0\n",
    "    loss_train_cv = 0\n",
    "    acc_train_cv = 0\n",
    "    for train_cv_index, val_index in kf.split(X_train):\n",
    "        X_train_cv = X_train[train_cv_index]\n",
    "        y_train_cv = y_train[train_cv_index]\n",
    "        X_val_cv = X_train[val_index]\n",
    "        y_val_cv = y_train[val_index]\n",
    "        hist = model_drop.fit(X_train_cv,y_train_cv,batch_size=200, epochs = 3)\n",
    "        loss_train_cv = loss_train_cv + hist.history.get('loss')[-1]\n",
    "        acc_train_cv = acc_train_cv + hist.history.get('acc')[-1]\n",
    "        score_val_cv = model_drop.evaluate(X_val_cv,y_val_cv, batch_size=200, verbose = 1)\n",
    "        loss_val_cv = loss_val_cv + score_val_cv[0]\n",
    "        acc_val_cv = acc_val_cv + score_val_cv[1]\n",
    "    loss_val_drop.append(loss_val_cv/3)\n",
    "    acc_val_drop.append(acc_val_cv/3)\n",
    "    loss_train_drop.append(loss_train_cv/3)\n",
    "    acc_train_drop.append(acc_train_cv/3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = rate\n",
    "loss_train_drop= pd.Series(loss_train_drop, index = ix)\n",
    "loss_val_drop = pd.Series(loss_val_drop, index = ix)\n",
    "acc_train_drop = pd.Series(acc_train_drop, index = ix)\n",
    "acc_val_drop = pd.Series(acc_val_drop, index = ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEPCAYAAACk43iMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3gVZfr/8XdOekhCD1U63ARESlARLFhwLcvawFUUFfvX7auuZf266ldXd3+o67qVRRbsIqKurr0riEoCAhJuDYjSOwmQnnN+f8wEDiHlhGQySc79uq5cOWfa+eSgzz3zzMwzMaFQCGOMMdEp4HcAY4wx/rEiYIwxUcyKgDHGRDErAsYYE8WsCBhjTBSzImCMMVHMioCpk4j0EZGQiHxYzbzZ7rxO9dzmqyJyRR3LjBeRFTXk2Vufz2vORGSviPTxOcPRIvKPRtjOW/X9b8H4y4qAiVQxICLSu3KCiLQBxvkXyTSioUDPRtjOhEbYhmlCcX4HMC1GBfAccAnwe3fa+cDLwI2VC4nItcDP3eW3AD9V1a9FpDswB+gOfAdkhK2TCTwCdARigT+r6qzDCSkibYG/AiOAEPA6cLuqlovI3cB5QCmwA7hCVTfVNL3KNtcBg1R1szvtM+AuYA/wkJs7BNyvqi/UkfEE4FF3+S9wd8ZEZLz7PewDUoGjgcup/vucDRS5f2cG8Bbwc1Utc7f//4AU92+6Q1XfcI+8JqnqD93PuwKYBPwPcA/QVkT+rarTquRdC3wGHAXcDpS5vxPcz56jqv8rIv92V3lfRM4CgsBfgF5APPCsqv4e06zYkYCpj8eBqWHvLwdmV74RkVOA3wAnq+pw4GngJRGJwWmYF6nqUJxGbbC7ThwwD7hVVbOAk4CbRGTMYWb8M05DPgwYDQx3t3cE8EvgaFUdjdNoHlvT9PANqmo+8CJwqZs5E+gKvAncDTzkZr8SOKW2cCKSADwP3KiqI4H3geSwRY4ELlbVo3COsmr6PnFzTgCGuD/XiUhHnO/zF+42LgeeFJG+NWVS1XXAncDHVQtAmBWqmgm8hFP0L3e/rzHAbSLSKWzdk91tPgHMcr+bY4DTROTC2r4f0/SsCJiIqWo2UCEiWW7jmaaq4X32ZwDPqeo2d/nZQA+gD3AabsFQ1TzgPXedQUB/YJaILAU+xGkURx5mzDOBv6hqSFVLgH+40zYAXwI5IjIdWKqqL9UyvaqZOA0qwDScxi0IzAX+KiJPAVk4e8i1GQaUqeq7AKr6DM7RRKV1qvqd+7q27xNgtqrudf/Ox4Ef4BSGPFX9zF3nK2ABML6OXHX52N1eCJgIZInI73COgmKANuELu12FJwH/5/67LsI5IhjRwBymkVkRMPX1BM4e8VT3dbjKLpFwMThdASH3daXysHXyVXVE5Q/O3uW/OTyBKhkCQLzbYJ8EXIFzpPCwiPyxpulVN6qqHwNxInIMMAWY5U7/J07D/jZOI7xMRJLqyBhT5X152OvwE961fZ9V1wvgdBlVt06A6v8NEurIGW4v7G/clwCjgBzgZpzuoap/U6w7bWyVf1frDmpmrAiY+noSmAz8GKd7ItwbwEUi0hlARKbhNKx57rxr3em9gJPddRQoEpHKrpYjgBU4e9WH403gpyISIyKJ7me+LSLD3e3mqur9wMPA0TVNr2HbM3H68pe53R2IyEJgpLuXfi3QDqerqCbLgBi3zxwR+RHQvoZla/s+AX4sIolu0bkceAX4FBjsFitEZChwIvABsA04UkSSRCQe53xApXIOFJfaDATScc4zvIJzhJGI0+iDU4jiVbUAZ+//126OdjhHJOdE8BmmCVkRMPWiqhuAXOAbVd1ZZd7bOI3oeyLyFU7D9EN3b/snwBARyQUeA5a665TiNAxXi8gynD75/1XVBXVEaeNeWhn+MwznfEMGsNz9UeA+Vf0Sp+tmsYgsxum//3VN02v4zDk43Rkzw6b9BrhHRJbgNLR3q+paERntdoNU/f7KgHM50E1yPrC1ug+r4/sEKMTpplnu/v63qm7HKdKPishynEI9TVW/xvluPwRWAR8Bi8M+bhHQT0Tm1/C3V1oGvAqscv8tJwIrgQHu/OeBD0XkSJwjpjFujs+AZ1T1qTq2b5pYjA0lbUzL414dtEJVp/udxbRsdiRgjDFRzI4EjDEmitmRgDHGRDErAsYYE8WsCBhjTBRrUWMHZWdn2wkMY4w5DFlZWVVv6ANaWBEAyMo63HuIIDc3l8zMzEZM0zgsV/1YrvqxXPXTGnNlZ2fXOM+6g4wxJopZETDGmChmRcAYY6KYFQFjjIliVgSMMSaKWREwxpgoZkXAGGOimBUBY4xpzkIheOpCOmjVZzg1DisCjWD+/PlMn+7/sO7jxo3zO4IxprFtXALfvEkoUJ+ngUauxd0xXJsXstczd/G6GucXFhaS8tHuem3zwtFHcEFWz4ZGM8aYw5MzB+KSye/9g1qfW3q4WlUR8NusWbP473//S1xcHKNHj+bmm28mOzubP/zhD8TFxZGens706dPZtm0bt912G3FxccTGxnLNNddUu72ysjLOOussXn75ZVJSUpg5cyZxcXGMHTuWBx54gGAwSEFBAXfccQejRo1q4r/WGOO5kr2wfB4MPZdgQponH9GqisAFWT1r3Wv3ckyQ7777js8++4xnn32WuLg4fvazn/H+++/z+eefM2HCBK666iree+89CgoKWLhwIUOHDuXWW29l8eLF5OfnV7vN+Ph4Tj/9dN566y3OPfdcXnvtNR577DE+/fRTbrnlFkSEV155hfnz51sRMKY1+upFKN0Loy53nijtATsn0Ehyc3MZPnw48fHxxMTEMHr0aL755huuv/56du7cyeWXX84bb7xBXFwckyZNon379lx99dU89dRTxMbG1rjdyZMn89JLL7Fs2TL69OlD+/btycjI4G9/+xu33HILb775JuXl5U34lxpjmkzOHOgk0GuMZx9hRaCRZGZmsmzZMsrLywmFQnzxxRf07duXV155hfPOO48nnniCgQMHMnfuXN59912ysrKYM2cOZ5xxBvPnz69xu3369CEUCjFz5kwmT54MwH333cfPf/5z/vCHPzBo0CDsEaHGtEJbVsL6L2DUZRBT7SjQjaJVdQf5qXfv3owaNYqLL76YYDBIVlYWp512GsuWLePWW28lJSWF+Ph47rnnHkKhEDfffDOPPvoogUCAiy66qNZtT5o0iUceeYQxY5y9gR/96EfccMMNdOzYka5du7Jr166m+BONMU0pZw4E4mF47e1DQ1kRaATnn3/+/tfTpk07aN7w4cOr3dN/7rnn9r/Ozc2tdfsTJ05k4sSJB31G1c8BWLBgQcSZjTHNWFkxfPksZP4Q2nTy9KOsCDQDZWVlTJ069ZDpffv25Z577vEhkTHGV7mvQPFu54Swx6wINAPx8fE88cQTfscwxjQXOXOgXW/oe5LnH2Unho0xpjnZsRrWfuycEA5430RbETDGmOYkZw7ExMKIS5rk46wIGGNMc1FRBkufhkE/gPRuTfKRVgSMMaa50Ndh37YmOSFcyYpAI/ByFNGNGzfy3nvvRbz8fffdx8aNGz3JYozxWM4cSOsOA05rso9sXVcHLX0GljxZ4+xehftgUZv6bXPkpTDi4gYGO3yLFi1izZo1nHLKKREt/9vf/tbjRMYYT+z+HvLehRNvhtima5pbVxHwWWOPIlpRUcGMGTMoLi5m5MiRzJ49m/bt21NQUMCjjz7KHXfcwZ49e9i1axeTJ09mypQpTJ06lbvuuovXXnuN9evXs2PHDjZu3Mhtt93GCSec0MTfiDEmYkuecn6PvLRJP7Z1FYERF9e61/59CxtFNDY2lmuvvZY1a9Zw6qmnMnv2bCZOnMiECRP46quvOPvsszn99NPZsmULU6dOZcqUKQetn5CQwMyZM1mwYAGzZs2yImBMcxWscHox+p8M7Xs36UfbOYFG4tUoolX17dsXgE6dOvHOO+9w00038fe//73akUQrC17Xrl0pLS1tnD/UGNP48t6FgvVNekK4khWBRuLVKKKBQIBgMLj/fYw7muCsWbMYMWIE06dP54wzzqh2JNEYD0ceNMY0opw5kNIJ5Kwm/+jW1R3kI69GER00aBB///vfGTp06EHTTz75ZO666y5eeeUV2rVrR2xsrO3tG9MS7dnsXBp63E8gzpvnCNcqFAq1mJ/FixeHGmLlypUNWt8rlqt+LFf9WK76afJcHz0YCv0uPRTa9nWtizUkl9t2Vtuu2pFAM2CjiBoTpYJByHkceo+DTgN9iWBFoBmwUUSNiVJrP4Zd38L423yLYCeGjTHGLzlzIKktDPmRbxGsCBhjjB/27XAeHnPURRCf7FsMT7qDRCQA/A0YDpQAV6tqXtj8i4FfAhXAMuAGd1aN6xhjTKuy7DmoKHWeG+Ajr44EzgWSVPU44FbgwcoZIpIM3AucrKpjgbbAD2tbxxhjWpVQyOkK6pEFXY/0NYpXReB44A0AVV0EjA6bVwKMVdVC930cUFzHOsYY03qs+xy2rfLlDuGqvLo6KB0IHxCnQkTiVLVcVYPAFgAR+RmQCrwNXFjTOuEbzs3NPexQxcXFDVrfK5arfixX/Viu+mmKXN0+e4S0uBS+iT+SUISf5VUur4pAAZAW9j4Q3pi75wz+CAwCLlDVkIjUuk6lhgwAl+vhAHINYbnqx3LVj+WqH89zFefDC+/BURcy+KisJsmVnZ1d4zyvuoMWAGcBiMgYYHmV+f8EkoBzw7qF6lrHGGNavuXzoLyoWXQFgXdHAi8CE0RkIRADTBORKThdP4uBq4CPgfdEBOCR6tbxKJsxxvgnZw50ORJ6jPI7CeBREXD7/a+vMnlV2OuajkCqrmOMMa3HxqWw6Us48/9BMxnl124WM8aYppIzB+KS4KjJfifZz4qAMcY0hdJ9zvmAIedCcnu/0+xnRcAYY5rCVy9BSYHvdwhXZUXAGGOaQs4c6DgQeo/1O8lBrAgYY4zXtubCus+co4BmckK4khUBY4zxWs7jEIiHEVP8TnIIKwLGGOOl8hL48hkYfDa06eR3mkNYETDGGC/lvgJFu5rdCeFKVgSMMcZLOXOgXS/od/JhbyIUChEMhRox1AFWBIwxxis718C3H8HIyyBweM3tdzv2ceqDH/Lcst2NHM5hD5o3xhiv5DwOMQEYeclhrf7Nlj1cMvMzyiqCjDmiXSOHc1gRMMYYL1SUwdKnYeAPIL17vVdfsSGfy2Z9TlwghueuO46Knes9CGndQcYY442v34S9Ww7rhHD2dzu5+F+LSI6PZe51xzGoS1rdKx0mOxIwxhgv5MyBtG4w8PR6rbYwbztXP76YLulJPHX1sXRvl+xRQIcdCRhjTGPLXw9578CISyA28n3td3O3cMXsLziifQrPXTfG8wIAdiRgjDGNb8mTEArCqKkRr/Lqso388tmlDOmezpxpx9C+TYKHAQ+wImCMMY0pWOEUgX4nQ/s+Ea0yd/E6bn1hGaN7d+CxK0aTlhTvbcYw1h1kjDGNafX7kL8u4hPCcxau5TfzljFuQCfmXHlMkxYAsCMBY4xpXDmzIaWjM1ZQHf72QR5/fEM5fUgXHp0yksS4WO/zVWFFwBhjGsveraCvw7HXQ1xijYuFQiGmv6X89f3VnDOiO9MnDyc+1p+OGSsCxhjTWJY+DcFyGHV5jYsEgyHueXUlsxeu5eJjjuDec4cRG/DvGQNWBIwxpjGEQs4wEb3GQudB1S5SEQxx2/xlzF28nquO78sdZ2cS4/NDZqwIGGNMY1j7CexcDSfeXO3ssoogv3puKa8u28TPTx3Ir04b6HsBACsCxhjTOHLmQGJbGHLOIbOKyyr46dM5vJO7ldvOHMx1J/X3IWD1IioCItINaA+UA7cAj6rqUi+DGWNMi1G4E1b+x7ksNCHl4Fml5Vzz+GIW5O3g/84ZytTj+viTsQaRno5+HOgC/B54G3jYs0TGGNPSLJsLFSWQdfAJ4YLiMi577HM+Xb2D6ZOHN7sCAJEXgTjgI6Cdqj4LNP3FrMYY0xyFQk5XUPdR0HXY/sk795Uy5V+L+HL9bv4yZRSTsnr6GLJmkRaBBOAh4CMRORk7l2CMMY71i2HryoPuEN5aUMyP//kp32zZy4ypozlrWDcfA9Yu0iJwBaDAH4DOwKVeBTLGmBYlZzbEt4FhkwBYv6uQyf/8lA27i/j3tKM5eXCGv/nqEGkR2Aj8B2gHCFDhWSJjjGkpigtgxXw48nxITGPNtr1c+I9P2bWvlCevPpax/Tv5nbBOkRaBp4BRwP8DyoAZniUyxpiWYsULUFYIWVewanMBF/5zESXlQZ699jhG9Wrvd7qIRFoE2gOvAD1U9QGg5kExjDEmWuTMgYyhLAv156IZi/Y/D3hI93S/k0WsPieGbwRyRGQIkOpdJGOMaQE2LYONS/iuzwVMmfk5aUlxPH/9cQzIaFnNY6RF4EYgA7gXOBm4wbNExhjTEuTMIRhI4MJPe9ElPZHnrxvLER1S6l6vmYnoUk9VXSgi7YFrga9V9XNvY7VuO/aW8OmaHSzI28GKDfn0Sw9xbdt8hnZv63c0Y0wkSgspW/ocr5UfQ8dOXXn8qmPolNoye8kjHTbifmAg8AlwuYicqKo31rJ8APgbMBwoAa5W1bwqy6Tg3H18laqucqctAfLdRb5V1Wn1/Huapb0l5Xz+7Q4W5u1gweod5G4qACAtMY7B3dL4r+7i5dxPGNw1jUlZPTl3ZI8W+x+UMdEg+/XZZJXt4YsOE3nmmjG0TWnap4E1pkhv+jpRVccBiMgjwKI6lj8XSFLV40RkDPAgsH9UJREZDfwD6Bk2LQlAVcdHnL6ZKimvYMn3u1mYt50Fq3fw5brdlAdDJMQFyOrVnptOH8TYAZ04qkdb4mIDfL50BVqUyrzs9dz731weeH0V4yWDSVk9OWVwBglx9hRQY5qLpz/7noHZs9kU34Nbr7+K1CZ+HGRji7QIxItIQFWDQAwQqmP544E3AFR1kdvoh0sEzgOeCJs2HEgRkbfcXLeral3FplmoCIb4amM+C1fvYEHedr5Yu5PisiCBGBjWsx3XntiPcQM6kdW7PUnxh464kZYYy9QRfZh6XB++2bKHeTnreTFnA+/kbqF9SjznjOjBpKyeDO2e3iyGnjUmWs38eA3PvPYO7yYqZSfdRXwLLwAQeRF4DlggIouAY933tUnnQLcOQIWIxKlqOYCqLgAQkfB1CoHpwEycrqfXRUQq12lOQqEQq7ftY+Hq7SzI286iNTvJLyoDYGBGKhcd3Yux/TtybL+OtE2u338kA7ukcduZmdx8uvBx3nbmZa/n6c++Z/bCtfu7i84Z0YPOadZdZExTCYVCPPpeHg+9/TUzu35OqCCO+FGX+B2rUcSEQnXt1DtE5EhgMLBKVVfUsexDwCJVneu+X6+qh4yeJCIfANer6ioRSQQCqlrkzvscuEBV11Uun52dHUpJOfyz78XFxSQlJR3Wutv2lbN0UxFfbipi6aYidhQ5N01ntIljRLdkRnRLZni3JDok139Ypbpy7Smp4MNv9/HO6j3o9hICMXB0jxROG5DKMT3bkBDrzdFBQ74vL1mu+rFc9VM1VygUYlb2TuZ9lc8Z/RL5y/YrKcwYxYZx9/uaqz4KCwvJysqqtqGotcVyTwhXrRKjRARVvb2WVRcAE4G57jmB5RHkvBIYBtwgIt1xjiY2VV0oMzMzgk1VLzc3N+L1d+0rda/g2c7C1Tv4dvs+ADq0SeC4gRmM69+JcQM60qtDSoO7aCLJdcwIuBnI27qHedkbmJ+znvs+2Eq7lHjOGd6dSVlHcGSPxu0uqs/31ZQsV/1YrvoJzxUMhrjzPyuY91U+U8f05u7+XxN4IZ/08T8lfUDTZm/I95WdnV3jvLp2W1fVNlNEElW1pJpZLwITRGQhzjmEaSIyBUhV1ZqGnHgMmC0in+AUniubsitoX0k5n6/dyaduv/7KTQWEQtAmIZZj+3XkkmN7MW5AJ6RLGgEfHwo9ICONW88czE2nD+ITt7vomS/WMefT75AubnfRyO5kpDW/PSxjWpLyiiC/eWEZ83M2cN1J/bj1jMHEPPFbaNsL+p3id7xGU2sRUNU5daz/OnDIt+GeQL6+yuRDCkr4lUCqWgpMqePzGk1peZCl63a7e/rbWbpuN2UVIRJiA4zs1Y5fnTaIcQM6clTPdsTHNr+rc+JiA4yXDMZLBvmFZby6fCPzstdz32u5PPDGKk4a1JlJWT05NTODxDh7/IMx9VFaHuQXzy7h9RWbuXHCIH56ygBidq2FNR/A+Nsh0PzahMPV0OcCtJhLVYLBEHk7Svj4o9UsyNvBF2t3UlhaQUwMDOvRlquO78fY/h05uk8HkhNaVqPZNiWeS47tzSXH9iZv615eyFnP/Jz1vLdqK22T4zlnRHcmZfVkWI+2dnWRMXUoKQ9y7ROL+UC3ccfZmVx9Qj9nxpInICYAI1vXSPoNLQKRnVX2WX5hGWf9+WM27C4CoH/nNkzK6snY/p04rl/HFn2jR1UDMlK55YzB3HS67O8ueu6LdTz+6XcM6pLKBaN6ct7IHmSkW3eRMVXtLSnnznc3s3xLMfefP4yLj+nlzKgohyVPwYAJ0LaHvyEbWVQ8IaxNYiwXH3MEFO5i0glH0bVt628AYwMxnDSoMycN6kx+URn/XbaJednruP/1Vfxhf3fREZyamVHtvQvGRIPte0tYubGA3E0FrNxUwOK1u9iUX8yffjyCc0aENfbfvAV7N0PWQ/6F9UhUdAfFxQb46SkDyc3NjYoCUFXb5HimHNuLKcf2YvW2vbyQvZ4Xl2zgJ0/n0DY5nonDuzEp6wiG97TuItM6VQRDfLt9Hys3uQ3+RqfR37bnwHUt3dsmkdktnetHtz24AIAzZHRqVxj4gyZO7r1Ixw7qoqpbqpm1spHzGI/175zKb84YzI2nCwtXO91Fzy9ez5OLvmdARiqTspzuoi7WXWRaqL0l5ejmAw39yk170M0FFJcFAYiPjWFARhonDuxMZrc0hnRPZ0i3dNqlJADOpZgHyd/gHAmM+yXEtr7Ok0j/ohdEZBvOZZyvuVf/oKo/8SyZ8VRsIIYTBnbmhIGdKSh2uoteyF7PA6+v4o9vrGLcgE6kB0rpunoliXEBEuICJMbFkhgXIDE+QEJsgMR49707L8F9nRR/8PvK17E+XlprWp9QKMSm/OKDunNyNxWwdkfh/mXapcST2TWdS47tTWY3p7EfkJFav/G4lj4FoSCMmurBX+G/SIeSPl5EMnFu6LpDRN4FHlPVNZ6mM00iPSmei4/pxcXH9GLNtr3Mz9nAa8s38eWeIoJrCykpr6CsouHXAMTHxhxSPKoWl8S4WHeZQ4tLYlwsifEBCnbms2LfOtokxpGSEEtKQuXv2IOmWdFpPUrLg+Rt3XtQd07u5gJ2F5btX6ZPxxQyu6VzwaieDOmeTma3dLq1TWpYF2cwCDlPQN+ToEO/RvhLmp/6HNtsBNYAWcCRwCMiskRV7/QkmfFFv86p3PQD4aYfyEF3KFYEQ5SWByktD1JSXkGJ+7u4LEhpRZCSsgPTnWXc92XBsGkVB02vul5JWZCCovKD3jvLOO/Lg2GF6LMddf4tiXEB2iTGkRwfS5vE8GIR5753XyfEkuxOc5Y9uLgceN8yiksoFCIUgmAoRND93ZLsLix1unE2FpC7aQ8rNxWQt3XP/h2RpPgA0jWdM4/sxhC3O0e6ppOa6EFXzZr3If97mHBX42+7mYj0nMBcnIb/SeBSVd3oTl8MWBGIArGBGJITYt17KPy5pLYiGKKkvIIvV6yiZ59+7Cstp7C0gsKSCvaVllNU6vwuLKlwppeWV7vMrsIiikrL2VdaQWFJOYVlFdSnnawsLuGFISUhlqLCQpI/yd/f+IbCGuED70MEg860Aw31oY12MFjDuqFD1636WdX9LQmx3+0/0go/6grvvnOmHzhKS9r/OvagI7OkGrdz6LTEuABxNdxsGQyFWLt930FdOSs3FrAxv3j/MhlpiWR2S2e8dN7fndO3U5umK8Q5cyC5Awz+YdN8ng8iLZ3/UtW3q5l+fGOGMaY2sYEYUhLiaJcc26iP8QuFQhSXBQ8qJPtKKva/jrS4lJQHiasIEhMTQyAGAoEAgZgYYmIgUDktJubA/JgYAgHc92HTqp1/YF6t24s5eHsxMbBpy1bS2nU86Air8iiuctruojJKyir2H8UVlx04amtoV2BcIOaQAhMfG2D9zn0UlX8LOP+2/Tu34ei+HRjSzenKyeyW7u9ouXu3warX4NjrIK71jtobaREoFJGlQBdgA3CNqi5R1eI61jOm2YuJCT/KOXzNd0C0cjIzBx/2+pVdgZUFY3+BKDu0azC8CzD8dXhRqVx3cIcAxw/tzZBubRnYJbX53a/y5dMQLINRl/mdxFORFoE/A1NUdaU7pPQMYKx3sYwxzcXBXYGNxymavRp1m40mFIKcx+GIMdBZ6l6+BYv0OqndqroSwH2WQGEdyxtjTMv13ULYkQdZl/udxHORHglsFZGZwHs4VwcFRORagFqGhjbGmJYpZw4ktoUh5/qdxHORFoHKYaAHAAXAh0A3WsgAcsYYE6lAaQGsfNkZLTSh8S5AaK4ivVnsbhE5GxjqvNWXvY1ljDH+aLv2DSgvbvUnhCtFdE7AfczkNKAUuFxEpnuayhhj/BAK0W7Ny9BtBHQb7neaJhFpd9CJqjoOQEQeARZ5F8kYY3yyIYek/NVwwsN+J2kykV4dFC8ilcvGYOcCjDGtUc5sgrFJcOQkv5M0mUiPBJ4DFojIIuBY4FnvIhljjA/WZ8PSZ8jvcxbtk9L9TtNkIi0CrwJvAoNxRg9d4V0kY4xpYoU74fnLIb0bW4+6gfZ+52lCkRaBx1T1eMAaf2NM6xIMwvxrYO8WuPJNggXJfidqUpEWgX0i8jCgQOUDZewmMWNMy/fxg5D3Dpz9EPQYBQW5da/TikRaBBa6v7u4v+3EsDGm5Vv9Prx/Hwy7EEZf6XcaX0RaBCpU9d7KN+59A8YY03IVbIQXrobOg2Hin5xxt6NQrUVARK4CrgYyReQsd3IASABu8zibMcZ4o6IMnkPOvREAABaeSURBVJ8GZUVw4eOQ0MbvRL6p60jgSeBd4HbgPndaENjqZShjjPHUO3fBukVwwWPQeZDfaXxV681iqlqiqmuB63HOB/QG+uLcK2CMMS3Pyv/Ap3+BY66FYdFzU1hNIj0nMA/IANa570PAR54kMsYYr+xYDS//BHpkwen31r18FIi0CHRVVXuSmDGm5SorgrmXQSAWJs9u1c8Nro9Ixw5aJSLdPU1ijDFeeu0m2PIVnD8T2jXTx1r6INIjgeOB70VkO05XUEhVrSgYY1qGnCdgyZNw4m9g4Gl+p2lWIn2oTHSfPjfGtFyblztHAX1PgvG3+p2m2YmoCIjIUOAfQDvgKWCFqr7qZTBjjGmw4nznPEBye+dy0ECs34manUjPCfwZ58li24HHgLu8CmSMMY0iFIKXboBd3zknglM7+52oWYq0CKCqeTjnArYBe7yLZIwxjeDTv8KqV2HCPdBrjN9pmq1ITwzvFJHrgDYichGwu7aF3aeQ/Q0YDpQAV7tFJHyZFOBt4CpVXRXJOsYYE5HvPoW374TMiXDcT/xO06xFeiRwFc6dwtuB0e772pwLJKnqccCtwIPhM0VkNM7NZv0jXccYYyKydxvMmwbte8M5f43ageEiFenVQQU4DfNBRORFVT2vmlWOB95w113kNvrhEoHzgCfqsY4xxtQuWAEvXAVFu+CS5yGprd+Jmr1Iu4Nq0q6G6elAftj7ChGJU9VyAFVdACAiEa9TKTf38B/4UFxc3KD1vWK56sdy1U805eq8/J90+vZDNh59B/m74mBX/bcfTd8XNLwI1PRwmQIgLex9oGpjfrjrZGZm1i9hmNzc3Aat7xXLVT+Wq36iJtc3b8PKf8PIS+l+9s0c7t2srfH7ys7OrnFexFcH1dMC4CwAERkDLPdoHWOMgd3fO88J7jIMzprud5oWpaFHAjV5EZggIguBGGCaiEwBUmt5NvEh63iUzRjTmpSXwPNXOOcDLpwD8dH1oPiGamgR2FXdRFUN4jyDINyqapYbX8c6xhhTu7fugA3Z8OMnoWP/upc3B6nPsBHpOE8V+z3we1V9V1Uv8DKcMcbUavk8+HwGHPdT554AU2+RnhP4B84NXHcAvwV+51kiY4yJxDaF//wcjhgDp93ld5oWK9IiUAZ8BSSo6iK8O5dgjDF1K9nrDAwXnwyT/w2x8X4narEibcxDwNPAayJyIbDPu0jGGFOLUAhe/RVs/xqmvgjp9miThoi0CPwYOAZ4HTjJfW+MMU1v8SxYPhdOuQP6jfc7TYsXaXdQPLAWGAhMBezZbMaYprchB964FQZMgONv9DtNqxBpEXgc6IJzZdDbwMOeJTLGmOoU7oS5l0NqFzh/BgS8utc1ukT6LcbhjPrZTlWfBezxPMaYphMMwkv/A3s2weQ5kNLB70StRqTnBBKAh4CPROTkeqxnjDENt+Bh+PoNZ0iInll+p2lVIj0SuAJQ4AGgM3CpV4GMMeYg334E790LR14AR1/td5pWJ9IisAZnPJ+HgW7Aes8SGWNMpYJNMO9K6DgQJv7ZHhDjgUiLwAygH85J4T7ATK8CGWMMABXlTgEo3QcXPg6JqX4napUi7dsfqKonuq9fckf6NMYY77x3D3y/EM6fCRmD/U7TakV6JJDkPhgeEUnGrg4yxnhp1X9hwSMw+io4arLfaVq1SI8E/gR8KSIrgCHYAHLGGK/sXAMv/g90Hwln3O93mlYv0iKwCTgW57zAt6q6w7tIxpioVVbkDAwXE+PcDxCX6HeiVi/SInC3e05gp5dhjDFR7vVbYPNymDIX2vf2O01UiHgUURF5EedegSCAqt7uWSpjTPRZ+jTkzIETboRBP/A7TdSI9MTw68AHQC5wObDdq0DGmCi05St49dfQ5wQYb/uXTSnSInA+8LaqzgFOAM71LpIxJqoUF8BzUyGpLVzwGMTaqDRNKdIiUK6qKwFUdQ1ul5AxxjRIKAT/+RnsWguTZkFaF78TRZ1IS+53IvJ74FOch8ts8C6SMSZqfPYPWPkSTLgH+ozzO01UivRIYBqwFTgL2AZc6VkiY0xUSN6+HN66Awb/EMb+3O84USuiIwFVLca5YcwYYxpu33Z6LPwttO0J5/zVBobzkT2axxjTtHZ+C89dSmzJbmdguOR2fieKanYa3hjTNIp2wUfT4fMZEIhj0zG/pUe34X6ninpWBIwx3qoogy8egw8fgKLdMOISOOUOCjbspoff2YwVAWOMR0Ih0Nfgrf+Fnauh70lw+r3Q7Shn/obd/uYzgBUBY4wXNi6BN++A7z6BToOcsYAGnm4ngJshKwLGmMaTvx7e/T9Y9iykdHQeDJ91BcTG+53M1MCKgDGm4Ur2OA+BWfio0w007pdwwq+doSBMs2ZFwBhz+IIVsOQJeO8+2LcVjpwEp95pw0C3IFYEjDGHJ+8d56Tv1pVwxLFw8TPQc7TfqUw9WREwxtTP1lxnuIe8d6B9H+cJYEPOsZO+LZQVAWNMZPZuhffvg5zHITENTr8PjrnGHgHZwlkRMMbUrqwIPv0LfPInKC+GY66Dk34DKR38TmYagSdFQEQCwN+A4UAJcLWq5oXNnwjcCZQDs1T1X+70JUC+u9i3qjrNi3zGmAgEg7B8Lrx7DxRscEb7PO1u6DTA72SmEXl1JHAukKSqx4nIGOBB4BwAEYkHHgaOBvYBC0TkFWA3gKqO9yiTMSZSaxfAm7fDpqXQbQScPwP6HO93KuMBr4rA8cAbAKq6SETCLxnIBPJUdReAiHyC88jK74EUEXnLzXW7qi7yKJ8xpjo7VsPbd8KqVyG9B5w3A4ZNhoANONxaeVUE0jnQrQNQISJxqlpezbw9QFugEJgOzAQGAq+LiLjr7Jebm3vYoYqLixu0vlcsV/1YrvqJJFdsST6dvnqM9nkvEIxNZMew69k56CJCcUmg6lsuP0RbLq+KQAGQFvY+ENaYV52XhtMV9DXOEUII+FpEdgDdgHXhG87MzDzsULm5uQ1a3yuWq34sV/3Umqu8BD7/F3z0R+eu31GXEXvyb8lIzSDDz1w+ao25srOza5znVRFYAEwE5rrnBJaHzcsFBopIB2AvcCLOEcCVwDDgBhHpjnPEsMmjfMZEt1AIVr4M7/zOecj7gNNgwv9BlyF+JzNNzKsi8CIwQUQWAjHANBGZAqSq6gwR+TXwJs6TzWap6gYReQyY7Z4jCAFXVu0KMsY0gvWL4c3fwrpFkDEELp0PA071O5XxiSdFQFWDwPVVJq8Km/8K8EqVdUqBKV7kMcYAu7+Hd+6GFfOgTQZMfARGToVArN/JjI/sZjFjWrlA6V54+3ew6O8QE4ATb4Zxv3Du+jVRz4qAMa1VcQF8+Qz937sfSnbB8IvhlP+FtvZQR3OAFQFjWpNQCNZ/Adlz4Kv5UFZISeeRxJ33InQf6Xc60wxZETCmNSjcCV8+6wzuti0X4tvAsEkw6nK+L0ghs7td9WOqZ0XAmJYqGIS1HzsNf+5/oKIUemQ5J3yPvOBAn38zvPHJNB9WBIxpafZsgaVPOY3/rm+dRzhmXQGjLoeuR/qdzrQwVgSMaQmCFZD3LuTMAX0dQhXQexyMvw2G/Ajik/1OaFooKwLGNGe7v4clTzo/BRsgpRMc9xNnr9+GdDaNwIqAMc1NRRnoa053T967zrT+p8AZ98OgMyEuwd98plWxImBMc7E9D5Y8Dkufhn3bnKGcT/oNjLgE2vf2O51ppawIGOOnsiLIfcW5rv+7TyAmFuRMGHWZM6ibDelgPGZFwBg/bPnKafiXPQfFu6F9Hzj1TmevP62r3+lMFLEiYExTKdkLK15w+vo3LIbYBMic6Jzk7XOCPb3L+MKKgDFeCoVgQ45zaeeKF6B0L3QeDD+4H4ZfBCkd/E5oopwVAWO8ULQLlj3vNP5bVkB8Cgw9H7Iuh55HQ0yM3wmNAawIGNN4QiFYu8Bp+Fe+DOXF0G0E/PBhOHISJKX7ndCYQ1gRMOZwhULODVxbc2HjUvotfhz2fA+J6TDyUucKn27D/U5pTK2sCBgTicKdsHUlbFnp/N6a6/yU5O9fpKLTUXDqbTDkXEhI8TGsMZGzImBMuNJ9sG2V08Dvb/BXwt4tB5ZJagsZQ+GoyZCR6TynNyOT79ZuJjMz07/sxhwGKwImOlWUwY68sL37XOf1rrVAyFkmLhk6i3PTVkam+zPUuY6/2hO7m5vwDzCmcVgRMK1bMAj537t79l8d6MbZ/jUEy5xlYmKh4wCn/37ElAN79+372B27ptWzImBaj71bD+2337bKuTa/UtteTiM/cAJ0Geq87jQI4hL9y22Mj6wImBYnULYP1n1+aINfuP3AQikdnb35EZdAlyHO686D7TJNY6qwImCaj/JS2LfVeXLW3i2wd3PYa/dnz2akYMOBdeLbOHvzcuaBPfuMIZCa4d/fYUwLYkXAeCsUgpICp6tmz+aDGnP2bj24oS/aWf02UjpBahdI6wKdBrE12JaMI8c7DX7bXjbmjjENYEXAHJ6Kcqf7Jbwx37vFbdA3hzX6W6G86ND1YxMgtauzx96xP/Qee6ChTw3/yYDY+INW3ZGbS4bYpZjGNAYrAsYRrICSPc5ee3EBFOeTtm4pFHxUfUNfuB1CwUO3k9TuQGN+xDEHGvO0rmGvuzjL2fg5xvjOikBrUFHmNNwl+e5vtyEPb9TD55XsqbJcwcFX0Lh6Vr4IxEGbDGevPL0HdB9VZa/d3aNP7QLxSU36pxtjGsaKgN/Kiokt2gHbvznQWFfXSO9vwKuZVl5c9+fEJTlj2iSlH/id1vXQaYnpkJgGSems2bqXfkeNheQO1u9uTCtlRaAxhELOYwKLdjpDCFf9KQyfvtv97U4rL2ZQXdtPSD24kU7p4NzI5DbWJLY9pAE/sHxbZ9phPJy8pDQX2nQ6nG/EGNNCWBEIFwo5Y8cc0pBXbdx3V2nYd0FFSc3bjU10Gu7k9s5Ph76QPMp9345Nu4vo1lvcRjvt0L1yu2vVGOOR6CgCoRCs+YB2eQthW2L1e+v7G/PSmrcTl3ygIU9uD50GHPw+ub3TdVJ1Wh0jSu7OzaWbDTxmjPFBdBSBfdvgyQvoFqpw3senhDXY7ZxhAyob7JRqGvHK5eKT/f07jDGmkUVHEUjNgBtX8c3XysBhR9sVLMYY44qOIgCQmkF58g4rAMYYE8aTIiAiAeBvwHCgBLhaVfPC5k8E7gTKgVmq+q+61jHGGNP4vLr4+1wgSVWPA24FHqycISLxwMPA6cBJwLUi0rW2dYwxxnjDqyJwPPAGgKouAkaHzcsE8lR1l6qWAp8AJ9SxjjHGGA94VQTSgfyw9xUiElfDvD1A2zrWMcYY4wGvGtkCIC3sfUBVy2uYlwbsrmOd/XJzcw87VHFxcYPW94rlqh/LVT+Wq36iLZdXRWABMBGYKyJjgOVh83KBgSLSAdgLnAhMx3m6d03r7JfZgJuqcnNzG7S+VyxX/Viu+rFc9dMac2VnZ9c4z6si8CIwQUQWAjHANBGZAqSq6gwR+TXwJk531CxV3SAih6zjUTZjjDGumFAo5HeGiGVnZ7ecsMYY04xkZWVV+wCPFlUEjDHGNC4bJN4YY6KYFQFjjIlire46/EiGnxCRFOBt4CpVXdUcconIxcAvgQpgGXCDqlbzEN8mz3UBzh3cIWCGqs70OlMkucKWmwHsVNVbm0Mu96KHq4Bt7qTrVFWbQa6jgYdwLrrYDFyqqhE8ks67XO5IAc+GLT4CuFVV/+FnLnf+JcCNOP8/zlLVv3udKcJcU4Gbce6pmq2qjzX0M1vjkUCtw0+IyGjgI6B/c8klIsnAvcDJqjoW5+a5HzaDXLHAA8BpwHHAzSLSVI8aq3MYERG5DhjWRHkizTUKuExVx7s/nheAunKJSAzwL2Caqlbemd/b71yqurnyewJuA3LcnL7mck3H+e9+HHCjiLT3O5f7/969wHicIXcuEZE+Df3A1lgE6hp+IhE4D2iSI4AIc5UAY1W10H0fB3i+l1ZXLlWtADJVNR/oiLMXeegT6Zs4F4CIHAeMAf7ZRHkiygVkAbeJyCciclszyTUI2AH8UkQ+BDo0YXGqczgYt0g9CvyP+99cc8i1DGdnLAnnv/umuoKmtlz9gKWqutPtJfgC5/+BBmmNRaDW4SdUdYGqrmv6WDXnUtWgqm4BEJGfAak43VW+5nKzlYvI+cCXOEdQZX7nEpFuwF3AT5ooS0S5XM8C1wOnAMeLSFMd0dWWqxMwFqeb4TTgVBE5tRnkqjQR+KoJCxPUnWsFkA18BbyqqrubQa5vgKEi0sXt0j4VaNPQD2yNRSCi4Sd8UGsuEQmIyHRgAnCBqjbVnked35eqzgd6AAnAZc0g12Schu01nEPmKSJyhd+53D3aP6nqdndwxP8CI/3OhXMUkKeqK1W1DGdPM6sZ5Kp0KTCjifJUqu3f8SjgbKAv0AfIEJHJfudS1V3Ar4AXgFk43WfbG/qBrbEILADOAqht+Akf1JXrnziHnueGdQv5mktE0kXkQxFJdA8/9wGen6yuK5eq/llVs9y+5AeAp1V1tt+5cPbiVohIqlsQTsHZm/Q71xogVUQGuO9PwNnD9TtXpSxgYRPlqVRbrnygCChyu6e2Ak11TqC2/x/jcLp/TsTZGRvsLt8gre5msbCz60dxYPiJUbhDVoQt9wFwvQ9XBx2SC1js/nzMgb7HR1T1RT9zuUN8XItztUsZTj/pz5qi37Ye/45XAIN9uDqopu9rKvBznPM876rq75pJrlNwCmYMsFBVf9FMcnUG3lbVEU2Rpx65rgeuBEqB1cA17tGd37l+h3PyuBh4UFXnNfQzW10RMMYYE7nW2B1kjDEmQlYEjDEmilkRMMaYKGZFwBhjopgVAWOMiWJWBEyrJyJJIrK2CT/vPBHp3sBtdHCfxmeMp6wIGNP4foFz41hDHAX8qBGyGFMru0/AtEoikgo8hXOnZx7O3btrcYZ4bo8zLMBMnNFkY4GHVPU59ybCVTh3Y8YAP1bVzSLyIM7gXuDcofyIiMwGnlXVN0TkDOAi4Hn3c78Gjq/uBiMRuQtnLJ9UnBvxLsMZKCwNyFXVaSLyNs5wwncAr+MMq5CEc5PQtT6Nf2VaITsSMK3VFcAKVT2Rg0cafVpVTwOuAba7Q3efBtwbNkz2QndIiueA291B4Pri3LJ/PM5YRdUOYa2q/wWW4gwnXdsdprnuZ28AdqnqBJzCMEZEegD3Ae+5d0dPB/6sqie7rx+o53dhTI2sCJjWaijwOYCqfsaB0U8rR6rMxBkVFVXdA6zkwDMm3nN/LwTEXfZjVQ25A7AtAoZU+bxqH+Jdi8ocRTgDlD2DU6xSgfgqyw7DKUYfAHcCGfX8LGNqZEXAtFarcB6Eg4iM5EDDWjkAXi7OQGqISBpOQ/utO69yhM1xOAOt5eJ2BYlIPM4e+zc4XTPd3GVHhX12kLr/36rMcSZwhKpeDNwOJOMUlPBtrAJucY9OrgMaPF6MMZWsCJjW6q9ADxH5BOe5AyVV5s8AOrrzPwDuVtWt7rwr3IevnA3cp6qvAt+KyKc4RwHzVDUH55zCr0TkHZyhtistBB4XkQ4R5Pwc6Ccii3Aa9zVAd5xBy4aJyC+Bm4DfuZkexxnIz5hGYSeGjQnT1KPLGuO3VvegeWOaCxGZD1Q9GshX1XP8yGNMdexIwBhjopidEzDGmChmRcAYY6KYFQFjjIliVgSMMSaKWREwxpgoZkXAGGOi2P8HzBbZns6/GzoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(loss_val_drop, label = 'loss_val')\n",
    "ax.plot(loss_train_drop, label = 'loss_train')\n",
    "ax.legend()\n",
    "plt.xlabel('dropout_rate') \n",
    "plt.ylabel('cross_entropy_loss') \n",
    "plt.title('Model Loss vs. dropout rate')\n",
    "fig.savefig(\"drop_loss_cv.png\",dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(acc_val_drop, label = 'acc_val')\n",
    "ax.plot(acc_train_drop, label = 'acc_train')\n",
    "ax.legend()\n",
    "plt.xlabel('dropout_rate') \n",
    "plt.ylabel('accuracy') \n",
    "plt.title('Model Accuracy vs. dropout rate')\n",
    "fig.savefig(\"drop_acc_cv.png\",dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 14s 568us/step - loss: 0.3484 - acc: 0.8506\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 13s 505us/step - loss: 0.1211 - acc: 0.9577\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 13s 507us/step - loss: 0.0536 - acc: 0.9844\n",
      "25000/25000 [==============================] - 6s 250us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "model_drop = Sequential()\n",
    "model_drop.add(Dense(250,input_shape = (max_num,)))\n",
    "model_drop.add(Dropout(0.5))\n",
    "model_drop.add(Activation('relu'))\n",
    "model_drop.add(Dense(num_classes))\n",
    "model_drop.add(Activation('softmax'))\n",
    "model_drop.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_drop = model_drop.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_drop = model_drop.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "drop_train_acc = hist_drop.history.get('acc')[-1]\n",
    "drop_test_acc = score_drop[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with dropout(0.5) on training dataset is\n",
      "0.9844000105857849\n",
      "The accurate rate of the model with dropout(0.5) on test dataset is\n",
      "0.8729600014686585\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with dropout(0.5) on training dataset is')\n",
    "print(drop_train_acc)\n",
    "print('The accurate rate of the model with dropout(0.5) on test dataset is')\n",
    "print(drop_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 7s 283us/step - loss: 0.3292 - acc: 0.8593\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 6s 246us/step - loss: 0.0769 - acc: 0.9771\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 6s 244us/step - loss: 0.0193 - acc: 0.9965\n",
      "25000/25000 [==============================] - 3s 105us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "model_125 = Sequential()\n",
    "model_125.add(Dense(125,input_shape = (max_num,)))\n",
    "model_125.add(Activation('relu'))\n",
    "model_125.add(Dense(num_classes))\n",
    "model_125.add(Activation('softmax'))\n",
    "model_125.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_125 = model_125.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_125 = model_125.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "nn125_train_acc = hist_125.history.get('acc')[-1]\n",
    "nn125_test_acc = score_125[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with 125 hidden units on training dataset is\n",
      "0.9965200033187867\n",
      "The accurate rate of the model with 125 hidden units on test dataset is\n",
      "0.8692400031089783\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with 125 hidden units on training dataset is')\n",
    "print(nn125_train_acc)\n",
    "print('The accurate rate of the model with 125 hidden units on test dataset is')\n",
    "print(nn125_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 14s 567us/step - loss: 0.3492 - acc: 0.8533\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 13s 520us/step - loss: 0.1024 - acc: 0.9656\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 13s 516us/step - loss: 0.0349 - acc: 0.9922\n",
      "25000/25000 [==============================] - 5s 213us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "model_drop = Sequential()\n",
    "model_drop.add(Dense(250,input_shape = (max_num,)))\n",
    "model_drop.add(Dropout(0.4))\n",
    "model_drop.add(Activation('relu'))\n",
    "model_drop.add(Dense(num_classes))\n",
    "model_drop.add(Activation('softmax'))\n",
    "model_drop.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_drop = model_drop.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_drop = model_drop.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "drop_train_acc = hist_drop.history.get('acc')[-1]\n",
    "drop_test_acc = score_drop[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with dropout(0.4) on training dataset is\n",
      "0.9922400074005127\n",
      "The accurate rate of the model with dropout(0.4) on test dataset is\n",
      "0.8701600012779236\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with dropout(0.4) on training dataset is')\n",
    "print(drop_train_acc)\n",
    "print('The accurate rate of the model with dropout(0.4) on test dataset is')\n",
    "print(drop_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 14s 568us/step - loss: 0.3573 - acc: 0.8468\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 13s 503us/step - loss: 0.1421 - acc: 0.9507\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 13s 507us/step - loss: 0.0742 - acc: 0.9769\n",
      "25000/25000 [==============================] - 6s 223us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "model_drop = Sequential()\n",
    "model_drop.add(Dense(250,input_shape = (max_num,)))\n",
    "model_drop.add(Dropout(0.6))\n",
    "model_drop.add(Activation('relu'))\n",
    "model_drop.add(Dense(num_classes))\n",
    "model_drop.add(Activation('softmax'))\n",
    "model_drop.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_drop = model_drop.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_drop = model_drop.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "drop_train_acc = hist_drop.history.get('acc')[-1]\n",
    "drop_test_acc = score_drop[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with dropout(0.6) on training dataset is\n",
      "0.9768800086975098\n",
      "The accurate rate of the model with dropout(0.6) on test dataset is\n",
      "0.8719600014686585\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with dropout(0.6) on training dataset is')\n",
    "print(drop_train_acc)\n",
    "print('The accurate rate of the model with dropout(0.6) on test dataset is')\n",
    "print(drop_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 526us/step - loss: 0.3740 - acc: 0.8564\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 8s 476us/step - loss: 0.0917 - acc: 0.9828\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 8s 478us/step - loss: 0.0435 - acc: 0.9976\n",
      "8334/8334 [==============================] - 1s 168us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 480us/step - loss: 0.2051 - acc: 0.9390 2s - l\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 477us/step - loss: 0.0574 - acc: 0.9950\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 481us/step - loss: 0.0378 - acc: 0.9996\n",
      "8333/8333 [==============================] - 1s 161us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 476us/step - loss: 0.0578 - acc: 0.9931\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 477us/step - loss: 0.0388 - acc: 0.9997\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 480us/step - loss: 0.0341 - acc: 1.0000\n",
      "8333/8333 [==============================] - 1s 156us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 519us/step - loss: 0.5924 - acc: 0.8473\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 8s 475us/step - loss: 0.2856 - acc: 0.9798\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 8s 475us/step - loss: 0.2049 - acc: 0.9967\n",
      "8334/8334 [==============================] - 1s 168us/step - ETA\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 474us/step - loss: 0.3510 - acc: 0.9398\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 478us/step - loss: 0.2218 - acc: 0.9926\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 481us/step - loss: 0.1700 - acc: 0.9995\n",
      "8333/8333 [==============================] - 1s 156us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 475us/step - loss: 0.2129 - acc: 0.9810\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 478us/step - loss: 0.1758 - acc: 0.9969\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 475us/step - loss: 0.1414 - acc: 1.0000\n",
      "8333/8333 [==============================] - 1s 157us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 528us/step - loss: 1.8369 - acc: 0.8526\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 8s 487us/step - loss: 0.7665 - acc: 0.9507\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 8s 486us/step - loss: 0.5812 - acc: 0.9566\n",
      "8334/8334 [==============================] - 1s 169us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 497us/step - loss: 0.7104 - acc: 0.9189\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 476us/step - loss: 0.5210 - acc: 0.9674\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 480us/step - loss: 0.3922 - acc: 0.9801\n",
      "8333/8333 [==============================] - 1s 154us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 475us/step - loss: 0.5506 - acc: 0.9392\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 479us/step - loss: 0.4241 - acc: 0.9803 4s - l - ETA: 1s - loss: \n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 472us/step - loss: 0.3144 - acc: 0.9908\n",
      "8333/8333 [==============================] - 1s 152us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 9s 534us/step - loss: 6.3297 - acc: 0.8357\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 8s 503us/step - loss: 1.3332 - acc: 0.8669\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 8s 494us/step - loss: 1.2293 - acc: 0.8711\n",
      "8334/8334 [==============================] - 1s 177us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 495us/step - loss: 1.1430 - acc: 0.8764\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 502us/step - loss: 1.0341 - acc: 0.8869\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 493us/step - loss: 0.9667 - acc: 0.8915\n",
      "8333/8333 [==============================] - 1s 163us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 482us/step - loss: 0.9496 - acc: 0.8910\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 538us/step - loss: 0.8667 - acc: 0.9035\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 10s 577us/step - loss: 0.8105 - acc: 0.9111\n",
      "8333/8333 [==============================] - 2s 217us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 10s 600us/step - loss: 42.1275 - acc: 0.7672\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 9s 557us/step - loss: 3.8045 - acc: 0.8068\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 9s 552us/step - loss: 3.5522 - acc: 0.8283\n",
      "8334/8334 [==============================] - 2s 233us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 532us/step - loss: 3.5191 - acc: 0.8345\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 547us/step - loss: 3.5023 - acc: 0.8403\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 551us/step - loss: 3.4889 - acc: 0.8462\n",
      "8333/8333 [==============================] - 2s 203us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 533us/step - loss: 3.4878 - acc: 0.8511\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 561us/step - loss: 3.4870 - acc: 0.8526\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 567us/step - loss: 3.4820 - acc: 0.8585\n",
      "8333/8333 [==============================] - 2s 220us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 10s 625us/step - loss: 412.1660 - acc: 0.5414\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 10s 583us/step - loss: 31.7424 - acc: 0.4999\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 9s 560us/step - loss: 30.8289 - acc: 0.4989\n",
      "8334/8334 [==============================] - 2s 239us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 543us/step - loss: 30.8347 - acc: 0.4955\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 10s 579us/step - loss: 30.8026 - acc: 0.5010\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 11s 673us/step - loss: 30.8211 - acc: 0.5049\n",
      "8333/8333 [==============================] - 2s 218us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 545us/step - loss: 30.7826 - acc: 0.5021\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 559us/step - loss: 30.8032 - acc: 0.5048\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 560us/step - loss: 30.7899 - acc: 0.5039\n",
      "8333/8333 [==============================] - 2s 219us/step\n"
     ]
    }
   ],
   "source": [
    "lambda_list = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]\n",
    "loss_train_l1 = []\n",
    "acc_train_l1 = []\n",
    "loss_val_l1 = []\n",
    "acc_val_l1 = []\n",
    "for par in lambda_list:\n",
    "    model_l1 = Sequential()\n",
    "    model_l1.add(Dense(250,input_shape = (max_num,), kernel_regularizer = l1(par), bias_regularizer=l1(par)))\n",
    "    model_l1.add(Activation('relu'))\n",
    "    model_l1.add(Dense(num_classes, kernel_regularizer = l1(par), bias_regularizer=l1(par)))\n",
    "    model_l1.add(Activation('softmax'))\n",
    "    model_l1.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    loss_val_cv = 0\n",
    "    acc_val_cv = 0\n",
    "    loss_train_cv = 0\n",
    "    acc_train_cv = 0\n",
    "    for train_cv_index, val_index in kf.split(X_train):\n",
    "        X_train_cv = X_train[train_cv_index]\n",
    "        y_train_cv = y_train[train_cv_index]\n",
    "        X_val_cv = X_train[val_index]\n",
    "        y_val_cv = y_train[val_index]\n",
    "        hist = model_l1.fit(X_train_cv,y_train_cv,batch_size=200, epochs = 3)\n",
    "        loss_train_cv = loss_train_cv + hist.history.get('loss')[-1]\n",
    "        acc_train_cv = acc_train_cv + hist.history.get('acc')[-1]\n",
    "        score_val_cv = model_l1.evaluate(X_val_cv,y_val_cv, batch_size=200, verbose = 1)\n",
    "        loss_val_cv = loss_val_cv + score_val_cv[0]\n",
    "        acc_val_cv = acc_val_cv + score_val_cv[1]\n",
    "    loss_val_l1.append(loss_val_cv/3)\n",
    "    acc_val_l1.append(acc_val_cv/3)\n",
    "    loss_train_l1.append(loss_train_cv/3)\n",
    "    acc_train_l1.append(acc_train_cv/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03845995333584134, 0.17209522215436823, 0.42926743624753066, 1.0021590338595625, 3.507723528102316, 30.813288159613112]\n",
      "[0.17665963721892683, 0.297276239302909, 0.5640312226375032, 1.0241692131643885, 3.496250938156813, 30.906951873829343]\n"
     ]
    }
   ],
   "source": [
    "print(loss_train_l1)\n",
    "print(loss_val_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9990799712760805, 0.9987399603998445, 0.9758396216811569, 0.8912395972247843, 0.8443396800387178, 0.5025999266247423]\n",
      "[0.956642814160677, 0.9464422868833272, 0.9096412133018205, 0.8784400656591919, 0.8461607332347469, 0.504719904790355]\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_l1)\n",
    "print(acc_val_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_val</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.038460</td>\n",
       "      <td>0.176660</td>\n",
       "      <td>0.99908</td>\n",
       "      <td>0.956643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.172095</td>\n",
       "      <td>0.297276</td>\n",
       "      <td>0.99874</td>\n",
       "      <td>0.946442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000100</th>\n",
       "      <td>0.429267</td>\n",
       "      <td>0.564031</td>\n",
       "      <td>0.97584</td>\n",
       "      <td>0.909641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>1.002159</td>\n",
       "      <td>1.024169</td>\n",
       "      <td>0.89124</td>\n",
       "      <td>0.878440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>3.507724</td>\n",
       "      <td>3.496251</td>\n",
       "      <td>0.84434</td>\n",
       "      <td>0.846161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100000</th>\n",
       "      <td>30.813288</td>\n",
       "      <td>30.906952</td>\n",
       "      <td>0.50260</td>\n",
       "      <td>0.504720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss_train   loss_val  acc_train   acc_val\n",
       "lambda                                              \n",
       "0.000001    0.038460   0.176660    0.99908  0.956643\n",
       "0.000010    0.172095   0.297276    0.99874  0.946442\n",
       "0.000100    0.429267   0.564031    0.97584  0.909641\n",
       "0.001000    1.002159   1.024169    0.89124  0.878440\n",
       "0.010000    3.507724   3.496251    0.84434  0.846161\n",
       "0.100000   30.813288  30.906952    0.50260  0.504720"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_reg_cv = pd.DataFrame({'loss_train': loss_train_l1,\n",
    "                          'loss_val': loss_val_l1,\n",
    "                       'acc_train': acc_train_l1,\n",
    "                        'acc_val':acc_val_l1,\n",
    "                         'lambda':lambda_list}).set_index('lambda')\n",
    "l1_reg_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 13s 522us/step - loss: 0.3630 - acc: 0.85690s - loss: 0.3652 - acc: 0\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 12s 471us/step - loss: 0.0964 - acc: 0.9801\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 12s 469us/step - loss: 0.0456 - acc: 0.9980\n",
      "25000/25000 [==============================] - 4s 166us/step\n"
     ]
    }
   ],
   "source": [
    "# indicating by the result of l1_reg_cv data frame, will set the lambda as 1e-6 for l1 norm regularization\n",
    "model_l1 = Sequential()\n",
    "model_l1.add(Dense(250,input_shape = (max_num,), kernel_regularizer = l1(1e-6), bias_regularizer=l1(1e-6)))\n",
    "model_l1.add(Activation('relu'))\n",
    "model_l1.add(Dense(num_classes, kernel_regularizer = l1(1e-6), bias_regularizer=l1(1e-6)))\n",
    "model_l1.add(Activation('softmax'))\n",
    "model_l1.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_l1 = model_l1.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_l1 = model_l1.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "l1_train_acc = hist_l1.history.get('acc')[-1]\n",
    "l1_test_acc = score_l1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with l1 regularization on training dataset is\n",
      "0.9979600019454956\n",
      "The accurate rate of the model with l1 regularization on test dataset is\n",
      "0.8711199998855591\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with l1 regularization on training dataset is')\n",
    "print(l1_train_acc)\n",
    "print('The accurate rate of the model with l1 regularization on test dataset is')\n",
    "print(l1_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 14s 563us/step - loss: 0.5563 - acc: 0.8622\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 12s 476us/step - loss: 0.2818 - acc: 0.9758\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 12s 478us/step - loss: 0.1938 - acc: 0.9958\n",
      "25000/25000 [==============================] - 4s 175us/step\n"
     ]
    }
   ],
   "source": [
    "# indicating by the result of l1_reg_cv data frame, will set the lambda as 1e-5 for l1 norm regularization\n",
    "model_l1 = Sequential()\n",
    "model_l1.add(Dense(250,input_shape = (max_num,), kernel_regularizer = l1(1e-5), bias_regularizer=l1(1e-5)))\n",
    "model_l1.add(Activation('relu'))\n",
    "model_l1.add(Dense(num_classes, kernel_regularizer = l1(1e-5), bias_regularizer=l1(1e-5)))\n",
    "model_l1.add(Activation('softmax'))\n",
    "model_l1.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_l1 = model_l1.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_l1 = model_l1.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "l1_train_acc = hist_l1.history.get('acc')[-1]\n",
    "l1_test_acc = score_l1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with l1 regularization on training dataset is\n",
      "0.9958400039672851\n",
      "The accurate rate of the model with l1 regularization on test dataset is\n",
      "0.8743999996185303\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with l1 regularization on training dataset is')\n",
    "print(l1_train_acc)\n",
    "print('The accurate rate of the model with l1 regularization on test dataset is')\n",
    "print(l1_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 10s 583us/step - loss: 0.3717 - acc: 0.8422\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 8s 473us/step - loss: 0.0603 - acc: 0.9833\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 8s 473us/step - loss: 0.0151 - acc: 0.9984\n",
      "8334/8334 [==============================] - 2s 208us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 487us/step - loss: 0.1704 - acc: 0.9417\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 8s 496us/step - loss: 0.0239 - acc: 0.9950\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 8s 486us/step - loss: 0.0062 - acc: 0.9997\n",
      "8333/8333 [==============================] - 1s 158us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 8s 474us/step - loss: 0.0190 - acc: 0.9953\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 529us/step - loss: 0.0043 - acc: 0.9999\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 570us/step - loss: 0.0022 - acc: 1.0000\n",
      "8333/8333 [==============================] - 2s 187us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 12s 712us/step - loss: 0.3552 - acc: 0.8497\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 13s 802us/step - loss: 0.0652 - acc: 0.98342s - loss: 0.\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 14s 848us/step - loss: 0.0200 - acc: 0.9981\n",
      "8334/8334 [==============================] - 3s 330us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 562us/step - loss: 0.1804 - acc: 0.9425\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 557us/step - loss: 0.0324 - acc: 0.9948\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 10s 616us/step - loss: 0.0139 - acc: 0.9998\n",
      "8333/8333 [==============================] - 2s 275us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 565us/step - loss: 0.0300 - acc: 0.9944\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 10s 614us/step - loss: 0.0152 - acc: 0.9996\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 10s 583us/step - loss: 0.0114 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 221us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 11s 664us/step - loss: 0.3909 - acc: 0.8548\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 9s 556us/step - loss: 0.1128 - acc: 0.9804\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 9s 561us/step - loss: 0.0632 - acc: 0.9982\n",
      "8334/8334 [==============================] - 2s 269us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 542us/step - loss: 0.2255 - acc: 0.9409\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 560us/step - loss: 0.0857 - acc: 0.9935\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 555us/step - loss: 0.0590 - acc: 0.9996\n",
      "8333/8333 [==============================] - 2s 214us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 538us/step - loss: 0.0807 - acc: 0.9914\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 569us/step - loss: 0.0585 - acc: 0.9994\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 10s 578us/step - loss: 0.0497 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 228us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 11s 679us/step - loss: 0.6667 - acc: 0.8456\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 9s 563us/step - loss: 0.2985 - acc: 0.9766\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 9s 555us/step - loss: 0.1959 - acc: 0.9917\n",
      "8334/8334 [==============================] - 2s 266us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 545us/step - loss: 0.3584 - acc: 0.9272\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 561us/step - loss: 0.2332 - acc: 0.9839\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 557us/step - loss: 0.1580 - acc: 0.9972\n",
      "8333/8333 [==============================] - 2s 215us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 537us/step - loss: 0.2632 - acc: 0.9570\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 570us/step - loss: 0.2040 - acc: 0.9899\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 10s 572us/step - loss: 0.1464 - acc: 0.9978\n",
      "8333/8333 [==============================] - 2s 209us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 11s 661us/step - loss: 1.5827 - acc: 0.8511\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 9s 563us/step - loss: 0.5100 - acc: 0.9179\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 9s 563us/step - loss: 0.4485 - acc: 0.9183\n",
      "8334/8334 [==============================] - 2s 270us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 551us/step - loss: 0.4926 - acc: 0.9015\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 561us/step - loss: 0.3963 - acc: 0.9225\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 552us/step - loss: 0.3761 - acc: 0.9270\n",
      "8333/8333 [==============================] - 2s 212us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 541us/step - loss: 0.4299 - acc: 0.9061\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 563us/step - loss: 0.3382 - acc: 0.9375\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 10s 573us/step - loss: 0.3179 - acc: 0.9410\n",
      "8333/8333 [==============================] - 2s 228us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 11s 673us/step - loss: 5.3259 - acc: 0.8403\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 10s 573us/step - loss: 0.7179 - acc: 0.8597\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 9s 551us/step - loss: 0.6690 - acc: 0.8648\n",
      "8334/8334 [==============================] - 2s 269us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 9s 539us/step - loss: 0.6765 - acc: 0.8616\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 9s 567us/step - loss: 0.6584 - acc: 0.8635\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 10s 584us/step - loss: 0.6530 - acc: 0.8642\n",
      "8333/8333 [==============================] - 2s 235us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 10s 576us/step - loss: 0.6417 - acc: 0.8679\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 10s 573us/step - loss: 0.6301 - acc: 0.8741\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 9s 558us/step - loss: 0.6249 - acc: 0.8689\n",
      "8333/8333 [==============================] - 2s 211us/step\n"
     ]
    }
   ],
   "source": [
    "lambda_list = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]\n",
    "loss_train_l2 = []\n",
    "acc_train_l2 = []\n",
    "loss_val_l2 = []\n",
    "acc_val_l2 = []\n",
    "for par in lambda_list:\n",
    "    model_l2 = Sequential()\n",
    "    model_l2.add(Dense(250,input_shape = (max_num,), kernel_regularizer = l2(par), bias_regularizer=l2(par)))\n",
    "    model_l2.add(Activation('relu'))\n",
    "    model_l2.add(Dense(num_classes, kernel_regularizer = l2(par), bias_regularizer=l2(par)))\n",
    "    model_l2.add(Activation('softmax'))\n",
    "    model_l2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    loss_val_cv = 0\n",
    "    acc_val_cv = 0\n",
    "    loss_train_cv = 0\n",
    "    acc_train_cv = 0\n",
    "    for train_cv_index, val_index in kf.split(X_train):\n",
    "        X_train_cv = X_train[train_cv_index]\n",
    "        y_train_cv = y_train[train_cv_index]\n",
    "        X_val_cv = X_train[val_index]\n",
    "        y_val_cv = y_train[val_index]\n",
    "        hist = model_l2.fit(X_train_cv,y_train_cv,batch_size=200, epochs = 3)\n",
    "        loss_train_cv = loss_train_cv + hist.history.get('loss')[-1]\n",
    "        acc_train_cv = acc_train_cv + hist.history.get('acc')[-1]\n",
    "        score_val_cv = model_l2.evaluate(X_val_cv,y_val_cv, batch_size=200, verbose = 1)\n",
    "        loss_val_cv = loss_val_cv + score_val_cv[0]\n",
    "        acc_val_cv = acc_val_cv + score_val_cv[1]\n",
    "    loss_val_l2.append(loss_val_cv/3)\n",
    "    acc_val_l2.append(acc_val_cv/3)\n",
    "    loss_train_l2.append(loss_train_cv/3)\n",
    "    acc_train_l2.append(acc_train_cv/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.007824130377315422, 0.015088598974607422, 0.057281762232496654, 0.1667648056307641, 0.3808560894824569, 0.6489676033762257]\n",
      "[0.1390206992715748, 0.15104453086864839, 0.19869745330250457, 0.33077300593291253, 0.48299898957397297, 0.6537691378268679]\n"
     ]
    }
   ],
   "source": [
    "print(loss_train_l2)\n",
    "print(loss_val_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9993599810094662, 0.9992599771022933, 0.9992399799237882, 0.9955999265911689, 0.9287797917134272, 0.8659399778324643]\n",
      "[0.959482759669288, 0.9571628738318507, 0.9539227791629714, 0.9219216951839192, 0.8826001151991272, 0.8591601228896826]\n"
     ]
    }
   ],
   "source": [
    "print(acc_train_l2)\n",
    "print(acc_val_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_val</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.007824</td>\n",
       "      <td>0.139021</td>\n",
       "      <td>0.99936</td>\n",
       "      <td>0.959483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.015089</td>\n",
       "      <td>0.151045</td>\n",
       "      <td>0.99926</td>\n",
       "      <td>0.957163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000100</th>\n",
       "      <td>0.057282</td>\n",
       "      <td>0.198697</td>\n",
       "      <td>0.99924</td>\n",
       "      <td>0.953923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>0.166765</td>\n",
       "      <td>0.330773</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>0.921922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>0.380856</td>\n",
       "      <td>0.482999</td>\n",
       "      <td>0.92878</td>\n",
       "      <td>0.882600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100000</th>\n",
       "      <td>0.648968</td>\n",
       "      <td>0.653769</td>\n",
       "      <td>0.86594</td>\n",
       "      <td>0.859160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss_train  loss_val  acc_train   acc_val\n",
       "lambda                                             \n",
       "0.000001    0.007824  0.139021    0.99936  0.959483\n",
       "0.000010    0.015089  0.151045    0.99926  0.957163\n",
       "0.000100    0.057282  0.198697    0.99924  0.953923\n",
       "0.001000    0.166765  0.330773    0.99560  0.921922\n",
       "0.010000    0.380856  0.482999    0.92878  0.882600\n",
       "0.100000    0.648968  0.653769    0.86594  0.859160"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_reg_cv = pd.DataFrame({'loss_train': loss_train_l2,\n",
    "                          'loss_val': loss_val_l2,\n",
    "                       'acc_train': acc_train_l2,\n",
    "                        'acc_val':acc_val_l2,\n",
    "                         'lambda':lambda_list}).set_index('lambda')\n",
    "l2_reg_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 14s 569us/step - loss: 0.3231 - acc: 0.8651\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 12s 485us/step - loss: 0.0702 - acc: 0.9788\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 13s 511us/step - loss: 0.0148 - acc: 0.9978\n",
      "25000/25000 [==============================] - 8s 323us/step\n"
     ]
    }
   ],
   "source": [
    "model_l2 = Sequential()\n",
    "model_l2.add(Dense(250,input_shape = (max_num,), kernel_regularizer = l2(1e-6), bias_regularizer=l2(1e-6)))\n",
    "model_l2.add(Activation('relu'))\n",
    "model_l2.add(Dense(num_classes, kernel_regularizer = l2(1e-6), bias_regularizer=l2(1e-6)))\n",
    "model_l2.add(Activation('softmax'))\n",
    "model_l2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_l2 = model_l2.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_l2 = model_l2.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "l2_train_acc = hist_l2.history.get('acc')[-1]\n",
    "l2_test_acc = score_l2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with l2 regularization on training dataset is\n",
      "0.9977600021362305\n",
      "The accurate rate of the model with l2 regularization on test dataset is\n",
      "0.8718800010681153\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with l2 regularization on training dataset is')\n",
    "print(l2_train_acc)\n",
    "print('The accurate rate of the model with l2 regularization on test dataset is')\n",
    "print(l2_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 14s 555us/step - loss: 0.3362 - acc: 0.8628\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 12s 473us/step - loss: 0.0740 - acc: 0.9798\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 13s 508us/step - loss: 0.0220 - acc: 0.9979\n",
      "25000/25000 [==============================] - 6s 249us/step\n"
     ]
    }
   ],
   "source": [
    "model_l2 = Sequential()\n",
    "model_l2.add(Dense(250,input_shape = (max_num,), kernel_regularizer = l2(1e-5), bias_regularizer=l2(1e-5)))\n",
    "model_l2.add(Activation('relu'))\n",
    "model_l2.add(Dense(num_classes, kernel_regularizer = l2(1e-5), bias_regularizer=l2(1e-5)))\n",
    "model_l2.add(Activation('softmax'))\n",
    "model_l2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_l2 = model_l2.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_l2 = model_l2.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "l2_train_acc = hist_l2.history.get('acc')[-1]\n",
    "l2_test_acc = score_l2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with l2 regularization on training dataset is\n",
      "0.9978800020217895\n",
      "The accurate rate of the model with l2 regularization on test dataset is\n",
      "0.8700399985313415\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with l2 regularization on training dataset is')\n",
    "print(l2_train_acc)\n",
    "print('The accurate rate of the model with l2 regularization on test dataset is')\n",
    "print(l2_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 383us/step - loss: 0.4289 - acc: 0.8081\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 4s 255us/step - loss: 0.1823 - acc: 0.9371\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 4s 259us/step - loss: 0.1024 - acc: 0.9699\n",
      "8334/8334 [==============================] - 2s 296us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 237us/step - loss: 0.2068 - acc: 0.9312\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 258us/step - loss: 0.0942 - acc: 0.9723\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 236us/step - loss: 0.0511 - acc: 0.9888\n",
      "8333/8333 [==============================] - 2s 200us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 240us/step - loss: 0.1141 - acc: 0.9618\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 245us/step - loss: 0.0478 - acc: 0.9867\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 254us/step - loss: 0.0232 - acc: 0.9957\n",
      "8333/8333 [==============================] - 2s 199us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 397us/step - loss: 0.4025 - acc: 0.8220\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 302us/step - loss: 0.1520 - acc: 0.9473\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 4s 265us/step - loss: 0.0669 - acc: 0.9798\n",
      "8334/8334 [==============================] - 2s 287us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 291us/step - loss: 0.1979 - acc: 0.9341\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 281us/step - loss: 0.0547 - acc: 0.9849\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 301us/step - loss: 0.0186 - acc: 0.9960\n",
      "8333/8333 [==============================] - ETA:  - 2s 239us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 268us/step - loss: 0.0529 - acc: 0.9829\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 275us/step - loss: 0.0157 - acc: 0.9959\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 303us/step - loss: 0.0050 - acc: 0.9994\n",
      "8333/8333 [==============================] - 2s 206us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 405us/step - loss: 0.3917 - acc: 0.8298\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 300us/step - loss: 0.1285 - acc: 0.9566\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 277us/step - loss: 0.0437 - acc: 0.9885\n",
      "8334/8334 [==============================] - 2s 253us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 267us/step - loss: 0.1928 - acc: 0.9354\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 268us/step - loss: 0.0467 - acc: 0.9864\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 301us/step - loss: 0.0111 - acc: 0.9975\n",
      "8333/8333 [==============================] - 1s 167us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 286us/step - loss: 0.0426 - acc: 0.9852\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 314us/step - loss: 0.0126 - acc: 0.9977 0s - loss: 0.0125 - \n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 293us/step - loss: 0.0025 - acc: 0.9997\n",
      "8333/8333 [==============================] - 1s 176us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 446us/step - loss: 0.3854 - acc: 0.8284\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 4s 269us/step - loss: 0.1142 - acc: 0.9625\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 4s 270us/step - loss: 0.0369 - acc: 0.9906\n",
      "8334/8334 [==============================] - 2s 247us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 273us/step - loss: 0.1895 - acc: 0.9350\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 287us/step - loss: 0.0427 - acc: 0.9876\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 301us/step - loss: 0.0096 - acc: 0.9982\n",
      "8333/8333 [==============================] - 1s 158us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 327us/step - loss: 0.0393 - acc: 0.9873\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 327us/step - loss: 0.0097 - acc: 0.9980\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 317us/step - loss: 0.0020 - acc: 0.9999\n",
      "8333/8333 [==============================] - 2s 218us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 415us/step - loss: 0.3762 - acc: 0.8432\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 294us/step - loss: 0.1147 - acc: 0.9599\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 305us/step - loss: 0.0350 - acc: 0.9902\n",
      "8334/8334 [==============================] - 2s 268us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 300us/step - loss: 0.2004 - acc: 0.9330\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 295us/step - loss: 0.0420 - acc: 0.9876\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 324us/step - loss: 0.0089 - acc: 0.9983\n",
      "8333/8333 [==============================] - 2s 228us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 326us/step - loss: 0.0373 - acc: 0.9863\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 325us/step - loss: 0.0067 - acc: 0.9986\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 312us/step - loss: 0.0013 - acc: 0.9999\n",
      "8333/8333 [==============================] - 1s 159us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 417us/step - loss: 0.3677 - acc: 0.8450\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 295us/step - loss: 0.1025 - acc: 0.9635\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 6s 335us/step - loss: 0.0273 - acc: 0.9925\n",
      "8334/8334 [==============================] - 2s 260us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 284us/step - loss: 0.1889 - acc: 0.9350\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 335us/step - loss: 0.0360 - acc: 0.9901\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 324us/step - loss: 0.0068 - acc: 0.9983\n",
      "8333/8333 [==============================] - 2s 203us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 305us/step - loss: 0.0383 - acc: 0.9869\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 330us/step - loss: 0.0085 - acc: 0.9983\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 333us/step - loss: 0.0017 - acc: 0.9998\n",
      "8333/8333 [==============================] - 2s 182us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 8s 498us/step - loss: 0.3656 - acc: 0.8422\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 285us/step - loss: 0.0924 - acc: 0.9689\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 272us/step - loss: 0.0243 - acc: 0.9939\n",
      "8334/8334 [==============================] - 2s 275us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 275us/step - loss: 0.1868 - acc: 0.9369\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 269us/step - loss: 0.0363 - acc: 0.9905\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 266us/step - loss: 0.0061 - acc: 0.9988\n",
      "8333/8333 [==============================] - 1s 169us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 263us/step - loss: 0.0346 - acc: 0.9888\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 266us/step - loss: 0.0077 - acc: 0.9987\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 265us/step - loss: 0.0013 - acc: 0.9999\n",
      "8333/8333 [==============================] - 1s 175us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 441us/step - loss: 0.3555 - acc: 0.8471\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 279us/step - loss: 0.0886 - acc: 0.9713\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 278us/step - loss: 0.0203 - acc: 0.9950\n",
      "8334/8334 [==============================] - 2s 297us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 277us/step - loss: 0.2033 - acc: 0.9318 1s - loss:\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 279us/step - loss: 0.0363 - acc: 0.9901\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 278us/step - loss: 0.0055 - acc: 0.9992\n",
      "8333/8333 [==============================] - 1s 156us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 272us/step - loss: 0.0288 - acc: 0.9906\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 261us/step - loss: 0.0050 - acc: 0.9987 0s - loss: 0.0049 - acc: \n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 222us/step - loss: 0.0011 - acc: 0.9999\n",
      "8333/8333 [==============================] - 1s 118us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 5s 309us/step - loss: 0.3562 - acc: 0.8495 0s - loss: 0.3712 - acc\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 4s 230us/step - loss: 0.0855 - acc: 0.9736\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 4s 265us/step - loss: 0.0193 - acc: 0.9953\n",
      "8334/8334 [==============================] - 2s 222us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 256us/step - loss: 0.1993 - acc: 0.9316\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 237us/step - loss: 0.0347 - acc: 0.9903\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 235us/step - loss: 0.0039 - acc: 0.9993\n",
      "8333/8333 [==============================] - 1s 125us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 260us/step - loss: 0.0294 - acc: 0.9904\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 237us/step - loss: 0.0052 - acc: 0.9993\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 237us/step - loss: 6.2547e-04 - acc: 1.0000 3s - loss: 8.0275e-04 - ac - ETA: 2s -\n",
      "8333/8333 [==============================] - 1s 127us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 359us/step - loss: 0.3608 - acc: 0.8440\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 4s 258us/step - loss: 0.0880 - acc: 0.9710\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 4s 252us/step - loss: 0.0174 - acc: 0.9959\n",
      "8334/8334 [==============================] - 2s 209us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 262us/step - loss: 0.1841 - acc: 0.9374\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 249us/step - loss: 0.0273 - acc: 0.9924\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 249us/step - loss: 0.0036 - acc: 0.9996\n",
      "8333/8333 [==============================] - 1s 121us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 243us/step - loss: 0.0284 - acc: 0.9906\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 251us/step - loss: 0.0050 - acc: 0.9992\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 227us/step - loss: 0.0010 - acc: 0.9999\n",
      "8333/8333 [==============================] - 1s 105us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 353us/step - loss: 0.3571 - acc: 0.8460\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 4s 267us/step - loss: 0.0891 - acc: 0.9703\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 328us/step - loss: 0.0174 - acc: 0.9963\n",
      "8334/8334 [==============================] - 2s 277us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 294us/step - loss: 0.1916 - acc: 0.9356\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 280us/step - loss: 0.0285 - acc: 0.9930\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 258us/step - loss: 0.0041 - acc: 0.9993\n",
      "8333/8333 [==============================] - 1s 125us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 251us/step - loss: 0.0306 - acc: 0.9900\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 259us/step - loss: 0.0061 - acc: 0.9991\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 272us/step - loss: 0.0016 - acc: 0.9999\n",
      "8333/8333 [==============================] - 1s 124us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 389us/step - loss: 0.3650 - acc: 0.8420\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 4s 255us/step - loss: 0.0840 - acc: 0.9713\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 4s 252us/step - loss: 0.0162 - acc: 0.9963\n",
      "8334/8334 [==============================] - 1s 176us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 246us/step - loss: 0.1858 - acc: 0.9376\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 250us/step - loss: 0.0279 - acc: 0.9928\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 248us/step - loss: 0.0037 - acc: 0.9996\n",
      "8333/8333 [==============================] - 1s 110us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 243us/step - loss: 0.0234 - acc: 0.9922\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 250us/step - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 247us/step - loss: 4.6936e-04 - acc: 1.0000\n",
      "8333/8333 [==============================] - 1s 112us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 351us/step - loss: 0.3584 - acc: 0.8507\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 4s 260us/step - loss: 0.0752 - acc: 0.9761\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 4s 261us/step - loss: 0.0126 - acc: 0.9972\n",
      "8334/8334 [==============================] - 1s 176us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 263us/step - loss: 0.1928 - acc: 0.9369\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 273us/step - loss: 0.0301 - acc: 0.9914\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 270us/step - loss: 0.0037 - acc: 0.9996\n",
      "8333/8333 [==============================] - 1s 116us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 262us/step - loss: 0.0269 - acc: 0.9916\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 284us/step - loss: 0.0064 - acc: 0.9986\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 280us/step - loss: 0.0023 - acc: 0.9998\n",
      "8333/8333 [==============================] - 1s 119us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 374us/step - loss: 0.3570 - acc: 0.8446\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 277us/step - loss: 0.0753 - acc: 0.9758\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 277us/step - loss: 0.0102 - acc: 0.9980\n",
      "8334/8334 [==============================] - 2s 190us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 281us/step - loss: 0.1900 - acc: 0.9363\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 282us/step - loss: 0.0272 - acc: 0.9929\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 287us/step - loss: 0.0041 - acc: 0.9993\n",
      "8333/8333 [==============================] - 1s 118us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 285us/step - loss: 0.0258 - acc: 0.9923\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 286us/step - loss: 0.0034 - acc: 0.9995\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 282us/step - loss: 7.0690e-04 - acc: 0.9999\n",
      "8333/8333 [==============================] - 1s 117us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 383us/step - loss: 0.3725 - acc: 0.8379\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 285us/step - loss: 0.0819 - acc: 0.9738\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 282us/step - loss: 0.0150 - acc: 0.9964\n",
      "8334/8334 [==============================] - 1s 170us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 287us/step - loss: 0.1949 - acc: 0.9350\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 313us/step - loss: 0.0264 - acc: 0.9932\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 294us/step - loss: 0.0036 - acc: 0.9996\n",
      "8333/8333 [==============================] - 1s 100us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 294us/step - loss: 0.0237 - acc: 0.9929\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 298us/step - loss: 0.0047 - acc: 0.9992\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 291us/step - loss: 0.0014 - acc: 0.9999 0s - loss: 0.0015 - \n",
      "8333/8333 [==============================] - 1s 101us/step\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16666/16666 [==============================] - 7s 398us/step - loss: 0.3564 - acc: 0.8509\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 298us/step - loss: 0.0728 - acc: 0.9780\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 298us/step - loss: 0.0105 - acc: 0.9977 3s - loss: 0.0130 - acc: - ETA: 2s - los - ETA: 1s - \n",
      "8334/8334 [==============================] - 2s 182us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 318us/step - loss: 0.1929 - acc: 0.9319\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 330us/step - loss: 0.0256 - acc: 0.9936\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 306us/step - loss: 0.0025 - acc: 0.9997\n",
      "8333/8333 [==============================] - 1s 100us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 311us/step - loss: 0.0263 - acc: 0.9913\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 304us/step - loss: 0.0040 - acc: 0.9990\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 301us/step - loss: 5.2137e-04 - acc: 1.0000 1s - loss: 6 - ETA: 0s - loss: 5.4008e-04 - acc:  - ETA: 0s - loss: 5.2645e-04 - acc: 1.\n",
      "8333/8333 [==============================] - 1s 103us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 419us/step - loss: 0.3570 - acc: 0.8432\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 323us/step - loss: 0.0659 - acc: 0.9791\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 5s 312us/step - loss: 0.0094 - acc: 0.9984 0s - loss: 0.0089 - acc: 0. - ETA: 0s - loss: 0.0096 - acc: 0.9\n",
      "8334/8334 [==============================] - 1s 177us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 5s 309us/step - loss: 0.1972 - acc: 0.9358\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 308us/step - loss: 0.0258 - acc: 0.9926\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 311us/step - loss: 0.0021 - acc: 0.9996\n",
      "8333/8333 [==============================] - 1s 110us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 332us/step - loss: 0.0234 - acc: 0.9925\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 5s 317us/step - loss: 0.0073 - acc: 0.9982\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 5s 320us/step - loss: 0.0013 - acc: 0.9999\n",
      "8333/8333 [==============================] - 1s 107us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 447us/step - loss: 0.3605 - acc: 0.8429\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 5s 329us/step - loss: 0.0709 - acc: 0.9782\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 6s 336us/step - loss: 0.0098 - acc: 0.9979\n",
      "8334/8334 [==============================] - 2s 194us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 335us/step - loss: 0.1951 - acc: 0.9347\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 335us/step - loss: 0.0267 - acc: 0.9934\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 335us/step - loss: 0.0050 - acc: 0.9994\n",
      "8333/8333 [==============================] - 1s 129us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 332us/step - loss: 0.0237 - acc: 0.9935\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 332us/step - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 331us/step - loss: 0.0017 - acc: 0.9998\n",
      "8333/8333 [==============================] - 1s 122us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 8s 456us/step - loss: 0.3742 - acc: 0.8391\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 6s 345us/step - loss: 0.0818 - acc: 0.9737\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 6s 343us/step - loss: 0.0123 - acc: 0.9973\n",
      "8334/8334 [==============================] - 2s 195us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 345us/step - loss: 0.1820 - acc: 0.9398\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 344us/step - loss: 0.0247 - acc: 0.9935\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 354us/step - loss: 0.0025 - acc: 0.9998\n",
      "8333/8333 [==============================] - 1s 162us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 6s 358us/step - loss: 0.0228 - acc: 0.9927\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 6s 347us/step - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 6s 350us/step - loss: 3.2763e-04 - acc: 1.0000\n",
      "8333/8333 [==============================] - 1s 128us/step\n"
     ]
    }
   ],
   "source": [
    "units = range(10,200,10)\n",
    "loss_train_2 = []\n",
    "acc_train_2 = []\n",
    "loss_val_2 = []\n",
    "acc_val_2 = []\n",
    "for num in units:\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Dense(num,input_shape = (max_num,)))\n",
    "    model_2.add(Activation('relu'))\n",
    "    model_2.add(Dense(num))\n",
    "    model_2.add(Activation('relu'))\n",
    "    model_2.add(Dense(num_classes))\n",
    "    model_2.add(Activation('softmax'))\n",
    "    model_2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    loss_val_cv = 0\n",
    "    acc_val_cv = 0\n",
    "    loss_train_cv = 0\n",
    "    acc_train_cv = 0\n",
    "    for train_cv_index, val_index in kf.split(X_train):\n",
    "        X_train_cv = X_train[train_cv_index]\n",
    "        y_train_cv = y_train[train_cv_index]\n",
    "        X_val_cv = X_train[val_index]\n",
    "        y_val_cv = y_train[val_index]\n",
    "        hist = model_2.fit(X_train_cv,y_train_cv,batch_size=200, epochs = 3)\n",
    "        loss_train_cv = loss_train_cv + hist.history.get('loss')[-1]\n",
    "        acc_train_cv = acc_train_cv + hist.history.get('acc')[-1]\n",
    "        score_val_cv = model_2.evaluate(X_val_cv,y_val_cv, batch_size=200, verbose = 1)\n",
    "        loss_val_cv = loss_val_cv + score_val_cv[0]\n",
    "        acc_val_cv = acc_val_cv + score_val_cv[1]\n",
    "    loss_val_2.append(loss_val_cv/3)\n",
    "    acc_val_2.append(acc_val_cv/3)\n",
    "    loss_train_2.append(loss_train_cv/3)\n",
    "    acc_train_2.append(acc_train_cv/3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = units\n",
    "loss_train_2 = pd.Series(loss_train_2, index = ix)\n",
    "loss_val_2 = pd.Series(loss_val_2, index = ix)\n",
    "acc_train_2 = pd.Series(acc_train_2, index = ix)\n",
    "acc_val_2 = pd.Series(acc_val_2, index = ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEPCAYAAACk43iMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3gU1frA8W96BRJ6L6G8BERK6NIVRBRFFAsXC0Xk6rX3dq9d8SpeO/2HYgMVVBQBFWmhhw7hCIQO0gklhLT9/TETWUJCFrKb3bDv53n2yfR5dxbmnXNm5pwAh8OBUkop/xTo7QCUUkp5jyYBpZTyY5oElFLKj2kSUEopP6ZJQCml/JgmAaWU8mOaBPyMiNQWEYeIzM1n3gR7XvkL3OZPInJ3Ict0EZF1BcRz4kL250tEZJuItMxneksR+baAdfI9XiJSXkTc9sy2/Xs+7q7tFcX5jofyrmBvB6C8Ih0QEalljNmONRIFXOHdsC4dxpjlwM3ejsNX6PHwXZoE/FM2MAn4B/C6Pa0v8APwWO5CIjIUeNBefh/wL2PMnyJSFfgUqApsByo6rRMPvAeUA4KA940x4y8mSBEpA3wENAMcwC/As8aYLBF5CbgRyAAOAXcbY/YWND3PNncCDYwxf9nTlgAvAseBEXbcDuANY8x3LoR6r4iMtI/DRGPMcyLSBfjQGHNZIcerL/AakAYsy/P9BwP3YZXYD2Ed/40iMgE4BjQBagBrgDuNMQWWqERkEHAvEAqUBd40xnwiIr8Ck40xY+zlngfKGWMeKWT/ZYG6wE/GmKec9hMN/B9QH8gBkuz9dnI6HjOBSvYq0UAcIPaxGQ50xvoNVgIPGmOOne/gq6LR6iD/9Rlwh9P4XcCE3BER6QY8CXQ1xjQFvgS+F5EArBPzYmNMY6wk0dBeJxj4FnjaGJOA9Z/5cRFpe5Exvo918mkCtASa2turATwMtDLGtARmAW0Kmu68QWNMKjAVGGDHHA9UBmYCLwEj7NgHAd1cjDPd3l9r4DE7DmcFHa9KwHjgJnuf23NXEJHOWL9JR2NMc+AtO+5cCUBPIB6oDfQrKDj7xHwP0Mve1q329nJju8deLhAYDIx0Yf+RxpjGzgnAdiNQyhjTDGhlT4tzXsAYc7U9vw2wG3jGGLMJeBrIAhLsf3N7gDcL+l7KPTQJ+CljTBKQLSIJ9kmrlDHGuc6+JzDJGHPAXn4CUA3rhHMVdsIwxmwGZtvrNMC6OhwvIquAuUAE0Pwiw7wG6+rRYYw5DYy0p+0GVgMrRORtYJUx5vvzTM9rLNYJDmAgMN4YkwNMBj4SkS+wTrLPuhjnlwB2yWIfTlf6toKOVwdgrTFmgz0+ymmda4F6wEL7WL4FxIpIWXv+DGPMaWNMJrAW68o8X3YJ4TrgWhF5BXgO6wocYBpQSUSaAlcDW40xxoX9LyhgdwuAxiIyB+uk/j/7O5/FTjifA8nGmOH25OuAG4CV9j77AI0K+l7KPTQJ+LeJWFfEd9jDznKrRJwFACH29ACn6VlO66QaY5rlfoC2WNUDFyMwTwyBQIh9wu4M3I1VUnhXRN4qaHrejRpj5gPBItIa6I91NY4xZhRWqeNXrBPiGhEJdyHOTKfhvMcmv2lZTsMFTQ/CqlrKPY4tsEpDR+z5pwrZ599EpDqwCqiFdZJ+PneeMSYbK/kMsj8jXdx/vlVPxpitWMnjDaA08JuI9M5n0feAKOD+PN/5Iad9tkbvI3icJgH/9jlWNcKt2FezTmYAt4lIBQARGYh1Yt1szxtqT68JdLXXMcApEcmtaqkBrMO6qr4YM4F/iUiAiITZ+/zVvmpdh3UV+QbwLtCqoOkFbHss8AGwxhiz0453IdDcLvUMBWKwqoqKqqDjNQ/rqrmpPX630zozgdtFpIo9Pgz4/SL33xI4ALyKVUV2nR1LkD1/LFY1TgJnqnwuav8i8k+spD/LriqaiZVAnJd5GmgH3GInoVy5v3eoXVIYg5VMlAdpEvBjxpjdQDKwyRhzOM+8X7FOorNFZD1W9cl19tX2/UAjEUkGxmFdZWKMycAqzg8RkTVYJ5wXjDGJhYQSJSIn8nyaYNWfV8Sq7liLlWReM8asxqq6WS4iy7GuYB8taHoB+/wU64bzWKdpTwIvi8hKYA7wkjFmm/1446pCvsP5FHS8DmCVRL4QkRVAndwVjDGzsG6S/mofy/5AX2PMxTxCOgvYhXX8koGaWEmhnr2v/cBy4Cu7eqko+/8M64p+g4gkAWWw7u0AYN8kfx2rFDBPRFbZn+uBV4BtWDeEN2CVbh5DeVSANiWtlH+z3wtZBnTKLRUp/6ElAaX8mIjcg1U6+K8mAP+kJQGllPJjWhJQSik/pklAKaX8mCYBpZTyYyWq7aCkpCS9gaGUUhchISEh3xcKS1QSAEhIuNj3jopHcnIy8fHx3g6jUBqn+5WUWDVO9/P1WJOSkgqcp9VBSinlxzQJKKWUH9MkoJRSfkyTgFJK+TFNAkop5cc0CSillB/TJKCUUn5Mk4BS6m9zzH6avTyLJ79dzZ/7jns7HFUMStzLYkopzzialsGT364hNCiQH1fvYfLyXXSRCtzTMY72dcsREFBgD5aqBNMkoJQC4KVpGzh8MoPv77+CqjERfLF4O58u2s4/xi4hvkpphnSoQ++mVQkN1gqES4kmAaUUM9f/xdSVu3noyvpcVq0MAA9cWZ97OsXx46o9jJmfwmPfrOatmRu5q31t/tG6FmUiQ7wc9fntOXqK3UdPERESRHhIEBGhQUSEWJ+w4EACA7VkA5oElPJ7h09m8NzUtTSqUpp/dat31rzwkCBuaVWDfi2rM+fPA4ydn8JbMwwfzt7MLS1rMOiKOtQsF+mlyM/IzM4hee8xlm87QtKOI6zYfoS9qennXSfCKTGEhwSeSRKhwUSEBP49v2bZKK5vVpVqMRHF9G2KlyYBpfzcCz+sI/VUJp8PaUNIUP5VPQEBAXSVinSViqzfk8q4+Vv5fPF2Plu0jZ6XVWZIxzha1IwttpiPnMxgxY4jJG23Pqt3HSU9MweAajERtKxdloSaMdSpEE1GVg5pGVmkZ2ZzKiObU5k5nMrMJj0zm7SMLE5l5Fjz7PmppzLZl2qNp2Vkc/DEaYbP2EibOmXp26Ia1zSpQulw3y4FXQhNAqpESzlwgqDAAGqVi/J2KCXST2v28POavTxxtdCwcmmX1mlctQwjbm3Gkz0bMmHhNr5csp3pa/8ioVYs93SsQ/dGlQlyY1VLTo6DlIMnSNp+5O8r/ZQDJwEIDgygcdXS3N66Ji1rlaVFrRiqlHHvFfvOw2lMXbmbqSt389R3a3nhh/V0j6/Ejc2r0VkqFJg4SwpNAqrESj2VyY0fL+R4eibXNKnCfV3q0rhqGW+HVWIcOH6aF75fR9PqZbi3U9wFr1+5TDhPX9OQB7rVY/LynYxP3Mqwz1dQs2wkt7aqQemIol0tb9p2hJ2Ll7Jix1FST2UCEBsZQkKtWG5OqE5CzVgurx5DRGhQkfZTmBplI3nwyvo80K0eq3elMnXFLqat2cvPa/dSNiqU3pdXoVlsJg0bOkrkE1QeSQIiEgh8DDQFTgNDjDGbnebfDjwMZANrgPvsWQWuo1ReI+duIfVUJv3b1OTHVdYVbVepwP1d69Gydllvh3dBHA4HyXuPU79SdLFcWTocDp6bupaTGdm8c0tTgouwz6iwYAZeUYc729Vm5vq/GDM/hf/ONG6Js37FaK65rDIJtWJJqBVLnfJRXjvRBgQE0KxGDM1qxPD8dY2Y9+cBpqzczVfLdvJpVg4fLE2lT/Nq3Ni8GjXKev8+ias8VRLoA4QbY9qJSFvgHeAGABGJAF4Fmhhj0kTkK+A6O5Z811Eqr33H0vm/xK3c0Kwqr9/YhKd6NmTiom2MT9zGzSMX0bpOWe7vWo9O9cv7/NXZ4ZMZPP/9Wqav/YsuUoGRAxIID/Hs1e33q3Yza8M+nu3VkHoVS7llm0GBAfRqUoVeTapw+GQG2TlF6whwe8pmWjZt7JbY3C0kKJAr4ytxZXwljqVnMn7WChb/lcOIX/9kxK9/0rJWLDe2qMZ1Tar6/FNUnkoCHYAZAMaYxSLS0mneaaC9MSbNKYZ0oOd51lHqLO/9vonsHAePdRcAykSE8K9u9RnUoQ5fL93J6Hkp3DV+KZdVK839XepxdePKPvlI4O/J+3jqu7WknsqgT7Oq/LB6D4M/XcaYO1sSGeqZ/56H0rL4z7T1JNSKZXCHC68GckXZqNAib+NgaMmoay8dHsLV9Uvz8PXx7D56iu/t+wfPTV3HSz9uoGvDCtzdvg7t6pbzdqj5CnA43N9tr4iMBb4zxvxij+8A4owxWXmWewDoZX/GFLZOUlKSIzLSt4tZ6enphIeHezuMQpXkOHelZnDvD7u4VkpzX5vy+a6Xke3gj5TjTF57lD3Hs6hRJoR+l8XQNS6aYA8lgws5piczchi97BCzNh+nTmwoj3eoQFzZMH7bcpx3Ew/QqEI4L15ZmSg3nwgdDgcv/LqHdfsz+Oj66lQr7btXqSXl3yicG6vD4WDL4Qx+33KcOVtPcjQ9m+ukNIMTyhIeUvzJLS0trdj7GD4GOJcxA51P5vY9g7eABsBNxhiHiJx3nVy+3I8n+H5fo7lKcpwffrGC8JAg/n1TayqUCitw3aaXwQPXOZi+di8fz9nCiMQDTFp/gns7x3FLyxpur3Jx9Zgu2nKIx39Yzd7UU9zXpS4PXVWfsGArlvh4qF1jDw9PWsWrC47y6aDWlCniDVZnk5fvJGnvaf7TuxFXtanjtu16Qkn5Nwr5x9oI6N0B0jOz+e9Mw/jEraw9mMU7/ZoW+z0rb/QxnIh1dY9dv782z/xRQDjQx6laqLB1lGLNrqP8vHYvQzrGnTcB5AoKDKB306pMf7AD/3d3KyqXCeffP6ynw/DZfDxnM8fSM4shakt6ZjYvT9vA7WMWExIUwDfD2vNkz4Z/J4BcvZtW5eN/tGD9nlT6j1nM4ZMZbtn/nqOneGXaBppUCueudrXdsk1VuPCQIF64rhFf3dOW7BwH/UYt4o1fkknPzPZ2aIDnSgJTge4ishAIAAaKSH8gGlgODAbmA7NFBOC9/NbxUGyqBBs+YyNlo0K5p+OFXcUGBATQtWFFukgFlm49zEdztvDWDMMnc7ZwV7vaDGhbi8plPFf1sGbXUR6ZtIotB05yZ7taPH1Nw/PW+V/duDKj72zJsIlJ3D56MZ8PaeNS0iuIw+Hgqe/WkO1w8MgVFXzy/silrm1cOWY83InXft7AqLkp/LFxPyNuafZ3Mx3e4pEkYIzJAYblmbzRabigEkjeddziVEY2b/6SzH1d61GpdMmoY1Tnmr/pAImbD/HCdY0odZFvbAYEBNAmrhxt4sqxdlcqH8/ZzEdzNvPhH5tJqBVLryZVuOayylR1UxMBmdk5fDB7Mx/9sZmKpcL4fHAbOtTP/z5GXl2lIuPvbsWQT5dz6+hFfDmk7UUnqi+X7mD+poO80ucyqpRKK3wF5RHRYcG80fdyejSuzFPfrqHPR4k80K0+93Wt67WXzkrG7fciysjK4aulO/lg9iZvh6IuUk6Og+EzNlItJoIBbWu6ZZtNqpfhkwEJ/PFYFx7v0YC0jGxe+WkD7d+czY0fJzJmXgq7jlz8CfPPfce58eNE3v99Ezc0q8qMhzu5nAByXVGvPJ8Oas3+Y6e5ZdSii4pn5+E0Xvs5mQ71yjOgjXuOnSqarlKRWY904trLq/Dub39y0ycL2bzfO/03+EUSKBMZQt8W1fhm+S4Onjjt7XDURZi+bi/rdh/j0e4NzqlDL6ra5aP4V7f6/PJQR/54vAtPXC1kZufw2vRkOgz/gxs+XMDIuVvYcci1E3B2joMx81K47oMF7D2azsgBCYy4pdlF3+BtXacsEwe35mhaBreOWsz2QyddXjcnx8ET364mMCCA4Tdf7vPvTPiTmMhQ3rutOR//owU7D6fR6/0FjJ2fQk4R36+4UH6RBACGdoojIzuHCYnbvB2KukCZ2Tm8PdMglUrRp3k1j+6rTvko7u9aj58e6MjcJ7rw9DUNcQBv/rKRTv/9g+s+mM/Hczaz7WD+J+Idh9K4ffRiXpueTJcGFZj5SCd6Xla5yHE1rxnLl/e0JS0ji1tGLWLz/hMurffZom0sTjnMC9fFX7KtYJZ0vZpUYdYjnelUvwKv/pzMbWMWu3zB4Q5+kwTiKkRzdaPKfLZoGydOn/PkqfJhk5btZNuhNJ7sKW5tmKwwtcpFMaxzXX78VwfmP9mVZ3s1JDgwkLdmGLq8PYde783nw9mbSDlwAofDwfQ/j9HzvXkk7z3GO/2aMuqOBMpHX/zN3Lwuq1aGr4e2IzsHbhu9iI1/HTvv8tsOnuTNGRvpIhW4pWUNt8Wh3K9CqTDG3JnA2/2akrzH+nf05ZIdeOI9rrz8JgkADOtSl2PpWXy1ZIe3Q1EuSs/M4b3fN9GqdizdGlb0Whw1ykYytFNdvr//ChKf7sbz18YTERrE27P+pNs7c2n7xu98sOggzWvGMOORTtyUUN0jVS9SuRST7m1LUGAAt41ezLrdqfkul53j4PFvVhMaFMibfbUaqCQICAjg5oTqzHikE81rxvDs1LXc/X/L+KuQfhGKyq+SQLMaMbSLK8e4BVvJyMrxdjheszf1FEt3pZWIY/B9cioHjp/mqZ4NfeZEVi0mgiEd4/jun+1Z9Ew3/tO7EZdVLcN9bcoxcVAbj1e71K0QzeR72xEVGsztYxazcseRc5YZv2Ary7cf4cXrG3v00VflftViIpg4qA0v39CYJVsP0ePdufywarfHSgV+lQTAKg38dSyd71ft9nYoXrFp33Fu+DCR//z+F61f/41//7CO1TuPFkux80IdOZnBN+uOclV8RZ9tFbRKmQgGXlGHcXe3onfDMsX2/H2tclFMHtaOslGhDBi7hKVbD/89b/P+E/x3lqF7I6vNe1XyBAYGcGe72vzyUCfqVYzmoa9XMd5D9zP9Lgl0ql+eRlVKM2rulmK/C+9t63ancuvoxTiAxzpUoEO98ny9bCc3fJRI93fn8cmcLR4vel6Ij+ds5lSmgyeubujtUHxStZgIJt/bjsplwrlr/FISNx8kKzuHx75ZTWRoEK/deJnPlJ7UxalTPopvhrXnrZsup2Utz/Tc5ndJICAggHs7x7HlwEl+Td7n7XCKzfJth7l99GIiQoL45t52XFW3FB/2b8Gy567ijb5NiIkIYfiMjbR/83fuGLeE71fu5lSG915r33P0FJ8u2s6VdaORyu5p6vhSVKl0OJPubUetcpEMnLCMhyatYvXOo7xyw2VULKXVQJeCoMAAbmlVg6Y1Yjyyfb9LAgDXNqlCjbIRjJy7xSerQdxt/qYD3DFuKRVKhfHNsHbULn+mK8YyESHc3rom3/6zPXMe78K/utYj5cBJHp60ilav/caT365mScqhYi81/e+3P8EBA5oVX7+1JVX56DC+uqctDSpF8/OavfRqUpnrLq/i7bBUCeGX3UsGBwUytGMcL/ywnqVbD9Mmzjfb+XaHmev/4oEvVxJXIYqJg8/f/kzt8lE82kN4+KoGLNl6mCkrdvHzmr1MXr6LGmUj6Nu8On1bVPN4f76b9h3n26RdDLyiDpWitTrDFbFRoXwxpC1fLd3Bba1qaDWQcplflgQA+rWsQbmoUEbO3eLtUDzm+5W7ue+LFTSqWppJQ9u53ABZYGAA7eqW47/9mrLs+at499am1CobxfuzN9H5v3PoN3IhXy/dwXEPtcD535mGyNBg7u9azyPbv1SViQhhWOe6xEQWvUMX5T/8NgmEhwRxd/va/GEOFPrSTUn0xZLtPDJ5Fa1rl+XzIW0uuou7yNBgbmxenc+HtCHxqW48cbVw6GQGT09ZS6e3/mDy8p1urSpK2n6EWRv2MbRTnFt6p1JKnZ/fJgGAO9rVIjI0iFFzU7wdiluNnreF56auo6tU5P8GtiI6zD21flVjIri/az1+f7Qz3/2zPfUqRvPkt2u4dfQizF9Fb/zK4bAaiSsfHcbgDr7d4YlSlwq/TgIxkaH0b12TH1fvYefhkt+8rsPhYMQsw+vTN3Lt5VU81mF5QEAACbVimTS0HW/ddDmb9p/g2vfn8+YvG0nLuPgmOeaYAyzdepgHr6xHlJsSl1Lq/Pw6CQAM7liHwAAYt2Crt0MpEofDwSs/JfP+7M3c0rI679/WnNBgz/68gfaja7Mf60LfFtUYOXcL3UfM47cNF/7obW5T0TXLRnJbK23uWKni4vdJoEqZCG5oVo2vl+1wWzd+xS07x8EzU9YyPnErA6+ozZt9Ly/WhtbKRoXy1s1NraYMwoIY8tlyhn62nN1HT7m8jR9X72HjX8d5rEcDjycvpdQZ+r8NGNY5jvTMHD5duM3boVywzOwcHvp6JV8v28kD3erx7+saea3rwNZ1yvLTAx15qmdD5m06QPcRcxk9bwuZ2edvoygjK4d3fjU0qlKa3pdXLaZolVKgSQCAehVLcVV8JT5dtK1IddrFLT0zm2ETk/hpzV6evqYhj/UQrz8fHhocyD+71OXXRzrTvm45Xp++kd4fLCBp++EC1/lyyXZ2Hj7Fkz1F+75VqphpErD9s0tdjqZl8vXSnd4OxSUnT2cxaMIyZpv9vNLnMoZ1ruvtkM5So2wkY+9qxeg7Ejh2KpObPlnE09+t4UieKrcTp7P4YPZm2saVpXODCl6KVin/pUnAllArlta1yzJuwdZCqy+8LTUtkwHjlrBk62FG3NKUO9rW8nZIBerRuDK/PtqZoZ3i+CZpF1eOmMu3Sbv+bq5j7PwUDp3M8KmmopXyJ5oEnAzrEsfuo6eYtnqPt0Mp0K4jadw2xupM5KP+LbixeXVvh1SoqLBgnu0Vz08PdKBO+Sge/2Y1t41ezOKUQ4yZl0LPxpVpXlPbCFLKG/RhbCddpSJSqRSj5qZwY/NqPnVlumHPMUbP28JPa/YSHBTA2Ltalbjqk/gqpfnm3nZMXr6TN37ZyG2jFxMYAI9fLd4OTSm/pUnASW4z049OXs0fZj/dGlbyajwOh4PEzYcYNW8L8zcdJDI0iDvb1WZwxzolttPwwMAAbmtdk+6NKvHub39SLSaSehWjvR2WUn5Lk0AevZtW5Z1Zf/LJnC1eSwJZ2Tn8vHYvo+amsGHvMSqUCuOJq4UBbWpddBtAvqZcdBiv9mni7TCU8nuaBPIICQpkSMc6vDRtA0nbD5NQq/i6NTx5OotJy3YybsFWdh89Rd0KUQy/qQl9mlcjLNj9zT8opZQmgXzc2qoG7/++iU/mpDD2Ls8ngf3H0/l04TY+X7yD1FOZtKody0vXN6Zbw4r63LxSyqM0CeQjMjSYO9vV5r3fN7Fp33HqV/JM94ZbDpxgzLwUpqzYTWZODlc3qszQznG00CdllFLFRJNAAe5qX5tR87Ywal4Kb/dr6tZtL992mFHzUvh1wz7CggPp17I6QzrGUae8Z3vsUkqpvDQJFKBsVCi3tarJF0u282j3BlQt4tM4J09nMXP9X3y+eDsrdhwlJjKEB6+sz53talE+2rUev5RSyt00CZzHkI51mLh4O+MWbOWF6xpd8Po5OQ4WpRziuxW7mLHuL9IysqlVLpKXrm9Mv5bViQzVw6+U8i49C51H9dhIrm9ala+W7uCBbvVc7rt18/4TTFmxi+9X7mZPajqlwoK5oVlV+raoTstasT71EppSyr9pEijEvZ3jmLpyNxMXbeeBK+sXuNyRkxlMW7OHLxJ3Yw6mEBQYQKf65XmmVzzdG1XySA9fSilVVJoECtGwcmm6SgUmLNzGPZ3izjqZZ2Tl8IfZz5QVu5i9cT+Z2Q7iYkN5/tp4rm9WlYqlwr0YuVJKFU6TgAv+2aUet4xaxDfLdzKgbS3W7Eplyopd/Lh6D0fSMikfHcZd7WrTt0V1AlJ3Ex8f5+2QlVLKJZoEXNCqdiwtasbw/uzNfLpoO5v3nyA0OJAejSpxU4vqdKxfnuAgq0HW5NTdXo5WKaVcp0nABQEBATx4ZX0GTlhG7XKRvNG3Cb2aVKFMxKXRjo9Syn9pEnBRF6lI8ss99QavUuqSop3KXABNAEqpS40mAaWU8mMeqQ4SkUDgY6ApcBoYYozZnGeZSOBXYLAxZqM9bSWQai+y1Rgz0BPxKaWUsnjqnkAfINwY005E2gLvADfkzhSRlsBIoLrTtHAAY0wXD8WklFIqD5eSgIhUAWKBLOAp4ANjzKrzrNIBmAFgjFlsn/SdhQE3AhOdpjUFIkVklh3Xs8aYxS59C6WUUhfF1ZLAZ8DrwP3At8C7QNfzLF+aM9U6ANkiEmyMyQIwxiQCiJzVwXga8DYwFqgP/CIikrtOruTkZBdD9o709HSfjxE0Tk8oKbFqnO5XkmLNy9UkEAzMA54zxnwtIvcVsvwxwLknlsC8J/N8/AlsNsY4gD9F5BBQBdjpvFB8fLyLIXtHcnKyz8cIGqcnlJRYNU738/VYk5KSCpzn6tNBocAIYJ6IdKXw5JEI9AKw7wmsdWEfg7DuHSAiVbFKE3tdjE8ppdRFcDUJ3A0YYDhQARhQyPJTgXQRWYhVdfSIiPQXkaHnWWccECMiC4BJwCAXSg9KKaWKwNXqoD3Aj0AMIMCS8y1sjMkBhuWZvDGf5bo4DWcA/V2MRymllBu4WhL4AmgB/BfIBEZ7LCKllFLFxtUkEAtMA6oZY97EesRTKaVUCXchN4YfA1aISCMg2nMhKaWUKi6uJoHHgIrAq1jvBxT2iKhSSqkSwKUkYIxZCMwFhgK7jDFLPRqVUkqpYuFSEhCRN4CBWDeF7xKRdzwalVJKqWLh6iOinYwxVwCIyHuAtumjlFKXAFfvCYTYzUMDBAAOD8WjlFKqGLlaEpgEJIrIYqCNPa6UUqqEcykJGGPeEZGZQENgnDFmnWfDUkopVRzOmwTsG8J5q35aiAjGmGc9F5ZSSqniUFhJ4Jz2fpyJSJgx5rQb41FKKVWMzpsEjDGfFrL+L0A394WjlFKqOLn6dFBBAtwShVJKKa8oahLQR0WVUqoEK2oSUEopVYJpdZBSSvkxV9sOqlTArA1ujEUppVQxc/WN4e9E5ABWP8DT7e4jMTULeFMAAB0BSURBVMbc77HIlFJKeZyrTUl3AJ4FOgMLReQ1EYnzaGRKKaU87kLuCewBUoA04DLgPRF52SNRKaWUKhau3hOYDCzC6mt4gDHmBmNMb6CXJ4NTSinlWa7eExhjjPk1n+kd3BmMUkqp4uVqEkgTkVVAJWA3cI8xZqUxJt1zoSmllPI0V+8JvA/0N8ZUAe4GPvJYREoppYqNq0ngqDFmA4Ddl0Ca50JSSinvmjJlCm+//ba3w+CKK67w+D5crQ7aLyJjgdlAAhAoIkMBjDGjPRWcUkopz3I1CeT2K1APOAbMBaqgDcgppTzsu6RdTF6+063bvKVlDW5KqF7ocuPHj+fnn38mODiYli1b8sQTT5CUlMTw4cMJDg6mdOnSvP322+zevZuXXnqJ4OBggoKCeOutt6hU6dyGFjIzM+nVqxc//PADkZGRjB07luDgYNq3b8+bb75JTk4Ox44d4/nnn6dFixZu/c4FcbV7yZdE5FqgsTVqfvBsWEop5V3bt29nyZIlfP311wQHB/PAAw/wxx9/sHTpUrp3787gwYOZPXs2x44dY/Xq1TRu3Jinn36a5cuXk5qamm8SCAkJoUePHsyaNYs+ffowffp0xo0bx6JFi3jqqacQEaZNm8aUKVN8KwnY3UzWBxYAd4lIR2PM4x6NTCmlgJsSqrt01e5uycnJdOnShZCQEABatmzJpk2bGDZsGCNHjuSuu+6iUqVKXH755Vx11VXMnz+fIUOGUKpUKR555JECt9uvXz9efPFF4uLiqF27NrGxsVSsWJGPP/6Y8PBwTp48SXR0dHF9TZdvDHcyxtxsjPkfcBPQ0YMxKaWU18XHx7NmzRqysrJwOBwsW7aMOnXqMG3aNG688UYmTpxI/fr1mTx5MkuXLiUhIYFPP/2Unj17Mnbs2AK3W7t2bRwOB2PHjqVfv34AvPbaazz44IMMHz6cBg0a4HAUX027q/cEQkQk0G44LgC9F6CUusTVqlWLFi1acPvtt5OTk0NCQgJXXXUVa9as4emnnyYyMpKQkBBefvllNm3axP/+9z8++OADAgMDeeaZZ8677Ztvvpn33nuPtm3bAnD99ddz3333Ua5cOSpXrsyRI0eK4ysCrieBSUCiiCwG2gBfey4kpZTyrr59+/49PHDgwLPmNW3alClTppw17cSJE0yaNMnl7ffu3ZvevXuftY+8+wFITEx0eZsXy9Uk8BMwE2gIjLPfFVBKKZWPjIwMBg8efM70OnXq8PLLvtXupqtJYJzdnLSe/JVSqhChoaFMnDjR22G4xNUkcFJE3gUMkNuhjL4kppRSJZyrSWCh/Tf3wVe9MayUUpcAV5NAtjHm1dwR+70BpZRSJdx5k4CIDAaGAPEiktuBTCAQCpz/GSillFI+r7CXxT4Hbgcm239vB/oB7Twcl1JKeY0nWxHds2cPs2fPdnn51157jT179ngkFiikJGCMOQ1sE5FhQEsg3J5VB5hX0HoiEgh8DDQFTgNDjDGb8ywTCfwKDDbGbHRlHaWUKukWL15MSkoK3bp1c2n55557zqPxuHpP4FugIpDblJ+D8yQBoA8QboxpJyJtgXeAG3JnikhLYCRQ3dV1lFJ+atVXsPJz926z+QBodnuhi7m7FdHs7GxGjx5Neno6zZs3Z8KECcTGxnLs2DE++OADnn/+eY4fP86RI0fo168f/fv354477uDFF19k+vTp7Nq1i0OHDrFnzx6eeeYZOnYsegs+riaBysaY9hew3Q7ADABjzGL7pO8sDLgRmHgB6yilVLHxRCuiQUFBDB06lJSUFK688komTJhA79696d69O+vXr+faa6+lR48e7Nu3jzvuuIP+/fuftX5oaChjx44lMTGR8ePHF2sS2CgiVY0xrlZMlQZSncazRSTYGJMFYIxJBBARl9fJlZyc7GII3pGenu7zMYLG6QklJdYSF2dYM2jbzP07OM8x2LNnD6tXr6ZVq1Zs3mzVSteoUYOFCxfSo0cPvvnmG/r160e5cuW466676NChA9OnT+f2228nKiqKAQMGkJ2dXeC2Dx06RHJyMidPnsThcJCcnMzRo0f57rvv+Pbbb4mIiCAtLe3vZVJSUjhw4ACxsbEkJyeTlpbGkSNH3PI7upoEOgA7ROQgVlWQwxhT9TzLHwNKOY0H5j2ZX+w68fHxLobsHcnJyT4fI2icnlBSYtU4Xdt306ZN2blzJ/Xr1ycoKIgPP/yQPn36YIxhyJAhNGjQgFGjRrFy5UrCwsLo2bMnL730Ej/99BOzZ8/mjTfyf5LeGENaWhrx8fFERUVRt25d6tatyxtvvEHnzp3p378/ixcvZs2aNX8vExcXx8aNGylfvjzx8fGEhoYSFRXl8vFJSkoqcJ6rnco0cGlPZyQCvYHJdv3+Wg+to5RSHuGpVkQbNGjAJ598QuPGjc+a3rVrV1588UWmTZtGTEwMQUFBZGRkePprEuBKu9Ui0hjrRm4M8AWwzhjz03mWz33S53KspqcHAi2AaOfmJkRkDjAsz9NBf69jjNnovN2kpCRHQkLCBX3B4qZXWe5VUuKEkhOrxul+vh5rUlISCQkJAfnNc7U66H2sE/kYYBzwC1bLovmy+x0YlmfyxnyW61LIOkopVeJciq2IYozZLCIOY8wBETnuyaCUUqokK0mtiLraveRhEbkXiBKR24CjHoxJKaVUMXE1CQzGekv4INabw+eWc5RSSpU4rj4ddAx4Ou90EZlqjLnR7VEppZQqFq6WBAoS45YolFJKeUVRk4B2LqOUUiVYUZOAUkqpEkyTgFJK+bGiJoEjbolCKaWUV7j0dJDdbERpIAd4HXjdGPO7MeYmTwanlFLKs1wtCYzE6u3reeA54D8ei0gppVSxcTUJZALrgVBjzGIuoLkJpZRSvsvVJOAAvgSmi8gtwEnPhaSUUqq4uHpFfyvQGqv10M72uFJKqRLO1ZJACLANqA/cAdT0VEBKKaWKj6tJ4DOgEtaTQb8C73osIqWUUsXG1SQQDMwDYowxXwNBngtJKaVUcXE1CYQCI4B5ItIVfTpIKaUuCa4mgbsBA7wJVAAGeCogpZRSxcfVJJCC1fn7u0AVYJfHIlJKKVVsXE0Co4E4rJvCtYGxngpIKaVU8XG1br++MaaTPfy9iCz0VEBKKaWKj6slgXARiQQQkQj06SCllLokuFoS+B+wWkTWAY3QBuSUUuqS4GoS2Au0wbovsNUYc8hzISmllCouriaBl+x7Aoc9GYxSSqni5WoScIjIVKx3BXIAjDHPeiwqpZRSxcLVG8O/AHOAZOAu4KCnAlJKKVV8XE0CfYFfjTGfAh2BPp4LSSmlVHFxNQlkGWM2ABhjUrCrhJRSSpVsrt4T2C4irwOLsDqX2e25kJRSShUXV0sCA4H9QC/gADDIYxEppZQqNi6VBIwx6VgvjCmllLqEuFoSKNkyT8GcN+HEAW9HopRSPsU/kkDWaVjwLkx/3NuRKKWUT/GPJBARAx0fgw3fw6bfvB2NUkr5DP9IAgBXPATl6sH0x6zqIaWUUn6UBILD4Np34Mg2mD/C29EopZRP8J8kABDXBZr0g8T/wcFN3o5GKaW8ztWXxS6IiAQCHwNNgdPAEGPMZqf5vYF/A1nAeGPMGHv6SiDVXmyrMWag24Pr8Rr8OQt+fhTu/BECAty+C6WUKik8kgSw2hYKN8a0E5G2wDvADQAiEoLVYX0r4CSQKCLTgKMAxpguHorJUqoSXPmC9aTQ2m/h8n4e3Z1SSvkyT1UHdQBmABhjFgMtnebFA5uNMUeMMRnAAqxG6ZoCkSIyS0Rm28nDM1oOgqotYOYzcOqox3ajlFK+zlNJoDRnqnUAskUkuIB5x4EyQBrwNnA1MAz4wmkd9woMguvehbRDMPsVj+xCKaVKAk9VBx0DSjmNBxpjsgqYVwqrKuhPrBKCA/hTRA4BVYCdzhtOTk52U4hhVKp3E7HLxrGtTDvSyzV2y1bT09PdGKPnaJzuV1Ji1TjdryTFmpenkkAi0BuYbFfrrHWalwzUF5GywAmgE1YJYBDQBLhPRKpilRj25t1wfHy8+6Ks8w58OJ8669+He/6wSghFlJyc7N4YPUTjdL+SEqvG6X6+HmtSUlKB8zxVHTQVSBeRhVg3gR8Rkf4iMtQYkwk8CszEapp6vDFmNzAOiBGRBcAkYJBT6cEzwstAz9dh72pYNtaju1JKKV/kkZKAMSYHq17f2Uan+dOAaXnWyQD6eyKe82rcF1Z+Dr+/AvHXQ+kqxR6CUkp5i3+9LJafgADo9TZkZ8DMZ70djVJKFStNAgDl6kLHR2H9FNj8u7ejUUqpYqNJINcVD0PZutZLZJnp3o5GKaWKhSaBXCHhVgNzh1OsvgeUUsoPaBJwVrcrXHYzLBgBBzcXvrxSSpVwmgTyuvp1CA63+h1wOLwdjVJKeZQmgbxKVYIr/w0pc2Ddd96ORimlPEqTQH5aDoKqza1HRrWBOaXUJUyTQH4Cg+DaEXBiP8x+1dvRKKWUx2gSKEi1FtD6Hqs5id0rvB2NUkp5hCaB8+n2PERXhJ8egZxsb0ejlFJup0ngfMLLWE8L7V0Fy8Z5OxqllHI7TQKFuewmq4P62a/A8b+8HY1SSrmVJoHCBARAr3cgK10bmFNKXXI0CbiifD3o8Kj13sD398HJQ96OSCml3EKTgKs6PW4lgjWT4MOWsOpLfaNYKVXiaRJwVVAIXPUfuHc+lK8P3/8TPu2tbQwppUo0TQIXqlIjGDgDrnsX9q6BT9rBnOGQddrbkSml1AXTJHAxAgOtpiX+tQzie8Oc12FkB9iW6O3IlFLqgmgSKIpSleDm8fCPb62nhyb0osrS1yDtsLcjU0opl2gScIf63eG+JXDFw5TZNt26cbz6a71xrJTyeZoE3CU0Erq/xNYeE6BsHEy9Fz67Hg5t8XZkSilVIE0CbnY6pj4MmmW1QrpnNXzcDua+pTeOlVI+SZOAJwQGQqvB8K+l0LAX/PEajOwI2xd6OzKllDqLJgFPKlUZ+k2A/t9A5in4v2vgu3tgxUTYtRxOH/d2hEopPxfs7QD8QoMeUHsxzHkTlo6BtZPPzCtdHSo2hAr2p2I8VBAIK+W9eJVSfkOTQHEJjYIer8BVL8KRbXBgI+xPtv4e2Ahb50O2032DMjWsZPB3YmioyUEp5XaaBIpbYBCUq2t9Gl57ZnpOdp7kYOBAMmxbYL2DkKtMDevpo4hYiIix+jwIt/+eNe40LSik2L+mUqpk0CTgKy4kORzZBsf3QnoqnDp6dgkiPyGR5ySKylmhkNoeKjaCSo0hqrwnv51SykdpEvB1BSUHZ5npkH70TFJIT80zfvTs8WN7KHVkB6T8eGYbURWtZFCpsZ0YGllVUCERxfM9lVJeoUngUhASDiGVraeRXLRpwwbia5SD/eth3wbYvwH2rYdlY89UPwUEWlVPFRtBpcusxFCxEcTWsR6DVUqVeJoE/FVAgNX2UalKULfbmek52XA4xUoIuYlh3zpIngbYzWCERFqlhHJ1IbI8RJa1P+XO/kSUheBQr3w9pZRrNAmoswUGWf0llK8PjfucmZ5xEvZvdCo5rIedS+HUETh9rODthZbKP0FExtp/y0N0RYiqYH3CSlkJSilVLDQJKNeERkH1BOuTV1YGnDpstZ6adsjpk3f8IBw01vSME/nvJzj8TEKIrkiVzBDYXf/sRJE7HFFWq6WUKiJNAqrogkOt+xEXcE+CzPQzieHkAThxwPp7cv+Z4WO7iTq6F7ZNB0f2udsICLKeaoqItZ58CittPyJb+uzh8Bh7vPTZy4VGaalD+T1NAso7QsKhTDXrcx6bk5OJF7Gebjqx/9xEcXK/VSWVfswaP7zFGk5PhZzM88cQEGRVP+UmhOAwqySS+wnJHQ6D4Igz8wuYHr1rB+RshOwsyMmy9p+daQ1nZ9rjztMzz142J8vaXlgpCIu2qtLCoq3x0Dx/w6Kt4cAgN/4oyh9pElC+LzDwzM1nGrq2jsNhPeWUmxBO23//Hs4zPTPNauk185R1/yPtoDWelW6VWrJOQ9YpyM4ocJc1Lug7BUNgiPUiX2CQNRwYbMWRccJKCK4IicyTGEo5JanchGUnqpAICA6n7OFUOFHLaZmIMwktd/ncd0pCIj1bWsrOso71if12ct//d7KvvH8PHGgMMTWtlyRjakCpKpr43EyTgLo0BQRYJ7eQCOsJKHfJybESw1kfK3ls3badOvUa2Cd355N83vHg859YHQ5rmxknrCR1+oQ9bI/nDmecsBohPH3caf5x655LbmyZ6Vbyyk1wOKgEsMrF7xsYcu7b6K4MB4c7ndwPwIl9Tid4uyR3Yp9VJUg+nS8FR1AqMAS2TDl7ekAQlK5mJYTcxOD8t0x177zb4six3sE5dcQumToNnzpiJbvgUAgKg6BQp+EQKwEHhdrTnYadlwsOsx6k8EBC1iSg1IUIDLQ6EAqNPGdW+rEIqBRf9H0EBNjvfoS7901uhwOyMzHrVyN1a1lJ4axkkTucdu6Lh87DR7adefnQ1RILWCWM6IrWJ7Y21GgF0ZXO3Ox3Hg6NZtPGjcTXrQmpu+DoTkjd4TS802pS5fge6wTsLKrCmcQQVcEuZQXZn2A7CTuPO00PDLLnOY1nZ559Qs97gj91hIbpqefG4W7dXoBOj7t9s5oElPIXAQEQHEpOaLR1oi0qh8OqOjvn7fRUK8FElbfeRM898YdGX/iVbGiU3ZCi5D8/O8tKBLmJIXXnmeF9G6ySRk629WBBTtaZz0UJsEtFdrtdEbFWMouI5dDJbMpXr2fPc/7Y7XgFhVpVibmfrNN5hjOt5l+yM6yn7c4ZzoQGV19k3OfnkSQgIoHAx0BT4DQwxBiz2Wl+b+DfQBYw3hgzprB1lFI+JiDAvnEdbVXDeENQsHXPIKam6+s4HNZVe06exODIOXs8J9v6BAadeQKtgPsRB5KTKR9fSCkw0C7d+RhPlQT6AOHGmHYi0hZ4B7gBQERCgHeBVsBJIFFEpgHtC1pHKaXcJiDgTHUQ+ka7p9606QDMADDGLAZaOs2LBzYbY44YYzKABUDHQtZRSinlAZ4qCZQGUp3Gs0Uk2BiTlc+840CZQtb5W3JysodCdo/09HSfjxE0Tk8oKbFqnO5XkmLNy1NJ4Bjg3AVWoNPJPO+8UsDRQtb5W3xh9W5elpyc7PMxgsbpCSUlVo3T/Xw91qSkpALneao6KBHoBWDX7691mpcM1BeRsiISCnQCFhWyjlJKKQ/wVElgKtBdRBYCAcBAEekPRBtjRovIo8BMrCQ03hizW0TOWcdDsSmllLJ5JAkYY3KAYXkmb3SaPw2Y5sI6SimlPEjb4VVKKT8W4HDk026Hj0pKSio5wSqllA9JSEjI93XtEpUElFJKuZdWBymllB/TJKCUUn5MWxEtArsdpPFAbSAMeBXYhfXk0yZ7sU+MMZO8EqATEVnJmTeytwKvAROwGnNfB9xvP6HlNSJyN3C3PRoONMNqU8pnjqeItAGGG2O6iEg98jmGInIPcC9WA4mvGmN+8oFYmwEfANlYDTTeaYzZJyLvA1dgvbkPcIMxJjX/LRZLnC3I5/f2hWOaJ86vgdz+VGsDi40xt/nC8bxQmgSKZgBwyBhzh4iUA1YCLwMjjDHveDe0M0QkHMAY08Vp2o/A88aYOSIyEquxvqneidBijJmAdVJFRD7CSrAt8JHjKSJPAndgNXwIMII8x1BEFgEPYrV9FQ4sEJFfjTGnvRzre8ADxphVInIv8BTwKNbxvdoYc7A44ztPnOf83iJSGS8f07xxGmNus6fHAn8AjzjF77XjeTG0OqhovgFecBrPAhKAa0VknoiME5FS+a9arJoCkSIyS0Rm229kJwBz7fm/AFd5Lbo8RKQl0NgYMxrfOp5bgL5O4/kdw9ZAojHmtH0FuBm4vFijtOSN9TZjTG5/YsFAut18e31gtIgkisig4g6S/I9p3t/bF45p3jhzvQR8YIzZ6yPH84JpEigCY8wJY8xx+x/qt8DzwFLgCWNMJyAF+I83Y7SlAW8DV2O9kPcFEGCMyX00LLcRP1/xLNZ/LvCh42mM+Q5w7r0+v2NYUAOJxSpvrMaYvQAi0h74F1Zz7lFYVUQDgJ7AfSJSrCfXfI5pfr+3149pPnEiIhWBK7FLr/jA8bwYmgSKSERqYBUHJxpjvgSmGmNyW2uaCjT3WnBn/Al8boxxGGP+BA4Bzh3v5jbi53UiEgM0NMb8YU/yxeOZy/keSkENIfrSsb0VGAlca4w5gHVx8J4xJs0YcxyYjVVq9Kb8fm9fPaY3A18aY7LtcV88noXSJFAEIlIJmAU8ZYwZb0+eKSKt7eErgYKb7ys+g7A66UFEqmJdWc0SkS72/GuA+d4J7RydgN+cxn3xeOZamc8xXAp0FJFwESmD1X/GOi/F9zcRGYBVAuhijEmxJzfAql8Psh9y6ACs8FaMtvx+b588pljVf784jfvi8SyU3hgummeBWOAFEcm9N/Ao8D8RyQD+AoZ6Kzgn44AJIrIA60mWQcBBYIzdkmsyVnWWLxCsaoBc/wQ+9LHjmesx8hxDY0y2/YTIfKyLrOeMMeneDFJEgoD3gR3AFBEBmGuM+Y+IfAEsxqrq+MwYs957kQL5/N7GmGO+dkxtZ/1bNcYk++DxLJS+MayUUn5Mq4OUUsqPaRJQSik/pklAKaX8mCYBpZTyY5oElFLKj2kSUD5DRO4WkTfzTPvafgTTeVpPEZmQz/pfOz23X9RYJohIT3dsy91EZIr9t4mIdLrIbcy0/34oIg3dGZ8qWfQ9AeXTchvqUmcYY3LbsLkJ61n6eReyvt3oWe4btw0A477oVEmjSUD5mrYiMguoAHyC9UJeQ6AOVquiJ+3PEQARuR8YAuwFKtrTQrCaR6iPVdrNbelzDVaDb5djvTRXaDO/IlIaGAvEAOWBMcCXWG+CNrBfDhsOLAc2Yr2UFYDVNMcgrGYPhgMZwGhjzMR89tEFGObUMuVfxpjKdmnnNFZTxVWAu40xK0TkL6yG1u4GMkRkBVYrsN3s7/uVMeZ/BXyf54B/AIEikgjUA17BavdK+SGtDlK+JhOrobsbgYedpr8C/NsYcxWwEMBuQuAhoC3WSTC32mgIcNBuhOwG4CN7emmsE2RnYDdWUw+FqQd8bYzpAVwHPGonjgXA1fbbuNcAP2AliPvtJrunA0/a2wg3xnTMLwG4YLsx5mqshsn+flvaGLMbq+GyEcaYpcCdQH+sZjdOFbQxY8xrWG+HDwSeAT40xmgC8GNaElC+ZoUxxmFf7UY6TW+M1YYMQCJW+zENgfW57cqLSO78JlhtzbSxx4Pt/h7A6vMBYCdW2/SF+Qt4WET6YjVkFmJPH4PVxn0g8JsxJkNE4oGP7WYZQrAa7oMLr25x7hDcOd4rzrPObcAbWB2d/FLQQnZJ4D6gC1AdOCYiYZoI/JeWBJSvKagdk41AO3u4lf03BWgkIhH2FXlzp2W/sq/Ir8Hq9+FIIdsvyOPAImPMAHs7AQDGmAVAXWAwVttMYJ3s77T3+yTwsz29sB7b0rGqexCRWkBZp3nnizcHq1onDOgH3I5VJXS3vZ38vA4k2aWkVVgNymkC8GOaBFRJcR/wrIj8DrQBsJtD/jdW9dAvnOmdahTQUETm2vO2F6HrzGnAQ3bjew8DWfZJF6x+GSo7NRL2T+AzEZkPvAmscXEfy4GjIrIEqx+FrS6ul4TVMmh74DDWSX02Vsu2OwpYpwFWpywA0cYYX2iSWXmRNiCn1EWyuxw86NSMuFIljt4TUH7Lfv9gVj6zjDHm3kLWnYD1tFB+XQ4WtM6/sapr8hpojHH16t/VfQ3FulGc1zPGmEXu3Jcq2bQkoJRSfkzvCSillB/TJKCUUn5Mk4BSSvkxTQJKKeXHNAkopZQf0ySglFJ+7P8BrQEUBvtEW3AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(loss_val_2, label = 'loss_val')\n",
    "ax.plot(loss_train_2, label = 'loss_train')\n",
    "ax.legend()\n",
    "plt.xlabel('hidden_layer_units_#') \n",
    "plt.ylabel('cross_entropy_loss') \n",
    "plt.title('Model Loss vs. hidden layer size')\n",
    "fig.savefig(\"loss_cv_2.png\",dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEPCAYAAACk43iMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU1fn48U/2hSRACAkgyO5DQAGFCm4IImrrXutSlyrWqq39tXVfWtva2q9tvyJttdTiUvRbcavSFhUExH1BjaAI4WEVWRMgQBLCZJ3fH+cODCHLADOZCfO8X695zcw59848cwPnuffce89J8Pv9GGOMiU+J0Q7AGGNM9FgSMMaYOGZJwBhj4pglAWOMiWOWBIwxJo5ZEjDGmDhmSeAwICJ9RMQvIm83UTfNq8s7wM98RUSuaWWZsSLy5QGGG7e8v1NlM3U3ishdzdRVikifJsq/IyJvhTG+r0RkZLg+71C0tD1MeCVHOwATNj5ARKS3qq7FvekAnBTdsEwoVPXRaMcQS2x7tB1LAoePeuB54Argf7yybwP/AW4NLCQi1wM/8ZYvAX6sqstFpAfwFNADWAvkB61TCPwZ6AIkAX9R1SebC0REEoHJwGggG0gArlPV90UkC3gYl5zqgH8DPwc6NFP+D+BLVX3Q++xpgfci8hWwABgK3APUes+pXvxPqeq93nrXetuhHtgKXA38EihV1Z97y1wJXKSqFwb9ljOASap6jPe+E7AG6AdcBtwI1OCS8A2qurS57eJJEpFHgeOBjsAdqvqSiPwayFPVH4vIKd628AOfEHTELiK/wf2NtwErgspTgT8Ap+L+RguBn6hqubedpgHjgSOBpwPbpSnN/f2ARcB6YJSqLveWnefFOquV79/zd1LVGUHfNQh4Akj3vudxVZ0S2B7eZ84MCq8bUKuqvUTkCOAR7zelAM+p6v9gDoh1Bx1engauCnp/Ne4/PwAichpwBzBOVYcB04F/i0gC8FfgI1UdgksSg7x1koF/AXep6gjcf/LbRGR0C3GMwiWTE1R1MC65BA7tf4P7D18IDMc1+qe2UN6aL1W1EJc0bgWuVtWRuAbsbhHJE5FhuMbkLFUdCvwXl2D+Ckz0fiPA9UDjPdC5QFZQN8l3gVeBcuBP3md+A5gKnBxCvOnAXFU9DrgN+GNwpdeYvwjcqqrHAm8CGV7d+cBFuO1zIi6JBNyFS54jvL/tRuD3QfVZqnqKt95tItK3hRib/Pup6i7v9XVePP2Bo4BXQvj+L1W1MDgBeG4HZnr/tr4FjPGSEACquk5Vh6vqcOBCXLK9wqv+P+BJb93jgdNF5JIWfpdpgiWBw4iqFgH1IjJCRHoB2aoa3Gd/FvC8qm7xlp8GHAH0AU7HSxiquhKY761zFNAfeFJEFgFv4xqlY1uI40PgF8ANIvIg8B0gy6s+HXhCVetVtUZVT1XVt1oob8273nf6gXOBESLyK+Ah3J5lB9we8Ouqus5b9k+qeqOqLsLt1Z/tHe30AOY0+i1+4EngGq9oIvCYqtbjGusPROQRYAduj7Y1Nar6kvd6EUFHXJ5jcHu6b3jf/yxQ4dWdDrysqhWqWufFFXAOcD6w0Ps7XQAMDqr/j/d5G4BSILe5AFv5+00BviciKbik+bi3LVr7/neb+boZwB0i8jLuyPUnqtrQeCHvnNYs4G5Vfcfr6jwV+K33fR/hjgiGN/e7TNOsO+jw83/AlcAW73WwJFzXRbAE3KG033sdUBe0zk5vTwwAESkAduL2tvcjImfjuo8m4RqfZV5Mgc/1By3bC6hqobxxXKmNvq7SW74DrgtiBq7BeRLXECU08dkZQG9VXYY7GrgWWA5M9Rr9xp4EPhORx4FOqvo2gKpeKSJH4xrnu3BHYa3tidYGvW782wIal9U1UxdcngT8VFVnAXjdbulB9btD+F68dZv9+3ldh1/gGvzLcUcNoXx/kyfEVfUVERkITMAl61+JyIhG8WTijjae8pJi4PsSgBNVtcpbLg93pGAOgB0JHH7+CVwMXIrr7gk2G7hMRLoCiMhEXN/ySq/ueq/8SGCct44Cu73+8kDj/CUwguZNwB3i/w34FNcYJ3l184CrRSRRRNJwXU2ntlC+BRjpfXcPmu8iGgjkAL9Q1ZnAWCDN+943cV0F3b1lb2BvN8y/cEc132HfPes9vL3nj4G/A497seSJyDpgm6r+Cbfn/I0WtkmovgASRORb3vecB3T26mYBF4tIJ6/LJLjr73XgxyKS6tU9BjxwkDG09PcDlzj/F/hYVTceyveLyHTgUlV9DvgRrputf1B9EvACsEhV93yeqpbj9v5v8ZbrBLyPS07mAFgSOMx4DVYxsEJVyxrVzcWd8JsvIktw5wzO8Q6/bwIGi0gxrltjkbdODe4/1nXeHuAc4F5Vfb+FMB4FxorIYuAzYBXQ12sc7sMdjXyO23N/TVVfbqH8YaC7iCjuJPH8xl/m+QK3t7jM+w3nAkuBAaq6GNf3PFtEPsd1i90Y9Pv+BXygqltb+E2P4ZLFU956W4H7gTdEpAjX//0D2HN54+MtfFazVLUW1+gGujm+jeu+QVVfwyWqT3EnWncGrfpb4CvctluK20u+lYPT0t8P3HbOYt/zJwf7/b8FrvD+LgtwR3LvBNVfApyN6+ZbKCKLvEcP3JHIaC/OBcCzqvrMwfzgeJZgQ0mbeOZ1I70D3KSqH0U7nvZARE7AHREd3Uz3mWlH7EjAxC0RORNYB8yyBBAaEXkKeA74viWAw4MdCRhjTByzIwFjjIljlgSMMSaOWRIwxpg41q5uFisqKrITGMYYcxBGjBjR5A2C7SoJAIwY0dI9StFXXFxMYWFhtMNolcUZfu0lVosz/GI91qKiombrrDvIGGPimCUBY4yJY5YEjDEmjkXsnICIjAL+oKpjG5Wfi5vMow43Fvhj3pgkU4BhQDVuApKVkYrNGGOME5EjARG5Aze2SHqj8hTcAGZn4EaDvF5EuuEGzEpX1RNwQ/JOikRcxhhj9hWp7qBVuNEPGysEVqrqdm/0xveAU3AzMs0G8MZwiYnJro0x5nAXke4gb87UPk1U5bDv8LcVuCnyGpfXi0iyN3vSPoqLi8MZatj5fL6YjxEszkhoL7FanAcgMLZaQrNz8AAxEutBauv7BMpxE1cHZOOm5WtcnthUAgBi+lpciP3rhQMszvBrL7EeVJx+PzTUQV011Nd4z9VQV9Po2av3N0B6J8jMhYzO7pGUEpk4/X7w7YRdW2HXlqDHVlde52sm1kYxN/eckACpWZDawXtk7fs+LYttlTV06dYrqDxrTx2pWe63+/2A35vjzh/0PnAPbOOyoGeAnt+AlIwD2oYBLd0n0NZJoBgYKCK5uOnmxgAP4n7lucAL3gTmi9s4LmPan4Z61zA31EF9rfe+Fmp2QW2Vew48gt7nbVwL6zKgxiur3bX/6/0a+WqCZug8OKnZLhlkdt6bGDK8JBGcLLyylF0bYUOV17hv3bdxb/y6obbp70zpAMlp7pGU6j2nQXKqe07tAJldmq4LPPsbvO1XCdWVe7dp5eY9rzvt3gnLdx/6NmrJST+DCfeF/WPbJAmIyOVAlqpOFZFbcFPRJeKuDtogIjOACSLyAW5GooltEZcx+/H7XYNXW+U9dnuN427XQNbudo3kPq/dct22lsDKHK9hbnDP/kBDXe8e/qCGu8ll6oIa9qDXDV4jX1+7t+wgG5yuAMkZkJrpGsnUDu51agfXCKdkQHL6/o3hPg1pC41mchqQAL4dsHv7vo+qMu91Gexcv7fcv9/c8gxoKvjkDMjqCpl5kN0dug2FDnnQoav3CHqd2cXF1AaWFxdTOGiQ92+i0nt4yaK6MihJJXhdS8HPXjk0URf0fERkRkuIWBJQ1a/wJiJX1elB5TOBmY2WbcCb7s+YVtXuhqptex/Vle6Qv3a3e67zQa0P6nZ7z77W62t37234m2iQWpSYAimZZJMIJamQmAwJSZAYeDT3Ptk1UvvUJ7tHUsre1/uUBZbx6pOCl/HqUztASmZQ98W+74tXrqVwyNGR+dscjIYGqC7fmxx2b4eq7Wxct4YeA47Zt3FP7RDtaJuXkOAl00wgP9rRhKzdjR1kDjP1dd5/+q37NuxV22DXNnpsXg2f1nllZW652qrQPjsxJWivNh1SAs9eWXpHryzDlaV2cM8pmV6jmbn3deP64NdeX/eKdnJOgMSk1pdpS4mJkNHJPei7p3hnSjE9pB1sz3bOkoCJnIYG2FXqDvt3rvOeNwS9Xu8a9eakZpORkg0du0FWPuQXukP8zFzv2XukZXsNeXpQg58Re42dMTHIkoA5eNUVTTfsgUa/fOP+J+xSs6BjL+jYE3oMh6xu7lA/M9f18+5p3HMhOY1V7WXv2ph2ypKAaV5djWvMt6+B7Wthx1rY/tXe17u377t8QhLk9HANfK/j3XPHnpDTc+/r9I6tXnNtjGk7lgTam13boHyD64dOSg16DrxOc8+hNLQNDe4yt6Ya+O1fuT354CtQklKh05HQqbe7UqFTL2+v3tuzzypwJyqNMe2G/Y+NVTVVsGUZlC6FkqVQusQ97yoNbf3E5pJEKiSn0m9XOfxrs7sGPFh2D+jcG/qOcY19597QuY97nd3dncQzxhw2LAlEW30dlK12jXxpMZQscQ1/2Rr27IUnp0PXQTDgdCgY7Bpkv3fNeH2N9wh6XVfTRHnwsjVUJ+8m7ZjzvIa+r2vsO/ZyJ1eNMXHDkkBbqq+FNW+7hr5kqWvst+jevfGERMjtBwVHw9BLIX+we+T2DfuVLhuKi8mxE67GxD1LAm1l9Vvw2h2wVd377O6uge936t7Gvqsc9NggxhhzMCwJRNrO9fD6z2Hpv13f+sVPuf72zNxoR2aMMZYEIqauGj58BN550A1DMO7ncOJPrM/dGBNTLAlEwsp5ruunbBUMOgfO/B934tUYY2KMJYFw2r6Wnu/dCRvehtz+cMVLMPD0aEdljDHNsiQQDrU++OAv8O4kOviB8b+CE27yhtQ1xpjYZUngUOlsmH2nu8N28AWs6j+RgSPGRjsqY4wJiSWBg1W2GmbfDctnQ95RcNW/of846trpPKPGmPhkSeBA1VTBe5Ph/T+7YRgm/BZG3dhmMxgZY0w4WRI4EMWvuL3/nV/DMRfDhN+4UTONMaadsiQQqg8ehjm/cHf2XvMq9Dk52hEZY8whsyQQCp0Nc+6FwefDRU/smU7QGGPaOxsXuDUlS+Cl70P3YXDBo5YAjDGHlYgcCYhIIjAFGAZUA9ep6sqg+quA24GdwDRVfUJE0oB/AP2AcuAmVV0RifhCVrkFpl/m5rD97rNu4nFjjDmMROpI4AIgXVVPAO4CJgUqRCQPuB8YC5wKXCEifYAfAJWqOhr4f8AjEYotNHXV8PwVsGsLXDbdTgAbYw5LkUoCJwOzAVT1I2BkUF0/YJGqlqlqA/AJMBoYDMzy1lEgeoPd+/0w86ewbgFc+Dc44riohWKMMZGU4Pf7W1/qAInI48BLqjrLe/810E9V60SkM67hPwmoAN4B/gYkAaOA67zn94FUVa0PfG5RUZE/MzPyXTJdip8m/4spbDn6erYOufaA1vX5fKSnx/5IoRZn+LWXWC3O8Iv1WKuqqhgxYkSTE49H6uqgciA76H2iqtYBqOp2EbkZeAlYD3wGbAVexe39v4lLAEXBCSCgMNKzYRW/Al/8DY6+iK4X/ZGuoUzYHrx6cXHkYwwDizP82kusFmf4xXqsRUVFzdZFqjvofeBbACIyGlgcqBCRZFz3zxjge8Agb/lvAO+p6lhgBrA6QrE1b9MX8PL1rvvn/L/CASYAY4xpbyJ1JDADmCAiHwAJwEQRuRzIUtWpIlIDFAE+YJKqbhURgN+KyG3ADuD7EYqtaRUl8Ox3IaOTOxFs0zwaY+JARJKAd8L3xkbFy4Lq7wPua7TOViA6g+/X+uC5y2F3GVw7G7K7RSUMY4xpa3bHsN8P//0xbPgULv2nuynMGGPihN0x/O6DsPhFGP9LKDw32tEYY0ybiu8ksPQ/MP9+GHopnHxLtKMxxpg2F79JYONCePkG6Hk8nPsXuxLIGBOX4jMJlG9yVwJ1yIPLnoGU2L3JwxhjIin+TgzXVMFz3wVfOXx/DmTlRzsiY4yJmvhKAg0N8O8fwsZF7l6AbkdHOyJjjImq+EoCb/8Blv7bTQs56FvRjsYYY6Iufs4JLP4XvP17GH4FnPiTaEdjjDExIT6SwO4d8J+b4MgT4JzJdiWQMcZ44qM7KCXTdQEd/R1ITot2NMYYEzPiIwkkp8KoG6IdhTHGxJz46A4yxhjTJEsCxhgTxywJGGNMHLMkYIwxccySgDHGxDFLAsYYE8csCRhjTByzJGCMMXHMkoAxxsSxiNwxLCKJwBRgGFANXKeqK4PqrwJuB3YC01T1CRFJAZ4C+gD1wA9UdVkk4jPGGONE6kjgAiBdVU8A7gImBSpEJA+4HxgLnApcISJ9gG8Byap6IvAb4HcRis0YY4wnUkngZGA2gKp+BIwMqusHLFLVMlVtAD4BRgPLgWTvKCIHqI1QbMYYYzyRGkAuB9fVE1AvIsmqWgesAIaISAFQAYzHJYBKXFfQMiAPOKepDy4uLo5QyOHh8/liPkawOCOhvcRqcYZfe4q1sUglgXIgO+h9opcAUNXtInIz8BKwHvgM2ArcDLyuqneLSC9gvogco6q+4A8uLCyMUMjhUVxcHPMxgsUZCe0lVosz/GI91qKiombrItUd9D6ujx8RGQ0sDlSISDKu+2cM8D1gkLf8dvYePZQBKUBShOIzxhhD5I4EZgATROQDIAGYKCKXA1mqOlVEaoAiwAdMUtWtIjIZeFJE3gVSgXtUdVeE4jPGGEOEkoB3wvfGRsXLgurvA+5rtE4lcEkk4jHGGNM0u1nMGGPimCUBY4yJY5YEjDEmjlkSMMaYOGZJwBhj4pglAWOMiWOWBIwxJo5ZEjDGmDhmScAYY+JYSHcMi0gO0BtYbUM5GGPM4aPVIwER+Q7wNjAduEVEfhHxqIwxxrSJULqDbsaN+rkVNyPYhRGNyBhjTJsJJQk0qGo14FdVP2DdQcYYc5gIJQm8KyLTgZ4i8ihuOkhjjDGHgVZPDKvqPSJyFrAQWKaqMyMfljHGmLbQbBIQkSTczF7PAZcC84EkEZmvqqe1UXzGGGMiqKUjgWuBe4BugOJmCKsH3muDuIwxxrSBZpOAqj4GPCYi16rqk20YkzHGmDYSys1i74jI3biJ3xOAHqp6Q2TDMsYY0xZCuTroae/5ZKAv0CVy4RhjjGlLoRwJVKnqAyIyUFWvFZF3W1tBRBKBKcAwoBq4TlVXBtVfBdwO7ASmqeoTInINcI23SDowHOimqjsO5AcZY4wJXShJIEFEugFZItIByA1hnQuAdFU9QURGA5OA8wFEJA935/GxwA5gnoi8oarTgGneMn8FnrQEYIwxkRVKd9B9uEb9n8AaYFYI65wMzAZQ1Y+AkUF1/YBFqlqmqg24m89GBypFZCQwRFWnhvQLjDHGHLRQjgSOV9UHvdf5IX5uDq6rJ6BeRJJVtQ5YAQwRkQKgAhgPLA9a9h5c4jHGGBNhoSSBb4nIZFWtP4DPLQeyg94negkAVd0uIjcDLwHrgc9wg9MhIp2AQar6ZnMfXFxcfABhtD2fzxfzMYLFGQntJVaLM/zaU6yNhZIE8oCNIrIG8OMGkjuxlXXeB84FXvDOCSwOVIhIMq77Z4z3/fNwe/94ZfNa+uDCwsIQQo6e4uLimI8RLM5IaC+xWpzhF+uxFhUVNVsXShI4t6lCERmlqguaWWcGMEFEPsDdWzBRRC4HslR1qojUAEWAD5ikqlsDHwusDiEmY4wxYRDKAHJrm6l6AGhyDCHvhO+NjYqXBdXfRxP9/qr6v63FY4wxJnwOZY7hhLBFYYwxJioOJQn4wxaFMcaYqDiUJGCMMaads+4gY4yJY6FcHYSI5AC9gdWqGphjeHrEojLGGNMmWj0SEJHvAG/jGv1bROQXsGe+AWOMMe1YKN1BN+Nu7tqKG/jtwohGZIwxps2EkgQaVLUad6ewH9jV2grGGGPah1CSwLsiMh3oKSKP4kb9NMYYcxgI5Y7he0TkLGAhsExVZ0Y+LGOMMW2h2SQgIklAEvAccCkwH0gSkfmq2uRwEcYYY9qXlo4ErsWN7tkNUNx9AfXAe20QlzHGmDbQbBLwLgF9TESuVdUn2zAmY4wxbSSUm8XeEZG7gRTc0UAPVb0hsmEZY4xpC6FcHfS093wy0BfoErlwjDHGtKVQkkCVqj4ArFfVa4CCyIZkjDGmrYSSBBJEpBuQJSIdgNwIx2SMMaaNhJIE7gMuAP4JrAFmRTQiY4wxbSaUE8PHq+qD3uv8SAZjjDGmbYVyJPAt78YxY4wxh5lQjgS6AhtFZA1uSkm/qp4Y2bCMMca0hVCSwDkH+qEikghMAYYB1cB1qroyqP4q4HZgJzBNVZ/wyu8GzgNSgSmBcmOMMZERShK4uomy37SyzgVAuqqeICKjgUnA+QAikoebl+BYYAcwT0TeAPoAJwInAZnAbaH8AGOMMQcvlHMCJd6jFOgJHBnCOicDswFU9SNgZFBdP2CRqpapagNuaOrRwJnAYmAGMBN4JcTfYIwx5iCFMpT034Pfi0gol4jm4Lp6AupFJFlV64AVwBARKQAqgPHAciAPN4/xObg7k/8rIoO8iWyMMcZEQKtJQESOCnrbndCOBMqB7KD3iV4CQFW3i8jNwEvAeuAz3NSV23DzFdQAKiI+3Enp0uAPLi4uDuHro8fn88V8jGBxRkJ7idXiDL/2FGtjoZwT+DvuqqAEYDeh9dW/D5wLvOCdE1gcqBCRZFz3zxjv++fhhqyuB34qIg/hkk0HXGLYR2FhYQhfHz3FxcUxHyNYnJHQXmK1OMMv1mMtKipqti6UJPBNoFBVF4rIBbhGuzUzgAki8gEueUwUkcuBLFWdKiI1QBHgAyap6lbgFREZA3yMO1dxk6rWh/BdxhhjDlIoSeCfuIZ/IXAUcAlweUsreCd8b2xUvCyo/j7ccBSN17sjhHiMMcaESShXBx2hqo8CqOofcV01xhhjDgOhJIE9J4dFpD9u3mFjjDGHgVC6g36GO8GbD2xk/24eY4wx7VQoRwKLgImq2gN3p+/nkQ3JGGNMWwklCTwDjPJeHwU8FblwjDHGtCU7MWyMMXHsQE8MD8BODBtjzGEjlBPDPwWe98b62Qj8MLIhGWOMaSuhHAkchxvCoRo3yNv0iEZkjDGmzYSSBK4DTgVeA64BlkQyIGOMMW0nlCSwVVU3Admq+haQG9mQjDEm+ip8tcz8fCMvfrqO7btqohrL2m272FVdF5HPDuWcwE5v4Di/iNyAG97ZGNPO1Tf4Ka3wsXGHj407du957Nxdy8g+uZw2KJ8enTKiHWab2lJRzdylJcxZupkPVm6jpr4BgOTEBE4ZmMc5Q3twxpACstNTIhqH3+9n2eYKZi3exGtfbmZlaSU/HjeA286UsH9XKEngOmAAcBduGGk7MWxMjPP7/ZT76ti00zXsG4Ia+lUby9j+n02UlPuoa9h3zqbs9GTSU5L496KNAAzqls34wnxOG5TP8F6dSUpMiMbPiai123bx+pLNzFlSQtHX2/H74cjcTK4+sTdnDulGWnISryzeyCufb+LWFz8ndUYi46Qr5w7rwWmD8slMDaUZbZ3f72fJxnJmfbmJWYs3s3rrLhITYFTfLlx9Qm8uPK5nWL6nsVBmFqvAjSAKcGtEojCmndu+q4bSyjq6lPtISUokOSmBlKREUpISD7rhbGjwU1VbT6WvjsrqWip8dVRW11Hpq6Oius699+oqvfflvjo279zNxh0+Kht1HyQnJtC9UzodU+D4vrn06JROj04Z7tExg+6d0slJT8Hv97OytJL5y0p5Y1kpj769mr++uYrOmSmMFZcQxhzVlY4Zkd0bjpRAYztnyWbmLC1h2eYKAAZ3z+Fn44/ijCEFDOqWTULC3r/bMT07ctdZg/js6x3M/Hwjry3exOtLSshISeL0wQUcm1tPv4H1pCUf2BX0fr+fxRt28upi1/B/XVZFUmICJ/TrwnWn9OOMIQXkZaWF9fc3Fp4UZswB8Pv9fPLVdp7/ZB0ZqYn8aOyAdtft4Pf7WV5Sydylm5m7tITP1wdmU/16v2UTEiAlMTgxJJDsvU/1Ekbg/e6a+j0NfWVNHf4QJlfNSEkiKz2Z7LRkstKT6dOlAyf2z+OITq5h79EpgyM6ZZCXlUZSYkKrE6AkJCQwsCCbgQXZ3HBqf3ZW1fL2ii28uayUt7SUGQs3kJSYwMjenTltUD7jC/Pp3zVrn0Yz1tQ3+Pnkq7I9e/wbduwmMQFG9snl3nMGc8bgAnrlZrb4GQkJCYzo3ZkRvTtz7zmD+XhNGTO/2MisxZuYWVXL5A/nceaQbpwztDsnDcgjJanpU65+v5+F63a4rp7Fm9mwYzfJiQmcNCCPm8b1Z8LgbuR2SI3EZmiSJQHTZnZW1fLywvVMX/A1K0oryU5LprqugRc+Xc/VJ/TmR2MH0LkN//EfqLr6Bj5du525S0uYu7SEr8uqABjWqxO3TjiK+l1ldMnvRl19A3X1fmobGqit81PX0EBtvd+VN/ipqW8IWsZPbV0DdQ2uLqNTEllpyWSnp+zTsGd5z8Hvs9NS6JCWRHIzjU24dMxM4bxhPThvWA/qG/wsWrfdHSUUl/LArGU8MGsZvXIzGD+ogHGD8hnVN5f0lOjdU9rQ4Keypo7y3bUs21TB60s288ayUsp21ZCanMjJA/L4yfgBnF5YQJeD3MtOSkzghP5dOKF/F+47bwjPv7mQRduTef3LzfyraD2dM1P45jHdOXdoD47vm0sC8NnX23lt8WZmf7mJjTt9pCQlcMrArvzs9IFMGFxAp8zo/Nu3JGAiyu/3s2jdDp5Z8DWvfLERX20Dw3p25I8XDeWcYd0p21XD5LkrePy9NTz38TpuHNufiSf1CVs/66HaVV3Huyu2MGdpCfOXlbKjqpbUpEROHNCFG07tx+mFBRTkpAOBKQZ7RzniyEpKTGBE71xG9M7l9jMHsXHHbt7UUuYXl/LcJ18z7YOvyBv3tSMAABoaSURBVEhJYmSfzuRkpJCenER6SiJp3nN6yv7v05KTSEtJ3LOsK0tkY3kt9Rt2Ur67lnJfLeW769yzr26fsopGZZXV+x5BZaclM25QPmcO6cap0pWstPD+20pJSmTEEZlceXohv7vwaN5ZvpWZn29kxmcbmL7ga7pmp5GYACXl1aQmJzJmYFduO1MYX1gQE11qsfE/zRx2Kqvr+PfCDTyz4GuKN5WTmZrEhcf25IpRR3L0ER33LJeZmsykS4Zx/Zh+/O/ryv++rkz74Ct+Mn4gl32jV1RiL63wMW9pKfOKS3hv5VZq6hromJHC+EH5TBhcwClHhb8haa96dMrgilG9uWJUb3y19Xy4ahvzl5WycN12NuzYTXVtA77aeqrr3HPjE9GtW9dkaXZ6MjnpKe45I4UjOmVQ2D2bnPQUcryynPQUenTK4Pi+uaQmR/ZoKSAtOYkJgwuYMLiAqpo65i8r5bXFm/D74ayju3HaoPyIX1l0oOxfsgmrLzfs5JkFX/PfRRvYVVNPYfcc7r/gaM4f3qPFf/zSLZvHrx7Jp1+V8YfZy7j331/yxLuruWxIFiJ+EiN4VUrgROgcr5tn0bodAPTKzeDKUb2ZMLiAb/TpHPFul/YuPSWJcYPyGTcov9ll6uob8NU1UF1bj89LDMFJIjhprNuwAel75J4GPdDgZ6Ult4urlDJTkzlnaA/OGdoj2qG0yJKAOWRVNXW88vkmnlmwls/X7yQ9JZFzh/bg8lFHMrxXpwM6YTiyTy4v3HAC85eV8sfZyu/fKeWVVe9x51mDOGVg+G5RWb+9igWry1iwZhsfrt7GurLdAAzt2ZFbJxzFhCEFSEF2TJ/sbI+SkxLJSkoM6UiqOL2cwsJubRBVfLMkYA6abq5g+oK1vPzZBiqq6xiYn8Wvzx3Mhcf1PKS+zoSEBMYXFjBW8pny2ic892UlVz3xMScN6MIdZw5iWK9OB/R5fr+fdWW7+Wj1Nj5as40Fq8vYsMM1+h0zUhjVN5frx/RnQmEB3TqmH3TcxrRHEUkCIpIITAGG4Qaeu05VVwbVXwXcDuwEpqnqE175Qq8MYI2qToxEfG2ptr6BtduqWLWlkpWllWyrrGFAfhaF3bMZ1C2HjNT2NzL3x2vK+PMby3l/5TZSkxL51jHduGJ0b0b27hzWPeekxARO75/N9WeN4J8ffc1f31zJ+X99n28d043bzhD6dc1qcj2/38+arbtYsKaMBau3sWBNGZt2+gDI7ZDKqL65/OCUvozq1wUpyI5oV5MxsS5SRwIXAOmqeoKIjAYmAecDiEgebprKY4EdwDwReQPYDKCqYyMUU0RV+GpZtWUX766qYObaZawsrWTVlkrWbqva52RYWnIi1XXuVvTEBOiT14HC7jkM9h6F3XMoyEmLyW6I4MY/LyuNu745iEtG9or4Nc1pyUl8/+S+XDKyJ4+9u4bH313N60tKuGRkL352+kDys9NYtaWSD1e7Rv/jNWWUVlQDkJeVxqh+uYzum8uofl0YmB/b17Mb09YilQROBmYDqOpHIjIyqK4fsEhVywBE5BNgNLAGyBSROV5c96jqRxGK76D4/X5Kyqv37NWv2lK553VJefWe5ZITt9K7SyYD8rM4c0g3+nfNYkB+Fv26diArLZn123ezZGM5xZvc4/N1O3j1i0171s/tkEph9+w9SaGwew4D8rOavfkk0ho3/r84u5ArRvVu86OY7PQUbplwFFeN7s0j81cw/eOvmbFwPVlpyWytdAN8FeSkMbpfF9fw9+tCv7wO1ugb04JIJYEc9nbrANSLSLKq1gErgCHeJDUVwHhgOVAFPAg8DgwEZomIeOtE3ZKNO7ni8QXsqKrdU5aVlkz//CxOGpDHgPwsd9dkRQnjvnFMiw12r9xMeuVmctbRe096lfvcjS1LN+6keFMFxZvLeerDtdR4Rw2pSYleN1IOQ3t2ZKx0pXeXDpH7wcRO499Y1+w07jv/aL5/cj+mvLWS6roGRvfLZVTfLvTukmmNvjEHIMEfyn3pB0hEHgI+UtUXvPfrVbVnUP25wJ3AeqAceBV35JCoqru9ZT4GLlLVPRcKFxUV+TMzW761O1Ie+2Qb/122kx+M7MKRnVLp1TGF3Iyk/Rocn89Henp4Ti7WN/hZX17L6rIaVm+vZk1ZDavLatjuqwegZ04Kx/fM5PiemQwpSCf5APq2W4rzyxIfz3y+nUWbdtM5PYmLj+7INyWH9Da61jpYOLdnpLWXWC3O8Iv1WKuqqhgxYkSTDUSkjgTeB84FXvDOCSwOVIhIMq77Z4z3/fOAe4BrgWOAH4lID9zRxKZGn9vimCeR4vf7KXrlLU4c0JU7v318i8u2Ni7LgTq6ibK123Yxf1kp85eV8oqW8fLSnWSnJTPmqK6cNiifsdK11dvhm4rzk6/K+NO82NrzD/f2jKT2EqvFGX6xHmtRUVGzdZFKAjOACSLyAZAATBSRy4EsVZ0qIjVAEeADJqnqVhF5ApgmIu8BfuDaWOkKWlHqTvBed0q/aIcCQO8uHZh4Ul8mntSXXdV1vLdyK/OLS3lTS3l18SYSEmBYz06M927cGdIjp8Uukn0b/9SYaPyNMW0jIklAVRuAGxsVLwuqvw+4r9E6NcDlkYjnUM1dWgLAhMKCKEeyvw5pyZw5pBtnDulGQ4OfpZvKeaO4lPlayqS5y5k0dzndctIZN6gr4ySfkwfm7RmXxxp/Y4zdLBaCOUtLGNazY8zfSJSYmMDRR3Tk6CM68tPTB7Klopq31HUbzfx8E89+vI7U5ERG9+vCzvIKPt+82hp/Y+KcJYFWlJT7+HzdDm4746hoh3LAumancfHIXlw8shc1dQ188lXZnnMJ5btqrfE3xlgSaE2gK+iMIe17DJPU5EROGpDHSQPyuPecwd6JrNg4x2GMiR4bFrEVc5eW0LtLJgPzmx6iwBhj2jNLAi2o8NXy4aptTCgssBuQjDGHJUsCLXh7+RZq6hvafVeQMcY0x5JAC+YuLSG3QyojeneOdijGGBMRlgSaUVvfwJvLSjltUH67mMXIGGMOhiWBZny8poxyXx0TBsfeDWLGGBMulgSaMWfJZtJTEhkTxikNjTEm1lgSaILf72fu0hJOHtDVbqQyxhzWLAk0YcnGcjbu9HGGdQUZYw5zlgSaMGdpCYkJML4wP9qhGGNMRFkSaMLcpSWM6N251TH5jTGmvbMk0Mi6siqKN5XbVUHGmLhgSaCRecXe3AGD7S5hY8zhz5JAI3OWlDAwP4u+eZGdxN0YY2KBJYEgO6pq+PirMusKMsbEDUsCQd7UUuob/DZgnDEmblgSCDJ3aQn52WkMPaJjtEMxxpg2YUnA46ut5y3dwumDC0i0AeOMMXEiItNLikgiMAUYBlQD16nqyqD6q4DbgZ3ANFV9IqguHygCJqjqskjE15QPV22jqqbezgcYY+JKpI4ELgDSVfUE4C5gUqBCRPKA+4GxwKnAFSLSx6tLAf4O7I5QXM2as7SEDqlJnNi/S1t/tTHGRE2kksDJwGwAVf0IGBlU1w9YpKplqtoAfAKM9uoeBB4FNkYoriY1NPiZV1zCWMknLdkGjDPGxI9IJYEcXFdPQL2IBLqeVgBDRKRARDKB8UAHEbkG2KKqr0copmYtWr+DLRXV1hVkjIk7CX6/P+wfKiIPAR+p6gve+/Wq2jOo/lzgTmA9UA68CtwK+L3HcGA5cJ6qbg6sV1RU5M/MzAx7vP8oKuOlJTt49tLeZKcd2pGAz+cjPT09TJFFjsUZfu0lVosz/GI91qqqKkaMGNHkFS8ROTEMvA+cC7wgIqOBxYEK74hgNDDG+/55wD2q+p+gZd4CbgxOAAGFhYVhD/azWW8zun8Xjh9+9CF/VnFxcURiDDeLM/zaS6wWZ/jFeqxFRUXN1kUqCcwAJojIB0ACMFFELgeyVHWqiNTgrgDyAZNUdWuE4mjV6i2VrCyt5MpRR0YrBGOMiZqIJAHvhO+NjYqXBdXfB9zXwvpjIxFXU+Yu9QaMs7uEjTFxKO5vFpu7tIQhPXI4olNGtEMxxpg2F9dJYGtlNUVfb7ergowxMefhhx/m2Wefjfj3ROqcQLvwRnEJfj+WBIxpB14qWs8Ln64L62deMrIXF43o2fqCh7G4TgJzl5ZwRKcMBnfPiXYoxpgYVFlZyc9//nMqKirYvn07F198MUOGDOF3v/sdfr+fgoICHnzwQZYvX86vfvWrfcqaumT06aefpry8nB//+MfU1NRw3nnn8d///peHH36YL7/8kl27dtG/f38eeOCBNvuNcZsEqmrqeHfFVr57/JEkJNiAccbEuotG9Gzzvfa1a9dy9tlnc8YZZ1BSUsJVV11Feno6kydPpn///jzzzDOsWrWKKVOmMGXKlH3KhgwZst/nnX/++Vx++eXcdNNNvPHGG4wbN46amhpycnL4xz/+QUNDA2effTYlJSVt9hvjNgm8s3wr1XUNnGFdQcaYZuTl5fHUU08xZ84csrKyqKurY9u2bfTv3x+AK664AoAdO3bsV9aUjh07UlhYSFFRETNmzODOO+8kLS2NsrIybrnlFjIzM6mqqqK2tjbyP84TtyeG5y4toWNGCt/omxvtUIwxMerJJ59k+PDhPPjgg5x11ln4/X7y8/P56quvAJg6dSpz584lNzd3v7LmXHLJJTz11FP4fD769+/PO++8w6ZNm3jooYe45ZZb8Pl8RGIkh+bE5ZFAXX0D85eVcNqgfFKS4jYPGmNaMW7cOH79618zc+ZMOnXqRFJSEr/+9a+55557SExMpGvXrlxzzTXs3r17v7LmHH/88dx777388Ic/BGDo0KFMmTKFSy65hNTUVHr16kVpaWkb/cI4TQJFa7ezvarWrgoyxrRo9OjRzJ49e7/y6dOn7/N+4MCB+5W15PXX946T2bVrV1566aX9lhkxYsQBRHrw4jIJzFlaQmpyImOO6hrtUIwxh6Hnn3+eV155Zb/yW265hWOPPTYKETUv7pKA3+9n7tISTurfhay0uPv5xpg2cOmll3LppZdGO4yQxF2H+PKSSr4uq2LCYBsryBhj4i4JzFmymYQEOH1wfrRDMcaYqIu7JDC3uIThvTqRnx27E0AYY0xbiasksHmnjy/W77SrgowxxhNXSWBusbsV2+4SNsZEy/PPPx/yHcHFxcU88sgjEY0nri6PmbNkM/3yOtC/a1a0QzHGHKhFz8LCf4b3M4+9EoZ/N7yf2Yq///3vXHDBBSEtW1hYGPFpK+MmCZT7avlo9TauPamvDRhnjAlJuEcRffHFF9myZQs333wzV199NQ8++CApKSlccsklpKen88wzz+xZ9s9//jMrVqzgueeeY/LkyZxxxhkcd9xxrFmzhi5duvDwww+TlJR0yL8xbpLA27qF2nq/nQ8wpr0a/t0232sP9yiiF198MX/729+YPHkyixYtorq6mhdffBGARx99lKlTp5KRkcEvf/lL3nvvPQoK9rZX69at46mnnqJ79+5cdtllLF68mOHDhx/yb4ybJDB3aQl5Wakce2TnaIdijGknwj2KaGN9+/bd87pLly7ceeeddOjQgdWrV+/XwHfu3Jnu3bsD0L17d6qrqw/ptwXExYnhmroG3lxWyvhBBSQlWleQMSY0kRhFNCEhgYaGBgASE10TXFFRwV/+8hcmT57M/fffT1pa2n4jiUaqGzsiRwIikghMAYYB1cB1qroyqP4q4HZgJzBNVZ8QkSTgMUCAemCiqq4KRzw7dtdQVVvP+cN7hOPjjDFxIhKjiI4cOZLrr7+em266aU9ZVlYWxx13HBdeeCGZmZnk5ORQWlpKz56Rn0QnIRLjVovIt4HzVPUaERkN3K2q53t1eUARcCywA5gHXAsM99a5VkTGAjcH1gkoKiryH+zIepXVdW0yVlBxcXHEz+aHg8UZfu0lVosz/GI91qKiIkaMGNHkoUSkWsWTgdkAqvqRiIwMqusHLFLVMgAR+QQYrarPiUhg2L3eQFjnV7PB4owxbcVGEYUcXFdPQL2IJKtqHbACGCIiBUAFMB5YDqCqdSLyFHAh8J0IxWaMMRHVnkYRjVR30EPAR6r6gvd+var2DKo/F7gTWA+UA6+q6n+C6rsBC4DBqrorUF5UVOTPzMwMe7zh5PP5mrw+ONZYnOHXXmK1OMMv1mOtqqpq8+6g94FzgRe8cwKLAxUikgyMBsZ43z8PuMc7WdxTVR8AqoAG3AnifcRyvxvEft9ggMUZfu0lVosz/GI91qKiombrIpUEZgATROQDIAGYKCKXA1mqOlVEanAnh33AJFXdKiIvA/8QkXeAFOBnquqLUHzGGGOIUBJQ1QbgxkbFy4Lq7wPua7TOLuCSSMRjjDGmaXFxs5gxxpimWRIwxpg4FpGrgyKlqKio/QRrjDExpLmrg9pVEjDGGBNe1h1kjDFxzJKAMcbEMRtQ5xCISArwJNAHSAPux90FPRM3PAbA31T1+agEGEREFrJ3KI81wO+AaYAf+BK4ybu0N2pE5BrgGu9tOm5QwROJoe0pIqOAP6jqWBEZQBPbUER+ANwA1AH3q+r+g8i0fazDgYdxN2BWA99T1RIR+QtwEm4IF4DzVXVn05/YJnEeRxN/71jYpo3ifA7o5lX1wY2QcFksbM8DZUng0FwJbFPVq0SkC7AQ+A3wkKpOim5oe4lIOoCqjg0q+y/wC1V9S0QeBc7H3eQXNao6DdeoIiJ/xSXY44iR7SkidwBXAYGhTB6i0TYUkQ+BnwAjcYnsPRGZq6rhmQHk4GP9M/D/VHWRiNyAG7blFtz2PVNVt7ZlfC3Eud/f2xtGJqrbtHGcqnqZV94ZeBO4OSj+qG3Pg2HdQYfmReDeoPd1wAjgbBF5R0SeEJHs6IS2j2FApojMEZH53lAeI4C3vfpZwOlRi64Rb9TZIao6ldjanquAbwe9b2obHg+8r6rV3h7gSmBom0bpNI71MlVd5L1OBnzevB8Dgaki8r6IXNvWQdL0Nm38946Fbdo4zoD7gIdVdVOMbM8DZkngEKhqpapWeP9Q/wX8AvgYuF1VxwCrgV9FM0ZPFfAgcCbuTu5ngARVDVwaVgF0jFJsTbmHvXeUx8z2VNWXgNqgoqa2YeMRdKOybRvHqqqbAETkRODHwGSgA66L6ErgLOBHItKmjWsT27Spv3fUt2kTcSIi+bhRkKd5RVHfngfDksAhEpFeuMPB/1PV6cAMVQ2M1jQDN3lOtC0H/qmqflVdDmwDCoLqs3ET/ESdiHQCBqnqm15RLG7PgOBzKIFtWO69blwedSJyKfAocLaqbsHtHPxZVatUtQKYjztqjKam/t6xuk2/A0xX1cBAl7G4PVtlSeAQeHMizAHuVNUnveLXReR47/V43EB50XYtMAlARHrg9qzmeDO4AXwTeDc6oe1nDG5k2YBY3J4BC5vYhh8Dp4hIuoh0BApxJ42jSkSuxB0BjFXV1V7xUbj+9STvIoeTgc+iFaOnqb93TG5TXPffrKD3sbg9W2Unhg/NPUBn4F4RCZwbuAX4kzdS6mbg+mgFF+QJYJqIvIe7kuVaYCvwmIikAsW47qxYILhugIAfAo/E2PYMuJVG21BV670rRN7F7WT9PNqj4Xrzd/8F+Bp4WUQA3lbVX4nIM8BHuK6Op1V1SfQiBZr4e6tqeaxtU88+/1ZVtTgGt2er7I5hY4yJY9YdZIwxccySgDHGxDFLAsYYE8csCRhjTByzJGCMMXHMkoCJGSJyjYj8vlHZc94lmMFlZ4nItCbWfy7ouv1DjWWaiJwVjs8KNxF52Xs+RkTGHORnvO49PyIig8IZn2lf7D4BE9MCA3WZvVQ1MIbNRbhr6d85kPW9Qc8Cd9weBWj4ojPtjSUBE2tGi8gcoCvwN9wNeYOAvrhRRXd5j+0AInITcB2wCcj3ylJwwyMMxB3tBkb6/AI34NtQ3E1zrQ7zKyI5wONAJyAPeAyYjrsT9Cjv5rA/AJ8Cy3A3ZSXghua4FjfswR+AGmCqqv5fE98xFrgxaGTKzarazTvaqcYNVdwduEZVPxORzbiB1q4BakTkM9wosKd5v/dZVf1TM7/n58AVQKKIvA8MAH6LG/fKxCHrDjKxphY30N2FwM+Cyn8L/FJVTwc+APCGEPgpMBrXCAa6ja4DtnqDkJ0P/NUrz8E1kKcCG3BDPbRmAPCcqp4BnAPc4iWO94Azvbtxvwn8B5cgbvKG7H4NuMP7jHRVPaWpBBCCtap6Jm5gsj13S6vqBtzAZQ+p6sfA94DLccNu7G7uw1T1d7i7wycCdwOPqKolgDhmRwIm1nymqn5vbzczqHwIbgwZgPdx48cMApYExpUXkUD9MbixZkZ575O9+R7AzfkAsA43Nn1rNgM/E5Fv4wYyS/HKH8ONcZ8IzFPVGhEpBKZ4wzKk4AbugwPvbgmeEDw43pNaWOcy4AHcRCezmlvIOxL4ETAW6AmUi0iaJYL4ZUcCJtY0N47JMuAE7/U3vOfVwGARyfD2yI8NWvZZb4/8m7h5H7a38vnNuQ34UFWv9D4nAUBV3wP6A9/Hjc0ErrH/nve9dwCveuWtzdjmw3X3ICK9gdygupbibcB166QBFwPfxXUJXeN9TlP+ByjyjpIW4QaUswQQxywJmPbiR8A9IvIGMArAGw75l7juoVnsnZ3q78AgEXnbq1t7CFNnzgR+6g2+9zOgzmt0wc3L0C1okLAfAk+LyLvA74EvQvyOT4EdIrIAN4/CmhDXK8KNDHoiUIZr1OfjRrb9upl1jsJNygKQpaqxMCSziSIbQM6Yg+RNObg1aBhxY9odOydg4pZ3/8GcJqpUVW9oZd1puKuFmppysLl1fonrrmlsoqqGuvcf6nddjztR3NjdqvphOL/LtG92JGCMMXHMzgkYY0wcsyRgjDFxzJKAMcbEMUsCxhgTxywJGGNMHLMkYIwxcez/A7AHd/31DHomAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(acc_val_2,label = 'acc_val')\n",
    "ax.plot(acc_train_2, label = 'acc_train')\n",
    "ax.legend()\n",
    "plt.xlabel('hidden_layer_units_#') \n",
    "plt.ylabel('accurate_rate') \n",
    "plt.title('Model accuracy vs. hidden layer size')\n",
    "fig.savefig(\"acc_cv_2.png\",dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 7s 270us/step - loss: 0.3421 - acc: 0.8544\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 4s 158us/step - loss: 0.1223 - acc: 0.9559\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 4s 159us/step - loss: 0.0409 - acc: 0.9875\n",
      "25000/25000 [==============================] - 3s 131us/step\n"
     ]
    }
   ],
   "source": [
    "# baseline model with two hidden layers\n",
    "model_overfitting_2 = Sequential()\n",
    "model_overfitting_2.add(Dense(50,input_shape = (max_num,)))\n",
    "model_overfitting_2.add(Activation('relu'))\n",
    "model_overfitting_2.add(Dense(50))\n",
    "model_overfitting_2.add(Activation('relu'))\n",
    "model_overfitting_2.add(Dense(num_classes))\n",
    "model_overfitting_2.add(Activation('softmax'))\n",
    "model_overfitting_2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_overfitting_2 = model_overfitting_2.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_overfitting_2 = model_overfitting_2.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "base_train_acc_2 = hist_overfitting_2.history.get('acc')[-1]\n",
    "base_test_acc_2 = score_overfitting_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the overfitting model with two hidden layers on training dataset is\n",
      "0.987520010471344\n",
      "The accurate rate of the overfitting model with two hidden layers on test dataset is\n",
      "0.8638800020217896\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the overfitting model with two hidden layers on training dataset is')\n",
    "print(base_train_acc_2)\n",
    "print('The accurate rate of the overfitting model with two hidden layers on test dataset is')\n",
    "print(base_test_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 342us/step - loss: 0.3881 - acc: 0.8276\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 163us/step - loss: 0.1257 - acc: 0.9543\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 164us/step - loss: 0.0485 - acc: 0.9853\n",
      "8334/8334 [==============================] - 2s 222us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 165us/step - loss: 0.1950 - acc: 0.9328\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 163us/step - loss: 0.0455 - acc: 0.9866\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 163us/step - loss: 0.0120 - acc: 0.9972\n",
      "8333/8333 [==============================] - 1s 90us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 165us/step - loss: 0.0411 - acc: 0.9861\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 165us/step - loss: 0.0135 - acc: 0.9966\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.0051 - acc: 0.9990\n",
      "8333/8333 [==============================] - 1s 93us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 338us/step - loss: 0.4107 - acc: 0.8174\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 167us/step - loss: 0.1479 - acc: 0.9449\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 166us/step - loss: 0.0667 - acc: 0.9781\n",
      "8334/8334 [==============================] - 2s 236us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 180us/step - loss: 0.2052 - acc: 0.9295\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 173us/step - loss: 0.0701 - acc: 0.9787\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 163us/step - loss: 0.0299 - acc: 0.9915\n",
      "8333/8333 [==============================] - 1s 95us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 163us/step - loss: 0.0590 - acc: 0.9803\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 163us/step - loss: 0.0192 - acc: 0.9940\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 170us/step - loss: 0.0122 - acc: 0.9962\n",
      "8333/8333 [==============================] - 1s 100us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 5s 330us/step - loss: 0.4484 - acc: 0.7904\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 163us/step - loss: 0.1867 - acc: 0.9331\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 163us/step - loss: 0.0990 - acc: 0.9657\n",
      "8334/8334 [==============================] - 2s 232us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 165us/step - loss: 0.2042 - acc: 0.9294\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.0825 - acc: 0.9728\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 167us/step - loss: 0.0396 - acc: 0.9877\n",
      "8333/8333 [==============================] - 1s 95us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 166us/step - loss: 0.0699 - acc: 0.9758\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 0.0340 - acc: 0.9887\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 177us/step - loss: 0.0258 - acc: 0.9914\n",
      "8333/8333 [==============================] - 1s 98us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 334us/step - loss: 0.5186 - acc: 0.7434\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 164us/step - loss: 0.2548 - acc: 0.9022\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 165us/step - loss: 0.1512 - acc: 0.9467\n",
      "8334/8334 [==============================] - 2s 231us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 165us/step - loss: 0.2253 - acc: 0.9206\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 167us/step - loss: 0.1334 - acc: 0.9532\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 163us/step - loss: 0.0824 - acc: 0.9713 2s - loss: 0.0777 - ETA: 1s - loss\n",
      "8333/8333 [==============================] - 1s 93us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 166us/step - loss: 0.1143 - acc: 0.9585\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.0768 - acc: 0.9717\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 169us/step - loss: 0.0584 - acc: 0.9770\n",
      "8333/8333 [==============================] - 1s 101us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 338us/step - loss: 0.5539 - acc: 0.7104\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 165us/step - loss: 0.2923 - acc: 0.8876\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 163us/step - loss: 0.2031 - acc: 0.9292\n",
      "8334/8334 [==============================] - 2s 234us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 169us/step - loss: 0.2449 - acc: 0.9124\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.1635 - acc: 0.9419\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.1282 - acc: 0.9549\n",
      "8333/8333 [==============================] - 1s 95us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 166us/step - loss: 0.1519 - acc: 0.9444\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 169us/step - loss: 0.1098 - acc: 0.9603\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 170us/step - loss: 0.0814 - acc: 0.9691\n",
      "8333/8333 [==============================] - 1s 99us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 340us/step - loss: 0.6292 - acc: 0.6495\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 162us/step - loss: 0.3972 - acc: 0.8274\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 163us/step - loss: 0.2877 - acc: 0.8838\n",
      "8334/8334 [==============================] - 2s 237us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 166us/step - loss: 0.2923 - acc: 0.8877\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.2353 - acc: 0.9125\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 165us/step - loss: 0.1884 - acc: 0.9283\n",
      "8333/8333 [==============================] - 1s 92us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.2161 - acc: 0.9180\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 169us/step - loss: 0.1821 - acc: 0.9317\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 173us/step - loss: 0.1515 - acc: 0.9402\n",
      "8333/8333 [==============================] - 1s 100us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 345us/step - loss: 0.7058 - acc: 0.5620\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 184us/step - loss: 0.5380 - acc: 0.7335\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 176us/step - loss: 0.4289 - acc: 0.8109\n",
      "8334/8334 [==============================] - 2s 253us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 165us/step - loss: 0.3966 - acc: 0.8354\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.3399 - acc: 0.8655\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 168us/step - loss: 0.2849 - acc: 0.8848\n",
      "8333/8333 [==============================] - 1s 98us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 166us/step - loss: 0.2971 - acc: 0.8806\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.2690 - acc: 0.8962\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 183us/step - loss: 0.2382 - acc: 0.9065\n",
      "8333/8333 [==============================] - 1s 101us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 349us/step - loss: 0.7501 - acc: 0.4933\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 163us/step - loss: 0.6910 - acc: 0.5371\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 164us/step - loss: 0.6498 - acc: 0.6076\n",
      "8334/8334 [==============================] - 2s 250us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 165us/step - loss: 0.6137 - acc: 0.6412\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 168us/step - loss: 0.5689 - acc: 0.6894\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.5337 - acc: 0.7151\n",
      "8333/8333 [==============================] - 1s 99us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 167us/step - loss: 0.5102 - acc: 0.7403\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 169us/step - loss: 0.4880 - acc: 0.7601\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 168us/step - loss: 0.4587 - acc: 0.7805\n",
      "8333/8333 [==============================] - 1s 98us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 350us/step - loss: 0.8428 - acc: 0.4963\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 163us/step - loss: 0.7036 - acc: 0.5007\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 166us/step - loss: 0.7065 - acc: 0.5006\n",
      "8334/8334 [==============================] - 2s 241us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.6975 - acc: 0.4968\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 163us/step - loss: 0.6984 - acc: 0.4940\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 162us/step - loss: 0.7001 - acc: 0.4988\n",
      "8333/8333 [==============================] - 1s 89us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.6972 - acc: 0.4994\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 165us/step - loss: 0.6988 - acc: 0.5005\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 164us/step - loss: 0.6974 - acc: 0.5032\n",
      "8333/8333 [==============================] - 1s 100us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "rate = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "loss_train_drop = []\n",
    "acc_train_drop = []\n",
    "loss_val_drop = []\n",
    "acc_val_drop = []\n",
    "for r in rate:\n",
    "    model_drop = Sequential()\n",
    "    model_drop.add(Dense(50,input_shape = (max_num,)))\n",
    "    model_drop.add(Activation('relu'))\n",
    "    model_drop.add(Dropout(r))\n",
    "    model_drop.add(Dense(50))\n",
    "    model_drop.add(Activation('relu'))\n",
    "    model_drop.add(Dropout(r))\n",
    "    model_drop.add(Dense(num_classes))\n",
    "    model_drop.add(Activation('softmax'))\n",
    "    model_drop.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    loss_val_cv = 0\n",
    "    acc_val_cv = 0\n",
    "    loss_train_cv = 0\n",
    "    acc_train_cv = 0\n",
    "    for train_cv_index, val_index in kf.split(X_train):\n",
    "        X_train_cv = X_train[train_cv_index]\n",
    "        y_train_cv = y_train[train_cv_index]\n",
    "        X_val_cv = X_train[val_index]\n",
    "        y_val_cv = y_train[val_index]\n",
    "        hist = model_drop.fit(X_train_cv,y_train_cv,batch_size=200, epochs = 3)\n",
    "        loss_train_cv = loss_train_cv + hist.history.get('loss')[-1]\n",
    "        acc_train_cv = acc_train_cv + hist.history.get('acc')[-1]\n",
    "        score_val_cv = model_drop.evaluate(X_val_cv,y_val_cv, batch_size=200, verbose = 1)\n",
    "        loss_val_cv = loss_val_cv + score_val_cv[0]\n",
    "        acc_val_cv = acc_val_cv + score_val_cv[1]\n",
    "    loss_val_drop.append(loss_val_cv/3)\n",
    "    acc_val_drop.append(acc_val_cv/3)\n",
    "    loss_train_drop.append(loss_train_cv/3)\n",
    "    acc_train_drop.append(acc_train_cv/3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = rate\n",
    "loss_train_drop= pd.Series(loss_train_drop, index = ix)\n",
    "loss_val_drop = pd.Series(loss_val_drop, index = ix)\n",
    "acc_train_drop = pd.Series(acc_train_drop, index = ix)\n",
    "acc_val_drop = pd.Series(acc_val_drop, index = ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(loss_val_drop, label = 'loss_val')\n",
    "ax.plot(loss_train_drop, label = 'loss_train')\n",
    "ax.legend()\n",
    "plt.xlabel('dropout_rate') \n",
    "plt.ylabel('cross_entropy_loss') \n",
    "plt.title('Model Loss vs. dropout rate')\n",
    "fig.savefig(\"drop_loss_cv_2.png\",dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(acc_val_drop, label = 'acc_val')\n",
    "ax.plot(acc_train_drop, label = 'acc_train')\n",
    "ax.legend()\n",
    "plt.xlabel('dropout_rate') \n",
    "plt.ylabel('accuracy') \n",
    "plt.title('Model Accuracy vs. dropout rate')\n",
    "fig.savefig(\"drop_acc_cv_2.png\",dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 8s 304us/step - loss: 0.4674 - acc: 0.7780\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 4s 172us/step - loss: 0.2513 - acc: 0.9074\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 4s 173us/step - loss: 0.1687 - acc: 0.9395\n",
      "25000/25000 [==============================] - 4s 155us/step\n"
     ]
    }
   ],
   "source": [
    "model_drop_2 = Sequential()\n",
    "model_drop_2.add(Dense(50,input_shape = (max_num,)))\n",
    "model_drop_2.add(Activation('relu'))\n",
    "model_drop_2.add(Dropout(0.5))\n",
    "model_drop_2.add(Dense(50))\n",
    "model_drop_2.add(Activation('relu'))\n",
    "model_drop_2.add(Dropout(0.5))\n",
    "model_drop_2.add(Dense(num_classes))\n",
    "model_drop_2.add(Activation('softmax'))\n",
    "model_drop_2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_drop_2 = model_drop_2.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_drop_2 = model_drop_2.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "drop_train_acc_2 = hist_drop_2.history.get('acc')[-1]\n",
    "drop_test_acc_2 = score_drop_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with two hidden layers and dropout(0.5) on training dataset is\n",
      "0.939479998588562\n",
      "The accurate rate of the model with two hidden layers and dropout(0.5) on test dataset is\n",
      "0.877079999923706\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with two hidden layers and dropout(0.5) on training dataset is')\n",
    "print(drop_train_acc_2)\n",
    "print('The accurate rate of the model with two hidden layers and dropout(0.5) on test dataset is')\n",
    "print(drop_test_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 22s 869us/step - loss: 0.3517 - acc: 0.8536\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 6s 249us/step - loss: 0.1441 - acc: 0.9484\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 6s 232us/step - loss: 0.0743 - acc: 0.9756\n",
      "25000/25000 [==============================] - 12s 487us/step\n"
     ]
    }
   ],
   "source": [
    "model_nn25_2 = Sequential()\n",
    "model_nn25_2.add(Dense(25,input_shape = (max_num,)))\n",
    "model_nn25_2.add(Activation('relu'))\n",
    "model_nn25_2.add(Dense(25))\n",
    "model_nn25_2.add(Activation('relu'))\n",
    "model_nn25_2.add(Dense(num_classes))\n",
    "model_nn25_2.add(Activation('softmax'))\n",
    "model_nn25_2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_nn25_2 = model_nn25_2.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_nn25_2 = model_nn25_2.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "nn25_train_acc_2 = hist_nn25_2.history.get('acc')[-1]\n",
    "nn25_test_acc_2 = score_nn25_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with two hidden layers(25units) on training dataset is\n",
      "0.9673600010871887\n",
      "The accurate rate of the model with two hidden layers(25units) on test dataset is\n",
      "0.8725199995040893\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with two hidden layers(25units) on training dataset is')\n",
    "print(drop_train_acc_2)\n",
    "print('The accurate rate of the model with two hidden layers(25units) on test dataset is')\n",
    "print(drop_test_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 8s 309us/step - loss: 0.4405 - acc: 0.7981\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 5s 182us/step - loss: 0.2181 - acc: 0.9203\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 4s 170us/step - loss: 0.1437 - acc: 0.9492\n",
      "25000/25000 [==============================] - 4s 150us/step\n"
     ]
    }
   ],
   "source": [
    "model_drop_2 = Sequential()\n",
    "model_drop_2.add(Dense(50,input_shape = (max_num,)))\n",
    "model_drop_2.add(Activation('relu'))\n",
    "model_drop_2.add(Dropout(0.4))\n",
    "model_drop_2.add(Dense(50))\n",
    "model_drop_2.add(Activation('relu'))\n",
    "model_drop_2.add(Dropout(0.4))\n",
    "model_drop_2.add(Dense(num_classes))\n",
    "model_drop_2.add(Activation('softmax'))\n",
    "model_drop_2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_drop_2 = model_drop_2.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_drop_2 = model_drop_2.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "drop_train_acc_2 = hist_drop_2.history.get('acc')[-1]\n",
    "drop_test_acc_2 = score_drop_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with two hidden layers and dropout(0.4) on training dataset is\n",
      "0.9491999969482422\n",
      "The accurate rate of the model with two hidden layers and dropout(0.4) on test dataset is\n",
      "0.8730800008773804\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with two hidden layers and dropout(0.4) on training dataset is')\n",
    "print(drop_train_acc_2)\n",
    "print('The accurate rate of the model with two hidden layers and dropout(0.4) on test dataset is')\n",
    "print(drop_test_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 8s 308us/step - loss: 0.4090 - acc: 0.8146\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 4s 166us/step - loss: 0.1834 - acc: 0.9328\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 4s 167us/step - loss: 0.0976 - acc: 0.9674\n",
      "25000/25000 [==============================] - 4s 148us/step\n"
     ]
    }
   ],
   "source": [
    "model_drop_2 = Sequential()\n",
    "model_drop_2.add(Dense(50,input_shape = (max_num,)))\n",
    "model_drop_2.add(Activation('relu'))\n",
    "model_drop_2.add(Dropout(0.3))\n",
    "model_drop_2.add(Dense(50))\n",
    "model_drop_2.add(Activation('relu'))\n",
    "model_drop_2.add(Dropout(0.3))\n",
    "model_drop_2.add(Dense(num_classes))\n",
    "model_drop_2.add(Activation('softmax'))\n",
    "model_drop_2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_drop_2 = model_drop_2.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_drop_2 = model_drop_2.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "drop_train_acc_2 = hist_drop_2.history.get('acc')[-1]\n",
    "drop_test_acc_2 = score_drop_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with two hidden layers and dropout(0.3) on training dataset is\n",
      "0.9673600010871887\n",
      "The accurate rate of the model with two hidden layers and dropout(0.3) on test dataset is\n",
      "0.8725199995040893\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with two hidden layers and dropout(0.3) on training dataset is')\n",
    "print(drop_train_acc_2)\n",
    "print('The accurate rate of the model with two hidden layers and dropout(0.3) on test dataset is')\n",
    "print(drop_test_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 402us/step - loss: 0.3948 - acc: 0.8295\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 184us/step - loss: 0.1339 - acc: 0.9548\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 191us/step - loss: 0.0534 - acc: 0.9863\n",
      "8334/8334 [==============================] - 3s 311us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 189us/step - loss: 0.2059 - acc: 0.9323\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 184us/step - loss: 0.0505 - acc: 0.9873\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 182us/step - loss: 0.0162 - acc: 0.9983\n",
      "8333/8333 [==============================] - 1s 102us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 0.0477 - acc: 0.9878\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 173us/step - loss: 0.0177 - acc: 0.9980\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.0117 - acc: 0.9996\n",
      "8333/8333 [==============================] - 1s 99us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 379us/step - loss: 0.4162 - acc: 0.8459\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 173us/step - loss: 0.1735 - acc: 0.9605\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 173us/step - loss: 0.1021 - acc: 0.9875\n",
      "8334/8334 [==============================] - 2s 268us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.2741 - acc: 0.9276\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 0.1165 - acc: 0.9852\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 0.0776 - acc: 0.9974\n",
      "8333/8333 [==============================] - 1s 104us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 179us/step - loss: 0.1257 - acc: 0.9779\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 196us/step - loss: 0.0900 - acc: 0.9947\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 193us/step - loss: 0.0729 - acc: 0.9994\n",
      "8333/8333 [==============================] - 1s 104us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 393us/step - loss: 0.8180 - acc: 0.8366\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 178us/step - loss: 0.4571 - acc: 0.9492\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 176us/step - loss: 0.3510 - acc: 0.9708\n",
      "8334/8334 [==============================] - 2s 287us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 0.4823 - acc: 0.9266\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.3380 - acc: 0.9761\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 177us/step - loss: 0.2568 - acc: 0.9903\n",
      "8333/8333 [==============================] - 1s 100us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 0.4007 - acc: 0.9435\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.3340 - acc: 0.9817\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.2488 - acc: 0.9956\n",
      "8333/8333 [==============================] - 1s 101us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 6s 390us/step - loss: 2.3336 - acc: 0.8399\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 175us/step - loss: 0.9719 - acc: 0.8942\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 180us/step - loss: 0.8172 - acc: 0.9024\n",
      "8334/8334 [==============================] - 2s 284us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.7263 - acc: 0.9030\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.5863 - acc: 0.9260\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 193us/step - loss: 0.5042 - acc: 0.9384\n",
      "8333/8333 [==============================] - 1s 124us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 189us/step - loss: 0.5779 - acc: 0.9121\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 182us/step - loss: 0.4615 - acc: 0.9431\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 178us/step - loss: 0.4252 - acc: 0.9490\n",
      "8333/8333 [==============================] - 1s 103us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 390us/step - loss: 11.5090 - acc: 0.7734\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 176us/step - loss: 2.2685 - acc: 0.8452\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 174us/step - loss: 1.4654 - acc: 0.8604\n",
      "8334/8334 [==============================] - 2s 282us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 180us/step - loss: 1.2861 - acc: 0.8702\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 1.2563 - acc: 0.8748\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 173us/step - loss: 1.2545 - acc: 0.8780\n",
      "8333/8333 [==============================] - 1s 98us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 1.2579 - acc: 0.8733\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 1.2486 - acc: 0.8759\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 179us/step - loss: 1.2477 - acc: 0.8806\n",
      "8333/8333 [==============================] - 1s 103us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 398us/step - loss: 106.2643 - acc: 0.5230\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 173us/step - loss: 14.8354 - acc: 0.5011\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 176us/step - loss: 7.6500 - acc: 0.5087\n",
      "8334/8334 [==============================] - 2s 283us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 6.4992 - acc: 0.4978\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 6.4632 - acc: 0.4998\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 6.4630 - acc: 0.5037\n",
      "8333/8333 [==============================] - 1s 95us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 181us/step - loss: 6.4624 - acc: 0.4986\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 6.4635 - acc: 0.4963\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 179us/step - loss: 6.4633 - acc: 0.4979\n",
      "8333/8333 [==============================] - 1s 103us/step\n"
     ]
    }
   ],
   "source": [
    "lambda_list = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]\n",
    "loss_train_2_l1 = []\n",
    "acc_train_2_l1 = []\n",
    "loss_val_2_l1 = []\n",
    "acc_val_2_l1 = []\n",
    "for par in lambda_list:\n",
    "    model_2_l1 = Sequential()\n",
    "    model_2_l1.add(Dense(50,input_shape = (max_num,), kernel_regularizer = l1(par), bias_regularizer=l1(par)))\n",
    "    model_2_l1.add(Activation('relu'))\n",
    "    model_2_l1.add(Dense(50, kernel_regularizer = l1(par), bias_regularizer=l1(par)))\n",
    "    model_2_l1.add(Activation('relu'))\n",
    "    model_2_l1.add(Dense(num_classes, kernel_regularizer = l1(par), bias_regularizer=l1(par)))\n",
    "    model_2_l1.add(Activation('softmax'))\n",
    "    model_2_l1.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    loss_val_cv = 0\n",
    "    acc_val_cv = 0\n",
    "    loss_train_cv = 0\n",
    "    acc_train_cv = 0\n",
    "    for train_cv_index, val_index in kf.split(X_train):\n",
    "        X_train_cv = X_train[train_cv_index]\n",
    "        y_train_cv = y_train[train_cv_index]\n",
    "        X_val_cv = X_train[val_index]\n",
    "        y_val_cv = y_train[val_index]\n",
    "        hist = model_2_l1.fit(X_train_cv,y_train_cv,batch_size=200, epochs = 3)\n",
    "        loss_train_cv = loss_train_cv + hist.history.get('loss')[-1]\n",
    "        acc_train_cv = acc_train_cv + hist.history.get('acc')[-1]\n",
    "        score_val_cv = model_2_l1.evaluate(X_val_cv,y_val_cv, batch_size=200, verbose = 1)\n",
    "        loss_val_cv = loss_val_cv + score_val_cv[0]\n",
    "        acc_val_cv = acc_val_cv + score_val_cv[1]\n",
    "    loss_val_2_l1.append(loss_val_cv/3)\n",
    "    acc_val_2_l1.append(acc_val_cv/3)\n",
    "    loss_train_2_l1.append(loss_train_cv/3)\n",
    "    acc_train_2_l1.append(acc_train_cv/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_val</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.027111</td>\n",
       "      <td>0.197342</td>\n",
       "      <td>0.994740</td>\n",
       "      <td>0.946803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.084224</td>\n",
       "      <td>0.267125</td>\n",
       "      <td>0.994780</td>\n",
       "      <td>0.942803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000100</th>\n",
       "      <td>0.285536</td>\n",
       "      <td>0.462369</td>\n",
       "      <td>0.985540</td>\n",
       "      <td>0.918402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>0.582214</td>\n",
       "      <td>0.661997</td>\n",
       "      <td>0.929919</td>\n",
       "      <td>0.886720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>1.322553</td>\n",
       "      <td>1.279183</td>\n",
       "      <td>0.873020</td>\n",
       "      <td>0.869440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100000</th>\n",
       "      <td>6.858770</td>\n",
       "      <td>6.491953</td>\n",
       "      <td>0.503460</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss_train  loss_val  acc_train   acc_val\n",
       "lambda                                             \n",
       "0.000001    0.027111  0.197342   0.994740  0.946803\n",
       "0.000010    0.084224  0.267125   0.994780  0.942803\n",
       "0.000100    0.285536  0.462369   0.985540  0.918402\n",
       "0.001000    0.582214  0.661997   0.929919  0.886720\n",
       "0.010000    1.322553  1.279183   0.873020  0.869440\n",
       "0.100000    6.858770  6.491953   0.503460  0.500000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_2_reg_cv = pd.DataFrame({'loss_train': loss_train_2_l1,\n",
    "                          'loss_val': loss_val_2_l1,\n",
    "                       'acc_train': acc_train_2_l1,\n",
    "                        'acc_val':acc_val_2_l1,\n",
    "                         'lambda':lambda_list}).set_index('lambda')\n",
    "l1_2_reg_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 9s 351us/step - loss: 0.3950 - acc: 0.8576\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 4s 177us/step - loss: 0.1798 - acc: 0.9588\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 4s 172us/step - loss: 0.1058 - acc: 0.9873\n",
      "25000/25000 [==============================] - 4s 163us/step\n"
     ]
    }
   ],
   "source": [
    "# indicating by the result of l1_reg_cv data frame, will set the lambda as 1e-5 for l1 norm regularization\n",
    "model_2_l1 = Sequential()\n",
    "model_2_l1.add(Dense(50,input_shape = (max_num,), kernel_regularizer = l1(1e-5), bias_regularizer=l1(1e-5)))\n",
    "model_2_l1.add(Activation('relu'))\n",
    "model_2_l1.add(Dense(50, kernel_regularizer = l1(1e-5), bias_regularizer=l1(1e-5)))\n",
    "model_2_l1.add(Activation('relu'))\n",
    "model_2_l1.add(Dense(num_classes, kernel_regularizer = l1(1e-5), bias_regularizer=l1(1e-5)))\n",
    "model_2_l1.add(Activation('softmax'))\n",
    "model_2_l1.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_2_l1 = model_2_l1.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_2_l1 = model_2_l1.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "l1_train_acc_2 = hist_2_l1.history.get('acc')[-1]\n",
    "l1_test_acc_2 = score_2_l1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with two hidden layers and l1 regularization on training dataset is\n",
      "0.987320011138916\n",
      "The accurate rate of the model with two hidden layers and l1 regularization on test dataset is\n",
      "0.865840000629425\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with two hidden layers and l1 regularization on training dataset is')\n",
    "print(l1_train_acc_2)\n",
    "print('The accurate rate of the model with two hidden layers and l1 regularization on test dataset is')\n",
    "print(l1_test_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 8s 338us/step - loss: 0.3470 - acc: 0.8552\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 4s 173us/step - loss: 0.1427 - acc: 0.9525\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 4s 175us/step - loss: 0.0596 - acc: 0.9826\n",
      "25000/25000 [==============================] - 4s 161us/step\n"
     ]
    }
   ],
   "source": [
    "# indicating by the result of l1_reg_cv data frame, will set the lambda as 1e-6 for l1 norm regularization\n",
    "model_2_l1 = Sequential()\n",
    "model_2_l1.add(Dense(50,input_shape = (max_num,), kernel_regularizer = l1(1e-6), bias_regularizer=l1(1e-6)))\n",
    "model_2_l1.add(Activation('relu'))\n",
    "model_2_l1.add(Dense(50, kernel_regularizer = l1(1e-6), bias_regularizer=l1(1e-6)))\n",
    "model_2_l1.add(Activation('relu'))\n",
    "model_2_l1.add(Dense(num_classes, kernel_regularizer = l1(1e-6), bias_regularizer=l1(1e-6)))\n",
    "model_2_l1.add(Activation('softmax'))\n",
    "model_2_l1.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_2_l1 = model_2_l1.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_2_l1 = model_2_l1.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "l1_train_acc_2 = hist_2_l1.history.get('acc')[-1]\n",
    "l1_test_acc_2 = score_2_l1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with two hidden layers and l1 regularization on training dataset is\n",
      "0.9826000151634217\n",
      "The accurate rate of the model with two hidden layers and l1 regularization on test dataset is\n",
      "0.8631199975013732\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with two hidden layers and l1 regularization on training dataset is')\n",
    "print(l1_train_acc_2)\n",
    "print('The accurate rate of the model with two hidden layers and l1 regularization on test dataset is')\n",
    "print(l1_test_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 414us/step - loss: 0.3684 - acc: 0.8426\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 172us/step - loss: 0.1094 - acc: 0.9639\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 172us/step - loss: 0.0346 - acc: 0.9913\n",
      "8334/8334 [==============================] - 2s 298us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 0.1944 - acc: 0.9338\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.0430 - acc: 0.9873\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 173us/step - loss: 0.0093 - acc: 0.9977\n",
      "8333/8333 [==============================] - 1s 100us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.0411 - acc: 0.9859\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.0106 - acc: 0.9978\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.0028 - acc: 0.9994\n",
      "8333/8333 [==============================] - 1s 99us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 419us/step - loss: 0.3726 - acc: 0.8359\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 177us/step - loss: 0.1180 - acc: 0.9606\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 174us/step - loss: 0.0384 - acc: 0.9899\n",
      "8334/8334 [==============================] - 3s 306us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.1952 - acc: 0.9341\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.0457 - acc: 0.9872\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.0114 - acc: 0.9985\n",
      "8333/8333 [==============================] - 1s 100us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 0.0434 - acc: 0.9857\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.0125 - acc: 0.9984\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.0059 - acc: 0.9996\n",
      "8333/8333 [==============================] - 1s 98us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 426us/step - loss: 0.3803 - acc: 0.8379\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 174us/step - loss: 0.1244 - acc: 0.9643\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 178us/step - loss: 0.0503 - acc: 0.9917\n",
      "8334/8334 [==============================] - 3s 309us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.2144 - acc: 0.9367\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.0651 - acc: 0.9880\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.0322 - acc: 0.9981\n",
      "8333/8333 [==============================] - 1s 100us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 0.0654 - acc: 0.9855\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.0382 - acc: 0.9968\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 174us/step - loss: 0.0293 - acc: 0.9995\n",
      "8333/8333 [==============================] - 1s 101us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 432us/step - loss: 0.4978 - acc: 0.8374\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 176us/step - loss: 0.2396 - acc: 0.9585\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 173us/step - loss: 0.1606 - acc: 0.9849\n",
      "8334/8334 [==============================] - 3s 320us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 189us/step - loss: 0.3119 - acc: 0.9294\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 184us/step - loss: 0.1693 - acc: 0.9826\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 183us/step - loss: 0.1187 - acc: 0.9964\n",
      "8333/8333 [==============================] - 1s 105us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 187us/step - loss: 0.1946 - acc: 0.9657\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 178us/step - loss: 0.1472 - acc: 0.9900\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 177us/step - loss: 0.1209 - acc: 0.9975\n",
      "8333/8333 [==============================] - 1s 103us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 7s 427us/step - loss: 1.1380 - acc: 0.8364\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 175us/step - loss: 0.5568 - acc: 0.9267\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 3s 173us/step - loss: 0.4381 - acc: 0.9302\n",
      "8334/8334 [==============================] - 3s 316us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.4591 - acc: 0.9032\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 176us/step - loss: 0.3410 - acc: 0.9408\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 175us/step - loss: 0.3277 - acc: 0.9428\n",
      "8333/8333 [==============================] - 1s 99us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 233us/step - loss: 0.3976 - acc: 0.9152\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 215us/step - loss: 0.3011 - acc: 0.9511\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 187us/step - loss: 0.2914 - acc: 0.9526\n",
      "8333/8333 [==============================] - 1s 120us/step\n",
      "Epoch 1/3\n",
      "16666/16666 [==============================] - 11s 644us/step - loss: 4.8265 - acc: 0.8372\n",
      "Epoch 2/3\n",
      "16666/16666 [==============================] - 3s 200us/step - loss: 1.6492 - acc: 0.8780\n",
      "Epoch 3/3\n",
      "16666/16666 [==============================] - 4s 250us/step - loss: 0.9525 - acc: 0.8799\n",
      "8334/8334 [==============================] - 3s 402us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 221us/step - loss: 0.7578 - acc: 0.8780\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 4s 220us/step - loss: 0.7033 - acc: 0.8783\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 4s 235us/step - loss: 0.6863 - acc: 0.8861\n",
      "8333/8333 [==============================] - 1s 154us/step\n",
      "Epoch 1/3\n",
      "16667/16667 [==============================] - 4s 217us/step - loss: 0.6862 - acc: 0.8844\n",
      "Epoch 2/3\n",
      "16667/16667 [==============================] - 3s 194us/step - loss: 0.6809 - acc: 0.8838\n",
      "Epoch 3/3\n",
      "16667/16667 [==============================] - 3s 191us/step - loss: 0.6703 - acc: 0.8899\n",
      "8333/8333 [==============================] - 1s 109us/step\n"
     ]
    }
   ],
   "source": [
    "lambda_list = [1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]\n",
    "loss_train_2_l2 = []\n",
    "acc_train_2_l2 = []\n",
    "loss_val_2_l2 = []\n",
    "acc_val_2_l2 = []\n",
    "for par in lambda_list:\n",
    "    model_2_l2 = Sequential()\n",
    "    model_2_l2.add(Dense(50,input_shape = (max_num,), kernel_regularizer = l2(par), bias_regularizer=l2(par)))\n",
    "    model_2_l2.add(Activation('relu'))\n",
    "    model_2_l2.add(Dense(50, kernel_regularizer = l2(par), bias_regularizer=l2(par)))\n",
    "    model_2_l2.add(Activation('relu'))\n",
    "    model_2_l2.add(Dense(num_classes, kernel_regularizer = l2(par), bias_regularizer=l2(par)))\n",
    "    model_2_l2.add(Activation('softmax'))\n",
    "    model_2_l2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    loss_val_cv = 0\n",
    "    acc_val_cv = 0\n",
    "    loss_train_cv = 0\n",
    "    acc_train_cv = 0\n",
    "    for train_cv_index, val_index in kf.split(X_train):\n",
    "        X_train_cv = X_train[train_cv_index]\n",
    "        y_train_cv = y_train[train_cv_index]\n",
    "        X_val_cv = X_train[val_index]\n",
    "        y_val_cv = y_train[val_index]\n",
    "        hist = model_2_l2.fit(X_train_cv,y_train_cv,batch_size=200, epochs = 3)\n",
    "        loss_train_cv = loss_train_cv + hist.history.get('loss')[-1]\n",
    "        acc_train_cv = acc_train_cv + hist.history.get('acc')[-1]\n",
    "        score_val_cv = model_2_l2.evaluate(X_val_cv,y_val_cv, batch_size=200, verbose = 1)\n",
    "        loss_val_cv = loss_val_cv + score_val_cv[0]\n",
    "        acc_val_cv = acc_val_cv + score_val_cv[1]\n",
    "    loss_val_2_l2.append(loss_val_cv/3)\n",
    "    acc_val_2_l2.append(acc_val_cv/3)\n",
    "    loss_train_2_l2.append(loss_train_cv/3)\n",
    "    acc_train_2_l2.append(acc_train_cv/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_train</th>\n",
       "      <th>loss_val</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.015571</td>\n",
       "      <td>0.182387</td>\n",
       "      <td>0.99614</td>\n",
       "      <td>0.950123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.018547</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>0.99598</td>\n",
       "      <td>0.950683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000100</th>\n",
       "      <td>0.037256</td>\n",
       "      <td>0.205451</td>\n",
       "      <td>0.99642</td>\n",
       "      <td>0.951043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>0.133404</td>\n",
       "      <td>0.314742</td>\n",
       "      <td>0.99294</td>\n",
       "      <td>0.930482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>0.352425</td>\n",
       "      <td>0.496134</td>\n",
       "      <td>0.94188</td>\n",
       "      <td>0.877400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100000</th>\n",
       "      <td>0.769707</td>\n",
       "      <td>0.733524</td>\n",
       "      <td>0.88528</td>\n",
       "      <td>0.873720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss_train  loss_val  acc_train   acc_val\n",
       "lambda                                             \n",
       "0.000001    0.015571  0.182387    0.99614  0.950123\n",
       "0.000010    0.018547  0.176901    0.99598  0.950683\n",
       "0.000100    0.037256  0.205451    0.99642  0.951043\n",
       "0.001000    0.133404  0.314742    0.99294  0.930482\n",
       "0.010000    0.352425  0.496134    0.94188  0.877400\n",
       "0.100000    0.769707  0.733524    0.88528  0.873720"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_2_reg_cv = pd.DataFrame({'loss_train': loss_train_2_l2,\n",
    "                          'loss_val': loss_val_2_l2,\n",
    "                       'acc_train': acc_train_2_l2,\n",
    "                        'acc_val':acc_val_2_l2,\n",
    "                         'lambda':lambda_list}).set_index('lambda')\n",
    "l2_2_reg_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 9s 342us/step - loss: 0.3527 - acc: 0.8592\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 4s 164us/step - loss: 0.1344 - acc: 0.9594\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 4s 163us/step - loss: 0.0587 - acc: 0.9888\n",
      "25000/25000 [==============================] - 4s 167us/step\n"
     ]
    }
   ],
   "source": [
    "# indicating by the result of l2_2_reg_cv data frame, will set the lambda as 1e-4 for l2 norm regularization\n",
    "model_2_l2 = Sequential()\n",
    "model_2_l2.add(Dense(50,input_shape = (max_num,), kernel_regularizer = l2(1e-4), bias_regularizer=l2(1e-4)))\n",
    "model_2_l2.add(Activation('relu'))\n",
    "model_2_l2.add(Dense(50, kernel_regularizer = l2(1e-4), bias_regularizer=l2(1e-4)))\n",
    "model_2_l2.add(Activation('relu'))\n",
    "model_2_l2.add(Dense(num_classes, kernel_regularizer = l2(1e-4), bias_regularizer=l2(1e-4)))\n",
    "model_2_l2.add(Activation('softmax'))\n",
    "model_2_l2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_2_l2 = model_2_l2.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_2_l2 = model_2_l2.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "l2_train_acc_2 = hist_2_l2.history.get('acc')[-1]\n",
    "l2_test_acc_2 = score_2_l2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with two hidden layers and l2 regularization on training dataset is\n",
      "0.988760009765625\n",
      "The accurate rate of the model with two hidden layers and l2 regularization on test dataset is\n",
      "0.862720000743866\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with two hidden layers and l2 regularization on training dataset is')\n",
    "print(l2_train_acc_2)\n",
    "print('The accurate rate of the model with two hidden layers and l2 regularization on test dataset is')\n",
    "print(l2_test_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 8s 340us/step - loss: 0.3385 - acc: 0.8563\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 4s 167us/step - loss: 0.1322 - acc: 0.9526\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 4s 166us/step - loss: 0.0576 - acc: 0.9823\n",
      "25000/25000 [==============================] - 4s 165us/step\n"
     ]
    }
   ],
   "source": [
    "# indicating by the result of l2_2_reg_cv data frame, will set the lambda as 1e-5 for l2 norm regularization\n",
    "model_2_l2 = Sequential()\n",
    "model_2_l2.add(Dense(50,input_shape = (max_num,), kernel_regularizer = l2(1e-5), bias_regularizer=l2(1e-5)))\n",
    "model_2_l2.add(Activation('relu'))\n",
    "model_2_l2.add(Dense(50, kernel_regularizer = l2(1e-5), bias_regularizer=l2(1e-5)))\n",
    "model_2_l2.add(Activation('relu'))\n",
    "model_2_l2.add(Dense(num_classes, kernel_regularizer = l2(1e-5), bias_regularizer=l2(1e-5)))\n",
    "model_2_l2.add(Activation('softmax'))\n",
    "model_2_l2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_2_l2 = model_2_l2.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_2_l2 = model_2_l2.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "l2_train_acc_2 = hist_2_l2.history.get('acc')[-1]\n",
    "l2_test_acc_2 = score_2_l2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurate rate of the model with two hidden layers and l2 regularization on training dataset is\n",
      "0.9823200106620789\n",
      "The accurate rate of the model with two hidden layers and l2 regularization on test dataset is\n",
      "0.8600399994850159\n"
     ]
    }
   ],
   "source": [
    "print('The accurate rate of the model with two hidden layers and l2 regularization on training dataset is')\n",
    "print(l2_train_acc_2)\n",
    "print('The accurate rate of the model with two hidden layers and l2 regularization on test dataset is')\n",
    "print(l2_test_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_258 (Dense)            (None, 50)                500050    \n",
      "_________________________________________________________________\n",
      "activation_210 (Activation)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "activation_211 (Activation)  (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 2)                 102       \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 502,702\n",
      "Trainable params: 502,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model_2_l2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### augment the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((X_train, X_test), axis=0)\n",
    "targets = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = max(y_train) + 1\n",
    "print(num_classes)\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "max_num = 10000\n",
    "tokenizer = Tokenizer(num_words=max_num)\n",
    "tokenizer.fit_on_sequences(X_train)\n",
    "X_train = tokenizer.sequences_to_matrix(X_train, mode = 'tfidf')\n",
    "X_test = tokenizer.sequences_to_matrix(X_test, mode = 'tfidf')\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 22s 553us/step - loss: 0.3048 - acc: 0.8711\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 21s 518us/step - loss: 0.0810 - acc: 0.9741\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 20s 510us/step - loss: 0.0160 - acc: 0.9971\n",
      "10000/10000 [==============================] - 2s 232us/step\n",
      "The accurate rate of the overfitting model on training dataset is\n",
      "0.9971000027656555\n",
      "The accurate rate of the overfitting model on test dataset is\n",
      "0.8960999977588654\n"
     ]
    }
   ],
   "source": [
    "# the baseline to compare with\n",
    "model_overfitting = Sequential()\n",
    "model_overfitting.add(Dense(250,input_shape = (max_num,)))\n",
    "model_overfitting.add(Activation('relu'))\n",
    "model_overfitting.add(Dense(num_classes))\n",
    "model_overfitting.add(Activation('softmax'))\n",
    "model_overfitting.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_overfitting = model_overfitting.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_overfitting = model_overfitting.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "base_train_acc = hist_overfitting.history.get('acc')[-1]\n",
    "base_test_acc = score_overfitting[1]\n",
    "\n",
    "print('The accurate rate of the overfitting model on training dataset is')\n",
    "print(base_train_acc)\n",
    "print('The accurate rate of the overfitting model on test dataset is')\n",
    "print(base_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 10s 258us/step - loss: 0.3205 - acc: 0.8643\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 0.1456 - acc: 0.9445\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.0584 - acc: 0.9799\n",
      "10000/10000 [==============================] - 2s 169us/step\n",
      "The accurate rate of the overfitting model with two hidden layers on training dataset is\n",
      "0.9799250122904778\n",
      "The accurate rate of the overfitting model with two hidden layers on test dataset is\n",
      "0.8881999969482421\n"
     ]
    }
   ],
   "source": [
    "# baseline model with two hidden layers\n",
    "model_overfitting_2 = Sequential()\n",
    "model_overfitting_2.add(Dense(50,input_shape = (max_num,)))\n",
    "model_overfitting_2.add(Activation('relu'))\n",
    "model_overfitting_2.add(Dense(50))\n",
    "model_overfitting_2.add(Activation('relu'))\n",
    "model_overfitting_2.add(Dense(num_classes))\n",
    "model_overfitting_2.add(Activation('softmax'))\n",
    "model_overfitting_2.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "hist_overfitting_2 = model_overfitting_2.fit(X_train,y_train, batch_size=200, epochs = 3, verbose = 1)\n",
    "score_overfitting_2 = model_overfitting_2.evaluate(X_test,y_test, batch_size=200, verbose = 1)\n",
    "\n",
    "base_train_acc_2 = hist_overfitting_2.history.get('acc')[-1]\n",
    "base_test_acc_2 = score_overfitting_2[1]\n",
    "\n",
    "print('The accurate rate of the overfitting model with two hidden layers on training dataset is')\n",
    "print(base_train_acc_2)\n",
    "print('The accurate rate of the overfitting model with two hidden layers on test dataset is')\n",
    "print(base_test_acc_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
